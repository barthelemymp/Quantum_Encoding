{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.autograd\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures, PowerTransformer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "class GenericDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None, preprocessing =None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        if preprocessing :\n",
    "            self.data = preprocessing(self.data)\n",
    "\n",
    "\n",
    "        \n",
    "        # shuffle the data\n",
    "        self.data= self.data.sample(frac=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Xs = self.data.iloc[:,0:-1]\n",
    "        self.labels = self.data.iloc[:,-1]\n",
    "        self.transform = transform\n",
    "        self.nfeatures = len(self.Xs.iloc[0,:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(type(idx))\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        X = torch.tensor(self.Xs.iloc[idx,:].as_matrix()).float()\n",
    "\n",
    "        \n",
    "        Y = torch.tensor(self.labels.iloc[idx]).long()\n",
    "\n",
    "        sample = {'X': X, 'label': Y}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def get_nfeatures(self,):\n",
    "        sample = self[0]\n",
    "        X = sample['X']\n",
    "        return(X.shape[0])\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC_binary_prep(object):\n",
    "    def __init__(self,):\n",
    "        super(BC_binary_prep, self).__init__()\n",
    "        \n",
    "    def __call__(self, data): #data is in panda format\n",
    "        data = data.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "        cols = data.columns.tolist()\n",
    "        cols = cols[1:] + [cols[0]]\n",
    "        data = data[cols]\n",
    "        data['diagnosis'].loc[data['diagnosis'] == 'M'] = 0\n",
    "        data['diagnosis'].loc[data['diagnosis'] == 'B'] = 1\n",
    "        #data = pd.DataFrame(data.as_matrix(), columns=['SepalLengthCm'  ,'SepalWidthCm','PetalLengthCm','PetalWidthCm', 'Species'])\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0         17.990         10.38          122.80     1001.0          0.11840   \n",
      "1         20.570         17.77          132.90     1326.0          0.08474   \n",
      "2         19.690         21.25          130.00     1203.0          0.10960   \n",
      "3         11.420         20.38           77.58      386.1          0.14250   \n",
      "4         20.290         14.34          135.10     1297.0          0.10030   \n",
      "5         12.450         15.70           82.57      477.1          0.12780   \n",
      "6         18.250         19.98          119.60     1040.0          0.09463   \n",
      "7         13.710         20.83           90.20      577.9          0.11890   \n",
      "8         13.000         21.82           87.50      519.8          0.12730   \n",
      "9         12.460         24.04           83.97      475.9          0.11860   \n",
      "10        16.020         23.24          102.70      797.8          0.08206   \n",
      "11        15.780         17.89          103.60      781.0          0.09710   \n",
      "12        19.170         24.80          132.40     1123.0          0.09740   \n",
      "13        15.850         23.95          103.70      782.7          0.08401   \n",
      "14        13.730         22.61           93.60      578.3          0.11310   \n",
      "15        14.540         27.54           96.73      658.8          0.11390   \n",
      "16        14.680         20.13           94.74      684.5          0.09867   \n",
      "17        16.130         20.68          108.10      798.8          0.11700   \n",
      "18        19.810         22.15          130.00     1260.0          0.09831   \n",
      "19        13.540         14.36           87.46      566.3          0.09779   \n",
      "20        13.080         15.71           85.63      520.0          0.10750   \n",
      "21         9.504         12.44           60.34      273.9          0.10240   \n",
      "22        15.340         14.26          102.50      704.4          0.10730   \n",
      "23        21.160         23.04          137.20     1404.0          0.09428   \n",
      "24        16.650         21.38          110.00      904.6          0.11210   \n",
      "25        17.140         16.40          116.00      912.7          0.11860   \n",
      "26        14.580         21.53           97.41      644.8          0.10540   \n",
      "27        18.610         20.25          122.10     1094.0          0.09440   \n",
      "28        15.300         25.27          102.40      732.4          0.10820   \n",
      "29        17.570         15.05          115.00      955.1          0.09847   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "539        7.691         25.44           48.34      170.4          0.08668   \n",
      "540       11.540         14.44           74.65      402.9          0.09984   \n",
      "541       14.470         24.99           95.81      656.4          0.08837   \n",
      "542       14.740         25.42           94.70      668.6          0.08275   \n",
      "543       13.210         28.06           84.88      538.4          0.08671   \n",
      "544       13.870         20.70           89.77      584.8          0.09578   \n",
      "545       13.620         23.23           87.19      573.2          0.09246   \n",
      "546       10.320         16.35           65.31      324.9          0.09434   \n",
      "547       10.260         16.58           65.85      320.8          0.08877   \n",
      "548        9.683         19.34           61.05      285.7          0.08491   \n",
      "549       10.820         24.21           68.89      361.6          0.08192   \n",
      "550       10.860         21.48           68.51      360.5          0.07431   \n",
      "551       11.130         22.44           71.49      378.4          0.09566   \n",
      "552       12.770         29.43           81.35      507.9          0.08276   \n",
      "553        9.333         21.94           59.01      264.0          0.09240   \n",
      "554       12.880         28.92           82.50      514.3          0.08123   \n",
      "555       10.290         27.61           65.67      321.4          0.09030   \n",
      "556       10.160         19.59           64.73      311.7          0.10030   \n",
      "557        9.423         27.88           59.26      271.3          0.08123   \n",
      "558       14.590         22.68           96.39      657.1          0.08473   \n",
      "559       11.510         23.93           74.52      403.5          0.09261   \n",
      "560       14.050         27.15           91.38      600.4          0.09929   \n",
      "561       11.200         29.37           70.67      386.0          0.07449   \n",
      "562       15.220         30.62          103.40      716.9          0.10480   \n",
      "563       20.920         25.09          143.00     1347.0          0.10990   \n",
      "564       21.560         22.39          142.00     1479.0          0.11100   \n",
      "565       20.130         28.25          131.20     1261.0          0.09780   \n",
      "566       16.600         28.08          108.30      858.1          0.08455   \n",
      "567       20.600         29.33          140.10     1265.0          0.11780   \n",
      "568        7.760         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0             0.27760        0.300100             0.147100         0.2419   \n",
      "1             0.07864        0.086900             0.070170         0.1812   \n",
      "2             0.15990        0.197400             0.127900         0.2069   \n",
      "3             0.28390        0.241400             0.105200         0.2597   \n",
      "4             0.13280        0.198000             0.104300         0.1809   \n",
      "5             0.17000        0.157800             0.080890         0.2087   \n",
      "6             0.10900        0.112700             0.074000         0.1794   \n",
      "7             0.16450        0.093660             0.059850         0.2196   \n",
      "8             0.19320        0.185900             0.093530         0.2350   \n",
      "9             0.23960        0.227300             0.085430         0.2030   \n",
      "10            0.06669        0.032990             0.033230         0.1528   \n",
      "11            0.12920        0.099540             0.066060         0.1842   \n",
      "12            0.24580        0.206500             0.111800         0.2397   \n",
      "13            0.10020        0.099380             0.053640         0.1847   \n",
      "14            0.22930        0.212800             0.080250         0.2069   \n",
      "15            0.15950        0.163900             0.073640         0.2303   \n",
      "16            0.07200        0.073950             0.052590         0.1586   \n",
      "17            0.20220        0.172200             0.102800         0.2164   \n",
      "18            0.10270        0.147900             0.094980         0.1582   \n",
      "19            0.08129        0.066640             0.047810         0.1885   \n",
      "20            0.12700        0.045680             0.031100         0.1967   \n",
      "21            0.06492        0.029560             0.020760         0.1815   \n",
      "22            0.21350        0.207700             0.097560         0.2521   \n",
      "23            0.10220        0.109700             0.086320         0.1769   \n",
      "24            0.14570        0.152500             0.091700         0.1995   \n",
      "25            0.22760        0.222900             0.140100         0.3040   \n",
      "26            0.18680        0.142500             0.087830         0.2252   \n",
      "27            0.10660        0.149000             0.077310         0.1697   \n",
      "28            0.16970        0.168300             0.087510         0.1926   \n",
      "29            0.11570        0.098750             0.079530         0.1739   \n",
      "..                ...             ...                  ...            ...   \n",
      "539           0.11990        0.092520             0.013640         0.2037   \n",
      "540           0.11200        0.067370             0.025940         0.1818   \n",
      "541           0.12300        0.100900             0.038900         0.1872   \n",
      "542           0.07214        0.041050             0.030270         0.1840   \n",
      "543           0.06877        0.029870             0.032750         0.1628   \n",
      "544           0.10180        0.036880             0.023690         0.1620   \n",
      "545           0.06747        0.029740             0.024430         0.1664   \n",
      "546           0.04994        0.010120             0.005495         0.1885   \n",
      "547           0.08066        0.043580             0.024380         0.1669   \n",
      "548           0.05030        0.023370             0.009615         0.1580   \n",
      "549           0.06602        0.015480             0.008160         0.1976   \n",
      "550           0.04227        0.000000             0.000000         0.1661   \n",
      "551           0.08194        0.048240             0.022570         0.2030   \n",
      "552           0.04234        0.019970             0.014990         0.1539   \n",
      "553           0.05605        0.039960             0.012820         0.1692   \n",
      "554           0.05824        0.061950             0.023430         0.1566   \n",
      "555           0.07658        0.059990             0.027380         0.1593   \n",
      "556           0.07504        0.005025             0.011160         0.1791   \n",
      "557           0.04971        0.000000             0.000000         0.1742   \n",
      "558           0.13300        0.102900             0.037360         0.1454   \n",
      "559           0.10210        0.111200             0.041050         0.1388   \n",
      "560           0.11260        0.044620             0.043040         0.1537   \n",
      "561           0.03558        0.000000             0.000000         0.1060   \n",
      "562           0.20870        0.255000             0.094290         0.2128   \n",
      "563           0.22360        0.317400             0.147400         0.2149   \n",
      "564           0.11590        0.243900             0.138900         0.1726   \n",
      "565           0.10340        0.144000             0.097910         0.1752   \n",
      "566           0.10230        0.092510             0.053020         0.1590   \n",
      "567           0.27700        0.351400             0.152000         0.2397   \n",
      "568           0.04362        0.000000             0.000000         0.1587   \n",
      "\n",
      "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "5                   0.07613  ...          23.75           103.40       741.6   \n",
      "6                   0.05742  ...          27.66           153.20      1606.0   \n",
      "7                   0.07451  ...          28.14           110.60       897.0   \n",
      "8                   0.07389  ...          30.73           106.20       739.3   \n",
      "9                   0.08243  ...          40.68            97.65       711.4   \n",
      "10                  0.05697  ...          33.88           123.80      1150.0   \n",
      "11                  0.06082  ...          27.28           136.50      1299.0   \n",
      "12                  0.07800  ...          29.94           151.70      1332.0   \n",
      "13                  0.05338  ...          27.66           112.00       876.5   \n",
      "14                  0.07682  ...          32.01           108.80       697.7   \n",
      "15                  0.07077  ...          37.13           124.10       943.2   \n",
      "16                  0.05922  ...          30.88           123.40      1138.0   \n",
      "17                  0.07356  ...          31.48           136.80      1315.0   \n",
      "18                  0.05395  ...          30.88           186.80      2398.0   \n",
      "19                  0.05766  ...          19.26            99.70       711.2   \n",
      "20                  0.06811  ...          20.49            96.09       630.5   \n",
      "21                  0.06905  ...          15.66            65.13       314.9   \n",
      "22                  0.07032  ...          19.08           125.10       980.9   \n",
      "23                  0.05278  ...          35.59           188.00      2615.0   \n",
      "24                  0.06330  ...          31.56           177.00      2215.0   \n",
      "25                  0.07413  ...          21.40           152.40      1461.0   \n",
      "26                  0.06924  ...          33.21           122.40       896.9   \n",
      "27                  0.05699  ...          27.26           139.90      1403.0   \n",
      "28                  0.06540  ...          36.71           149.30      1269.0   \n",
      "29                  0.06149  ...          19.52           134.90      1227.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "539                 0.07751  ...          31.89            54.49       223.6   \n",
      "540                 0.06782  ...          19.68            78.78       457.8   \n",
      "541                 0.06341  ...          31.73           113.50       808.9   \n",
      "542                 0.05680  ...          32.29           107.40       826.4   \n",
      "543                 0.05781  ...          37.17            92.48       629.6   \n",
      "544                 0.06688  ...          24.75            99.17       688.6   \n",
      "545                 0.05801  ...          29.09            97.58       729.8   \n",
      "546                 0.06201  ...          21.77            71.12       384.9   \n",
      "547                 0.06714  ...          22.04            71.08       357.4   \n",
      "548                 0.06235  ...          25.59            69.10       364.2   \n",
      "549                 0.06328  ...          31.45            83.90       505.6   \n",
      "550                 0.05948  ...          24.77            74.08       412.3   \n",
      "551                 0.06552  ...          28.26            77.80       436.6   \n",
      "552                 0.05637  ...          36.00            88.10       594.7   \n",
      "553                 0.06576  ...          25.05            62.86       295.8   \n",
      "554                 0.05708  ...          35.74            88.84       595.7   \n",
      "555                 0.06127  ...          34.91            69.57       357.6   \n",
      "556                 0.06331  ...          22.88            67.88       347.3   \n",
      "557                 0.06059  ...          34.24            66.50       330.6   \n",
      "558                 0.06147  ...          27.27           105.90       733.5   \n",
      "559                 0.06570  ...          37.16            82.28       474.2   \n",
      "560                 0.06171  ...          33.17           100.20       706.7   \n",
      "561                 0.05502  ...          38.30            75.19       439.6   \n",
      "562                 0.07152  ...          42.79           128.70       915.0   \n",
      "563                 0.06879  ...          29.41           179.10      1819.0   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0             0.16220            0.66560          0.71190   \n",
      "1             0.12380            0.18660          0.24160   \n",
      "2             0.14440            0.42450          0.45040   \n",
      "3             0.20980            0.86630          0.68690   \n",
      "4             0.13740            0.20500          0.40000   \n",
      "5             0.17910            0.52490          0.53550   \n",
      "6             0.14420            0.25760          0.37840   \n",
      "7             0.16540            0.36820          0.26780   \n",
      "8             0.17030            0.54010          0.53900   \n",
      "9             0.18530            1.05800          1.10500   \n",
      "10            0.11810            0.15510          0.14590   \n",
      "11            0.13960            0.56090          0.39650   \n",
      "12            0.10370            0.39030          0.36390   \n",
      "13            0.11310            0.19240          0.23220   \n",
      "14            0.16510            0.77250          0.69430   \n",
      "15            0.16780            0.65770          0.70260   \n",
      "16            0.14640            0.18710          0.29140   \n",
      "17            0.17890            0.42330          0.47840   \n",
      "18            0.15120            0.31500          0.53720   \n",
      "19            0.14400            0.17730          0.23900   \n",
      "20            0.13120            0.27760          0.18900   \n",
      "21            0.13240            0.11480          0.08867   \n",
      "22            0.13900            0.59540          0.63050   \n",
      "23            0.14010            0.26000          0.31550   \n",
      "24            0.18050            0.35780          0.46950   \n",
      "25            0.15450            0.39490          0.38530   \n",
      "26            0.15250            0.66430          0.55390   \n",
      "27            0.13380            0.21170          0.34460   \n",
      "28            0.16410            0.61100          0.63350   \n",
      "29            0.12550            0.28120          0.24890   \n",
      "..                ...                ...              ...   \n",
      "539           0.15960            0.30640          0.33930   \n",
      "540           0.13450            0.21180          0.17970   \n",
      "541           0.13400            0.42020          0.40400   \n",
      "542           0.10600            0.13760          0.16110   \n",
      "543           0.10720            0.13810          0.10620   \n",
      "544           0.12640            0.20370          0.13770   \n",
      "545           0.12160            0.15170          0.10490   \n",
      "546           0.12850            0.08842          0.04384   \n",
      "547           0.14610            0.22460          0.17830   \n",
      "548           0.11990            0.09546          0.09350   \n",
      "549           0.12040            0.16330          0.06194   \n",
      "550           0.10010            0.07348          0.00000   \n",
      "551           0.10870            0.17820          0.15640   \n",
      "552           0.12340            0.10640          0.08653   \n",
      "553           0.11030            0.08298          0.07993   \n",
      "554           0.12270            0.16200          0.24390   \n",
      "555           0.13840            0.17100          0.20000   \n",
      "556           0.12650            0.12000          0.01005   \n",
      "557           0.10730            0.07158          0.00000   \n",
      "558           0.10260            0.31710          0.36620   \n",
      "559           0.12980            0.25170          0.36300   \n",
      "560           0.12410            0.22640          0.13260   \n",
      "561           0.09267            0.05494          0.00000   \n",
      "562           0.14170            0.79170          1.17000   \n",
      "563           0.14070            0.41860          0.65990   \n",
      "564           0.14100            0.21130          0.41070   \n",
      "565           0.11660            0.19220          0.32150   \n",
      "566           0.11390            0.30940          0.34030   \n",
      "567           0.16500            0.86810          0.93870   \n",
      "568           0.08996            0.06444          0.00000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
      "0                 0.26540          0.4601                  0.11890          0  \n",
      "1                 0.18600          0.2750                  0.08902          0  \n",
      "2                 0.24300          0.3613                  0.08758          0  \n",
      "3                 0.25750          0.6638                  0.17300          0  \n",
      "4                 0.16250          0.2364                  0.07678          0  \n",
      "5                 0.17410          0.3985                  0.12440          0  \n",
      "6                 0.19320          0.3063                  0.08368          0  \n",
      "7                 0.15560          0.3196                  0.11510          0  \n",
      "8                 0.20600          0.4378                  0.10720          0  \n",
      "9                 0.22100          0.4366                  0.20750          0  \n",
      "10                0.09975          0.2948                  0.08452          0  \n",
      "11                0.18100          0.3792                  0.10480          0  \n",
      "12                0.17670          0.3176                  0.10230          0  \n",
      "13                0.11190          0.2809                  0.06287          0  \n",
      "14                0.22080          0.3596                  0.14310          0  \n",
      "15                0.17120          0.4218                  0.13410          0  \n",
      "16                0.16090          0.3029                  0.08216          0  \n",
      "17                0.20730          0.3706                  0.11420          0  \n",
      "18                0.23880          0.2768                  0.07615          0  \n",
      "19                0.12880          0.2977                  0.07259          1  \n",
      "20                0.07283          0.3184                  0.08183          1  \n",
      "21                0.06227          0.2450                  0.07773          1  \n",
      "22                0.23930          0.4667                  0.09946          0  \n",
      "23                0.20090          0.2822                  0.07526          0  \n",
      "24                0.20950          0.3613                  0.09564          0  \n",
      "25                0.25500          0.4066                  0.10590          0  \n",
      "26                0.27010          0.4264                  0.12750          0  \n",
      "27                0.14900          0.2341                  0.07421          0  \n",
      "28                0.20240          0.4027                  0.09876          0  \n",
      "29                0.14560          0.2756                  0.07919          0  \n",
      "..                    ...             ...                      ...        ...  \n",
      "539               0.05000          0.2790                  0.10660          1  \n",
      "540               0.06918          0.2329                  0.08134          1  \n",
      "541               0.12050          0.3187                  0.10230          1  \n",
      "542               0.10950          0.2722                  0.06956          1  \n",
      "543               0.07958          0.2473                  0.06443          1  \n",
      "544               0.06845          0.2249                  0.08492          1  \n",
      "545               0.07174          0.2642                  0.06953          1  \n",
      "546               0.02381          0.2681                  0.07399          1  \n",
      "547               0.08333          0.2691                  0.09479          1  \n",
      "548               0.03846          0.2552                  0.07920          1  \n",
      "549               0.03264          0.3059                  0.07626          1  \n",
      "550               0.00000          0.2458                  0.06592          1  \n",
      "551               0.06413          0.3169                  0.08032          1  \n",
      "552               0.06498          0.2407                  0.06484          1  \n",
      "553               0.02564          0.2435                  0.07393          1  \n",
      "554               0.06493          0.2372                  0.07242          1  \n",
      "555               0.09127          0.2226                  0.08283          1  \n",
      "556               0.02232          0.2262                  0.06742          1  \n",
      "557               0.00000          0.2475                  0.06969          1  \n",
      "558               0.11050          0.2258                  0.08004          1  \n",
      "559               0.09653          0.2112                  0.08732          1  \n",
      "560               0.10480          0.2250                  0.08321          1  \n",
      "561               0.00000          0.1566                  0.05905          1  \n",
      "562               0.23560          0.4089                  0.14090          0  \n",
      "563               0.25420          0.2929                  0.09873          0  \n",
      "564               0.22160          0.2060                  0.07115          0  \n",
      "565               0.16280          0.2572                  0.06637          0  \n",
      "566               0.14180          0.2218                  0.07820          0  \n",
      "567               0.26500          0.4087                  0.12400          0  \n",
      "568               0.00000          0.2871                  0.07039          1  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'breast-cancer-wisconsin-data\\data.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "prep = BC_binary_prep()\n",
    "\n",
    "\n",
    "#composed = transforms.Compose([prep,prepyj])\n",
    "data = prep(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutualInformationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "    def __init__(self, csv_file, encoder):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # shuffle the data\n",
    "        self.data= self.data.sample(frac=1)\n",
    "        \n",
    "        self.model = encoder\n",
    "        self.model.evalmode_()\n",
    "        self.BCprep = BC_binary_prep()\n",
    "        self.BC_dataset = GenericDataset('breast-cancer-wisconsin-data\\data.csv', transform=None, preprocessing = self.BCprep)\n",
    "        \n",
    "        dataset = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sample = self.BC_dataset[0]\n",
    "            X, label = sample['X'], sample['label']\n",
    "            self.Xs = torch.unsqueeze(X,0)\n",
    "            self.Ys = torch.unsqueeze(label,0)\n",
    "            print(0, self.Xs)\n",
    "            output = self.model(X)\n",
    "            dataset = [self.model.device._state]\n",
    "            for j in range(1,len(self.BC_dataset)):\n",
    "                sample = self.BC_dataset[j]\n",
    "                X, label = sample['X'], sample['label']\n",
    "                self.Xs = torch.cat((self.Xs,torch.unsqueeze(X,0)),0)\n",
    "                self.Ys = torch.cat((self.Ys,torch.unsqueeze(label,0)),0)\n",
    "                output = self.model(X)\n",
    "                dataset += [self.model.device._state]\n",
    "\n",
    "            dataset = np.array(dataset)\n",
    "            dataset2 = dataset.view(np.float64)\n",
    "            self.data_encoded = dataset2.reshape(dataset.shape + (2,))\n",
    "\n",
    "        \n",
    "        self.data_encoded = torch.tensor(self.data_encoded)\n",
    "        self.nfeatures = self.Xs.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(type(idx))\n",
    "\n",
    "        X = (self.Xs[idx]).float()\n",
    "\n",
    "        \n",
    "        Y = (self.data_encoded[idx]).float()\n",
    "\n",
    "        sample = {'X': X, 'encoded': Y}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def get_nfeatures(self,):\n",
    "        sample = self[0]\n",
    "        X = sample['X']\n",
    "        return(len(X[0]))\n",
    "    \n",
    "    def get_nencodedfeatures(self,):\n",
    "        sample = self[0]\n",
    "        X = sample['encoded']\n",
    "        return(X[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BC_mutual_inf(object):\n",
    "    def __init__(self, encoder):\n",
    "        super(BC_binary_prep, self).__init__()\n",
    "        self.model = encoder\n",
    "        self.model.evalmode_()\n",
    "        self.BCprep = BC_binary_prep\n",
    "        full_dataset = GenericDataset('breast-cancer-wisconsin-data\\data.csv', transform=None, preprocessing = self.BCprep)\n",
    "        \n",
    "    def __call__(self, data): #data is in panda format\n",
    "        yu\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        data = data.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "        cols = data.columns.tolist()\n",
    "        cols = cols[1:] + [cols[0]]\n",
    "        data = data[cols]\n",
    "        data['diagnosis'].loc[data['diagnosis'] == 'M'] = 0\n",
    "        data['diagnosis'].loc[data['diagnosis'] == 'B'] = 1\n",
    "        #data = pd.DataFrame(data.as_matrix(), columns=['SepalLengthCm'  ,'SepalWidthCm','PetalLengthCm','PetalWidthCm', 'Species'])\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[1.2360e+01, 2.1800e+01, 7.9780e+01, 4.6610e+02, 8.7720e-02, 9.4450e-02,\n",
      "         6.0150e-02, 3.7450e-02, 1.9300e-01, 6.4040e-02, 2.9780e-01, 1.5020e+00,\n",
      "         2.2030e+00, 2.0950e+01, 7.1120e-03, 2.4930e-02, 2.7030e-02, 1.2930e-02,\n",
      "         1.9580e-02, 4.4630e-03, 1.3830e+01, 3.0500e+01, 9.1460e+01, 5.7470e+02,\n",
      "         1.3040e-01, 2.4630e-01, 2.4340e-01, 1.2050e-01, 2.9720e-01, 9.2610e-02]])\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'breast-cancer-wisconsin-data\\data.csv'\n",
    "prep = BC_binary_prep()\n",
    "model = torch.load('modelBC_w3b_1model_id')\n",
    "mi_dataset = MutualInformationDataset(csv_file, encoder = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 30])\n",
      "torch.Size([569, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(mi_dataset.Xs.size())\n",
    "print(mi_dataset.data_encoded.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(mi_dataset))\n",
    "test_size = len(mi_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(mi_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight Parameter containing:\n",
      "tensor([[-0.0500,  0.0912, -0.1187, -0.0309,  0.1777, -0.0115,  0.0180, -0.1582,\n",
      "         -0.1862,  0.1353, -0.0552,  0.0630, -0.1892,  0.2055,  0.1882, -0.1648],\n",
      "        [-0.1764, -0.0089,  0.1547, -0.1447,  0.0342,  0.0151,  0.1883,  0.1390,\n",
      "         -0.1999,  0.0581,  0.1220,  0.1904,  0.1220, -0.1073,  0.1563, -0.1960],\n",
      "        [-0.1417, -0.0063, -0.1107, -0.0322, -0.0681,  0.1631,  0.1157,  0.0494,\n",
      "         -0.1919, -0.1285,  0.1970,  0.2469, -0.2225, -0.0700, -0.0204,  0.0676],\n",
      "        [-0.0484, -0.0025,  0.1645, -0.0326, -0.1280,  0.1416, -0.1558, -0.1153,\n",
      "          0.2386, -0.1785, -0.1691, -0.0895, -0.1691, -0.1071, -0.1578, -0.0251],\n",
      "        [-0.0942, -0.2408,  0.1548, -0.0538,  0.1633,  0.0648,  0.0029, -0.1827,\n",
      "          0.1817, -0.0664,  0.1003,  0.2413,  0.0598, -0.0583,  0.0844,  0.2260],\n",
      "        [ 0.2233, -0.1832,  0.1117,  0.0017, -0.0458,  0.0886,  0.2257, -0.2344,\n",
      "          0.2245,  0.0190, -0.0781, -0.0947, -0.0152, -0.2259, -0.0255,  0.1452],\n",
      "        [-0.2110,  0.0753,  0.2011,  0.1938, -0.1124, -0.0545, -0.0751,  0.0538,\n",
      "          0.1920,  0.2422,  0.2011, -0.0926, -0.1248,  0.2040, -0.1382, -0.0704],\n",
      "        [-0.2022,  0.0306,  0.1180, -0.0151, -0.1055, -0.2071, -0.1802,  0.1136,\n",
      "          0.1305,  0.0414, -0.1572,  0.0943, -0.1090, -0.0530, -0.0628,  0.0607],\n",
      "        [-0.1960,  0.1742,  0.2092,  0.2304, -0.1221, -0.1498, -0.0428,  0.2043,\n",
      "          0.1077,  0.1530,  0.2003,  0.0082,  0.0626, -0.1208,  0.0671, -0.1451],\n",
      "        [-0.0365,  0.0697,  0.2421,  0.1729, -0.0200,  0.0021, -0.0621,  0.1398,\n",
      "          0.1247, -0.2173, -0.1800,  0.1254,  0.2457, -0.2143, -0.0327,  0.0845],\n",
      "        [ 0.0967,  0.1277, -0.2101, -0.0489,  0.1957,  0.0529,  0.0830, -0.1051,\n",
      "          0.1170,  0.1642,  0.1482,  0.1291,  0.1331, -0.1048, -0.0967,  0.1313],\n",
      "        [ 0.0514,  0.1366,  0.1799, -0.0965,  0.0911,  0.0877,  0.0548, -0.1256,\n",
      "         -0.0282,  0.1427,  0.0123, -0.1309, -0.1752,  0.0057, -0.2398, -0.1215],\n",
      "        [-0.0888, -0.1206,  0.0377,  0.1900,  0.1138,  0.2046, -0.2017, -0.1009,\n",
      "         -0.1165, -0.2146, -0.1345,  0.0902, -0.0879,  0.1023,  0.0755,  0.0728],\n",
      "        [ 0.2429,  0.0274, -0.0163,  0.1083,  0.0235,  0.0233,  0.0033,  0.1437,\n",
      "          0.1560, -0.1581, -0.0116, -0.1624, -0.1715,  0.0325,  0.2155, -0.0915],\n",
      "        [-0.0582,  0.1894, -0.0548,  0.2131, -0.2148, -0.0347, -0.2438, -0.0679,\n",
      "          0.1543,  0.1261,  0.0293, -0.0227, -0.0846,  0.2369, -0.1462, -0.1793],\n",
      "        [-0.2353, -0.1989, -0.0520, -0.1084, -0.1411,  0.1356, -0.0224, -0.2091,\n",
      "          0.1388, -0.0155,  0.0805,  0.0086,  0.0627, -0.2194,  0.1286,  0.0144],\n",
      "        [ 0.0243,  0.2127, -0.2332,  0.2170, -0.0328, -0.2466, -0.1603, -0.0163,\n",
      "         -0.0185,  0.1189,  0.1156,  0.2208, -0.1119, -0.0743, -0.0414,  0.1260],\n",
      "        [ 0.0132,  0.1554, -0.0083,  0.1960,  0.1106,  0.1116, -0.0234, -0.1718,\n",
      "          0.2219, -0.1267, -0.0303,  0.0126,  0.0310,  0.2054,  0.1982, -0.2314],\n",
      "        [-0.1838, -0.1175, -0.0819,  0.1483, -0.0915,  0.0198,  0.0915, -0.0591,\n",
      "          0.1691, -0.0189,  0.1182,  0.0743, -0.1473,  0.0653,  0.1944,  0.0068],\n",
      "        [-0.1566,  0.1662,  0.1177,  0.2274, -0.1105,  0.0583,  0.1447, -0.0665,\n",
      "          0.0169,  0.1410, -0.0939,  0.0710, -0.0753, -0.1432,  0.2059,  0.0117],\n",
      "        [ 0.0758, -0.1493,  0.1462, -0.1601,  0.1260, -0.1095, -0.0453, -0.1293,\n",
      "         -0.2095, -0.0878, -0.0483,  0.0278,  0.1087,  0.1267, -0.1898, -0.0528],\n",
      "        [ 0.1225,  0.1404, -0.0717,  0.0150, -0.0620, -0.0990,  0.0450,  0.0972,\n",
      "         -0.2106, -0.0337,  0.0091, -0.2144, -0.1814,  0.1579,  0.0920, -0.2427],\n",
      "        [ 0.2377,  0.0987,  0.0462,  0.0359,  0.0206, -0.1809,  0.1166, -0.0485,\n",
      "         -0.0014,  0.0367,  0.1811, -0.2273, -0.0410,  0.1076,  0.2319,  0.1980],\n",
      "        [-0.1421,  0.1495,  0.2287, -0.2182, -0.0121, -0.0626,  0.0764, -0.0331,\n",
      "         -0.2465, -0.1212,  0.0728, -0.0821,  0.0708,  0.0108, -0.0718,  0.1124],\n",
      "        [ 0.2312,  0.2155, -0.0460, -0.0468,  0.1812,  0.1285,  0.1160,  0.1188,\n",
      "          0.0843,  0.1078,  0.0794, -0.1887, -0.0966, -0.1338, -0.1807,  0.1087],\n",
      "        [-0.2267, -0.0687,  0.1966,  0.1389, -0.1840,  0.0126, -0.0201, -0.0719,\n",
      "         -0.0518,  0.0528, -0.1653, -0.0172, -0.0240,  0.1904, -0.0802,  0.0597],\n",
      "        [-0.1512,  0.1136,  0.1935, -0.0555,  0.2077,  0.2211,  0.0668,  0.0222,\n",
      "          0.2282, -0.2426,  0.0700, -0.0985, -0.0697,  0.1434,  0.1922, -0.1384],\n",
      "        [ 0.0388, -0.2286, -0.1412,  0.1741,  0.2462, -0.1836, -0.0519,  0.1577,\n",
      "          0.1732,  0.0717, -0.2224,  0.1984, -0.2022,  0.0923,  0.1969, -0.1014],\n",
      "        [ 0.1207,  0.0876, -0.1141,  0.2317,  0.0974, -0.1885,  0.0596, -0.2479,\n",
      "         -0.1338,  0.0122, -0.0497,  0.1246,  0.2239,  0.1155, -0.1500, -0.1904],\n",
      "        [ 0.0142, -0.1441,  0.0444,  0.1647,  0.1256, -0.1247,  0.1702, -0.2176,\n",
      "          0.1625,  0.1489, -0.2294,  0.0718,  0.1167, -0.2377, -0.2401,  0.1276],\n",
      "        [-0.1484,  0.0455, -0.2248,  0.1736,  0.0458,  0.0491,  0.1009, -0.1772,\n",
      "         -0.0691,  0.1090, -0.1008, -0.0839,  0.2153,  0.1088,  0.1649,  0.0958],\n",
      "        [ 0.1886,  0.1049,  0.2410, -0.0264,  0.0251, -0.2093, -0.2199, -0.1928,\n",
      "         -0.0908, -0.1880, -0.1059, -0.1647,  0.1423, -0.1852,  0.1300,  0.2235]],\n",
      "       requires_grad=True)\n",
      "0.bias Parameter containing:\n",
      "tensor([-0.0368, -0.1886, -0.0591,  0.0395,  0.0132, -0.1785, -0.1887,  0.2025,\n",
      "        -0.0187, -0.1363,  0.1158,  0.0087, -0.2075,  0.1946, -0.1267,  0.2360,\n",
      "         0.1689,  0.1797,  0.0521,  0.1612, -0.1667,  0.2240,  0.2133,  0.2405,\n",
      "         0.0390, -0.1426,  0.0333,  0.1385,  0.2139,  0.1390,  0.1582, -0.1242],\n",
      "       requires_grad=True)\n",
      "3.weight Parameter containing:\n",
      "tensor([[ 0.1736,  0.1017, -0.1157,  ...,  0.0578, -0.0937,  0.0247],\n",
      "        [-0.0618, -0.1559,  0.1490,  ...,  0.1184,  0.1609,  0.1065],\n",
      "        [-0.1176,  0.0499,  0.0746,  ...,  0.0495, -0.1733,  0.0035],\n",
      "        ...,\n",
      "        [ 0.0400,  0.1369, -0.0947,  ...,  0.1626, -0.1338,  0.0893],\n",
      "        [-0.0836, -0.0722, -0.1572,  ..., -0.0585, -0.0758, -0.1617],\n",
      "        [-0.1490,  0.0022, -0.1257,  ..., -0.0947,  0.0209, -0.1331]],\n",
      "       requires_grad=True)\n",
      "3.bias Parameter containing:\n",
      "tensor([-0.0380,  0.0310, -0.1456, -0.1401, -0.0393, -0.0514,  0.0306,  0.0701,\n",
      "         0.0847, -0.0697, -0.1314,  0.1639, -0.1701, -0.0944, -0.1434,  0.0512,\n",
      "         0.0457,  0.0367,  0.0637,  0.1563, -0.0763,  0.1147, -0.1460, -0.0542,\n",
      "         0.0702,  0.0742, -0.1582, -0.0006,  0.0826, -0.0206,  0.1419, -0.0629,\n",
      "        -0.0886,  0.0075, -0.1707,  0.0608,  0.0914,  0.0970,  0.1416,  0.0222,\n",
      "        -0.1508,  0.1021, -0.1670,  0.0096, -0.0773, -0.0948, -0.0922, -0.0590,\n",
      "        -0.0983, -0.1198,  0.0109, -0.0478, -0.0948,  0.0115,  0.1748,  0.0100,\n",
      "         0.0819,  0.0262, -0.0809,  0.1196, -0.1319,  0.0784, -0.1598,  0.1025],\n",
      "       requires_grad=True)\n",
      "5.weight Parameter containing:\n",
      "tensor([[-0.0324, -0.0936, -0.0888,  ...,  0.0377, -0.0004,  0.0293],\n",
      "        [ 0.0522,  0.0070,  0.1129,  ...,  0.0851,  0.1146,  0.0076],\n",
      "        [ 0.1051,  0.0005,  0.0725,  ...,  0.1224,  0.0361,  0.0661],\n",
      "        ...,\n",
      "        [-0.0516, -0.0343, -0.1211,  ..., -0.0109,  0.0063, -0.0466],\n",
      "        [ 0.1193, -0.0061,  0.0345,  ..., -0.1145,  0.0333, -0.1017],\n",
      "        [-0.1226,  0.0879,  0.1123,  ..., -0.0916,  0.0190,  0.0383]],\n",
      "       requires_grad=True)\n",
      "5.bias Parameter containing:\n",
      "tensor([-0.0654, -0.1023,  0.1167, -0.0559,  0.1135, -0.0619, -0.0065, -0.0043,\n",
      "         0.0748,  0.0666, -0.0388, -0.0700,  0.0093,  0.0907,  0.0214,  0.0128,\n",
      "         0.0189,  0.0323, -0.0680, -0.0809, -0.0203,  0.0021, -0.0964,  0.0346,\n",
      "        -0.1142,  0.0313, -0.1049, -0.0587,  0.0780,  0.0402],\n",
      "       requires_grad=True)\n",
      "epoch [1/1000], train loss:44448.0565, valid loss:33305.0946\n",
      "epoch [2/1000], train loss:29392.3023, valid loss:22921.9172\n",
      "epoch [3/1000], train loss:21741.2819, valid loss:17855.0210\n",
      "epoch [4/1000], train loss:18092.3647, valid loss:15559.7483\n",
      "epoch [5/1000], train loss:16478.5141, valid loss:13861.5389\n",
      "epoch [6/1000], train loss:13969.4018, valid loss:11140.9354\n",
      "epoch [7/1000], train loss:11918.7365, valid loss:9451.7147\n",
      "epoch [8/1000], train loss:10656.0362, valid loss:8197.2373\n",
      "epoch [9/1000], train loss:9581.4075, valid loss:7223.5603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [10/1000], train loss:8903.8795, valid loss:6394.6403\n",
      "epoch [11/1000], train loss:8198.8532, valid loss:5728.8659\n",
      "epoch [12/1000], train loss:7610.5964, valid loss:5158.2079\n",
      "epoch [13/1000], train loss:7051.4638, valid loss:4864.5659\n",
      "epoch [14/1000], train loss:7190.5383, valid loss:4687.0259\n",
      "epoch [15/1000], train loss:6340.6062, valid loss:4186.2705\n",
      "epoch [16/1000], train loss:6219.5168, valid loss:4129.3933\n",
      "epoch [17/1000], train loss:5857.5021, valid loss:4173.3826\n",
      "epoch [18/1000], train loss:5730.9085, valid loss:3769.1588\n",
      "epoch [19/1000], train loss:5629.1095, valid loss:3828.7214\n",
      "epoch [20/1000], train loss:5397.7178, valid loss:3815.4924\n",
      "epoch [21/1000], train loss:5138.3501, valid loss:4201.0272\n",
      "epoch [22/1000], train loss:5274.1704, valid loss:3755.4413\n",
      "epoch [23/1000], train loss:4915.8506, valid loss:3634.5304\n",
      "epoch [24/1000], train loss:4849.6845, valid loss:3969.9399\n",
      "epoch [25/1000], train loss:4458.4244, valid loss:3672.3458\n",
      "epoch [26/1000], train loss:4693.7869, valid loss:3941.6482\n",
      "epoch [27/1000], train loss:4701.1602, valid loss:3602.5953\n",
      "epoch [28/1000], train loss:4608.6255, valid loss:3947.3362\n",
      "epoch [29/1000], train loss:4727.1263, valid loss:3642.6067\n",
      "epoch [30/1000], train loss:4699.9233, valid loss:3626.6054\n",
      "epoch [31/1000], train loss:4462.4817, valid loss:4022.1921\n",
      "epoch [32/1000], train loss:4674.4741, valid loss:3784.2059\n",
      "epoch [33/1000], train loss:4391.6604, valid loss:3701.2040\n",
      "epoch [34/1000], train loss:4405.4357, valid loss:3932.5136\n",
      "epoch [35/1000], train loss:4730.9164, valid loss:3822.2887\n",
      "epoch [36/1000], train loss:4288.2332, valid loss:3853.0189\n",
      "epoch [37/1000], train loss:4524.8375, valid loss:4075.7563\n",
      "epoch [38/1000], train loss:4688.7496, valid loss:3993.3155\n",
      "epoch [39/1000], train loss:4485.8641, valid loss:3505.5847\n",
      "epoch [40/1000], train loss:4598.0651, valid loss:3903.9907\n",
      "epoch [41/1000], train loss:4226.9665, valid loss:3878.4107\n",
      "epoch [42/1000], train loss:4041.0223, valid loss:3545.4191\n",
      "epoch [43/1000], train loss:4363.5580, valid loss:4184.5682\n",
      "epoch [44/1000], train loss:4355.9539, valid loss:3467.1383\n",
      "epoch [45/1000], train loss:4366.3814, valid loss:3731.7057\n",
      "epoch [46/1000], train loss:4134.2714, valid loss:4106.5753\n",
      "epoch [47/1000], train loss:4084.9114, valid loss:3848.8395\n",
      "epoch [48/1000], train loss:4384.1862, valid loss:3587.8818\n",
      "epoch [49/1000], train loss:4370.5310, valid loss:3205.4599\n",
      "epoch [50/1000], train loss:4269.1631, valid loss:3581.7279\n",
      "epoch [51/1000], train loss:3989.9581, valid loss:3395.2191\n",
      "epoch [52/1000], train loss:4325.8237, valid loss:3920.7461\n",
      "epoch [53/1000], train loss:4175.0490, valid loss:3934.5403\n",
      "epoch [54/1000], train loss:4158.4041, valid loss:3627.2620\n",
      "epoch [55/1000], train loss:4364.4479, valid loss:3643.1026\n",
      "epoch [56/1000], train loss:4332.6538, valid loss:3707.8015\n",
      "epoch [57/1000], train loss:4000.5687, valid loss:3804.1129\n",
      "epoch [58/1000], train loss:4163.9698, valid loss:3811.8615\n",
      "epoch [59/1000], train loss:3969.1624, valid loss:3234.8864\n",
      "epoch [60/1000], train loss:4065.6679, valid loss:3378.1749\n",
      "epoch [61/1000], train loss:4432.5998, valid loss:3845.9449\n",
      "epoch [62/1000], train loss:4294.2423, valid loss:3359.2248\n",
      "epoch [63/1000], train loss:4335.8106, valid loss:3617.3198\n",
      "epoch [64/1000], train loss:4143.8073, valid loss:3840.2823\n",
      "epoch [65/1000], train loss:4044.0219, valid loss:3605.7542\n",
      "epoch [66/1000], train loss:4145.8937, valid loss:3694.5477\n",
      "epoch [67/1000], train loss:4071.4393, valid loss:3699.3119\n",
      "epoch [68/1000], train loss:4197.0147, valid loss:3161.5570\n",
      "epoch [69/1000], train loss:4192.3569, valid loss:3421.2183\n",
      "epoch [70/1000], train loss:4207.2258, valid loss:3084.5924\n",
      "epoch [71/1000], train loss:4142.5420, valid loss:3155.6526\n",
      "epoch [72/1000], train loss:4458.2710, valid loss:3355.1727\n",
      "epoch [73/1000], train loss:3967.0441, valid loss:3282.7861\n",
      "epoch [74/1000], train loss:3887.0992, valid loss:3387.2114\n",
      "epoch [75/1000], train loss:3900.3277, valid loss:4160.5381\n",
      "epoch [76/1000], train loss:4185.7724, valid loss:3884.3955\n",
      "epoch [77/1000], train loss:4215.6103, valid loss:3935.9530\n",
      "epoch [78/1000], train loss:4113.3119, valid loss:3396.3951\n",
      "epoch [79/1000], train loss:4161.5306, valid loss:3289.2450\n",
      "epoch [80/1000], train loss:4159.6242, valid loss:3268.7127\n",
      "epoch [81/1000], train loss:3882.6543, valid loss:3391.1011\n",
      "epoch [82/1000], train loss:4107.3506, valid loss:3188.2813\n",
      "epoch [83/1000], train loss:3941.6747, valid loss:3108.5297\n",
      "epoch [84/1000], train loss:3776.3519, valid loss:3222.6207\n",
      "epoch [85/1000], train loss:4161.8416, valid loss:3072.6268\n",
      "epoch [86/1000], train loss:4181.9797, valid loss:3021.3725\n",
      "epoch [87/1000], train loss:3916.5042, valid loss:3118.1222\n",
      "epoch [88/1000], train loss:4172.5498, valid loss:2983.6140\n",
      "epoch [89/1000], train loss:3971.6175, valid loss:3343.8264\n",
      "epoch [90/1000], train loss:3692.4191, valid loss:3172.7518\n",
      "epoch [91/1000], train loss:3986.8533, valid loss:3454.1489\n",
      "epoch [92/1000], train loss:4411.5718, valid loss:3344.1199\n",
      "epoch [93/1000], train loss:4170.1435, valid loss:3070.2268\n",
      "epoch [94/1000], train loss:3823.4912, valid loss:3575.4658\n",
      "epoch [95/1000], train loss:3821.3823, valid loss:3598.5344\n",
      "epoch [96/1000], train loss:3802.3809, valid loss:3230.6485\n",
      "epoch [97/1000], train loss:3997.9412, valid loss:3461.7710\n",
      "epoch [98/1000], train loss:4104.1622, valid loss:3366.2214\n",
      "epoch [99/1000], train loss:4453.9273, valid loss:3116.2200\n",
      "epoch [100/1000], train loss:4379.7531, valid loss:3198.5282\n",
      "epoch [101/1000], train loss:3917.6376, valid loss:3351.5241\n",
      "epoch [102/1000], train loss:3931.0341, valid loss:3249.0278\n",
      "epoch [103/1000], train loss:4055.4947, valid loss:3462.5301\n",
      "epoch [104/1000], train loss:3896.3551, valid loss:3131.8815\n",
      "epoch [105/1000], train loss:4097.2331, valid loss:3058.8561\n",
      "epoch [106/1000], train loss:3815.1764, valid loss:3311.5452\n",
      "epoch [107/1000], train loss:4156.1099, valid loss:2986.9900\n",
      "epoch [108/1000], train loss:4158.1317, valid loss:3308.0324\n",
      "epoch [109/1000], train loss:4054.4482, valid loss:3282.4304\n",
      "epoch [110/1000], train loss:3796.8901, valid loss:3342.9195\n",
      "epoch [111/1000], train loss:3962.6486, valid loss:3050.9467\n",
      "epoch [112/1000], train loss:4086.3044, valid loss:3387.8480\n",
      "epoch [113/1000], train loss:3770.6757, valid loss:3105.4965\n",
      "epoch [114/1000], train loss:3502.0483, valid loss:3082.2942\n",
      "epoch [115/1000], train loss:3857.6879, valid loss:2946.6115\n",
      "epoch [116/1000], train loss:3837.9149, valid loss:2886.7236\n",
      "epoch [117/1000], train loss:3854.8064, valid loss:3140.1599\n",
      "epoch [118/1000], train loss:3959.4003, valid loss:2920.4838\n",
      "epoch [119/1000], train loss:4111.2263, valid loss:3638.3409\n",
      "epoch [120/1000], train loss:3979.5172, valid loss:3238.4320\n",
      "epoch [121/1000], train loss:3943.0985, valid loss:3283.4628\n",
      "epoch [122/1000], train loss:4092.9974, valid loss:3300.6184\n",
      "epoch [123/1000], train loss:3890.3220, valid loss:3140.8746\n",
      "epoch [124/1000], train loss:4073.7643, valid loss:3128.3279\n",
      "epoch [125/1000], train loss:3759.4925, valid loss:3590.4886\n",
      "epoch [126/1000], train loss:4152.5080, valid loss:3532.6486\n",
      "epoch [127/1000], train loss:4041.9397, valid loss:3450.1580\n",
      "epoch [128/1000], train loss:3904.8019, valid loss:3001.2778\n",
      "epoch [129/1000], train loss:3713.5613, valid loss:3434.5856\n",
      "epoch [130/1000], train loss:3944.4540, valid loss:3050.4945\n",
      "epoch [131/1000], train loss:4112.8484, valid loss:3077.4254\n",
      "epoch [132/1000], train loss:3849.4358, valid loss:3218.8864\n",
      "epoch [133/1000], train loss:3704.8120, valid loss:2927.2198\n",
      "epoch [134/1000], train loss:3648.7788, valid loss:3402.5108\n",
      "epoch [135/1000], train loss:3860.7179, valid loss:3257.6385\n",
      "epoch [136/1000], train loss:3914.1073, valid loss:3307.0092\n",
      "epoch [137/1000], train loss:4153.0814, valid loss:4139.9232\n",
      "epoch [138/1000], train loss:3629.9859, valid loss:3639.4959\n",
      "epoch [139/1000], train loss:3809.6663, valid loss:3463.5278\n",
      "epoch [140/1000], train loss:3912.3757, valid loss:2960.1032\n",
      "epoch [141/1000], train loss:3921.1296, valid loss:3507.6895\n",
      "epoch [142/1000], train loss:3647.7818, valid loss:3409.0548\n",
      "epoch [143/1000], train loss:4079.9853, valid loss:3143.7452\n",
      "epoch [144/1000], train loss:3723.9362, valid loss:3187.3328\n",
      "epoch [145/1000], train loss:3787.5505, valid loss:2838.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [146/1000], train loss:4292.5620, valid loss:2840.5906\n",
      "epoch [147/1000], train loss:4022.4741, valid loss:3491.4069\n",
      "epoch [148/1000], train loss:3845.1673, valid loss:2859.3882\n",
      "epoch [149/1000], train loss:3876.1277, valid loss:3091.8933\n",
      "epoch [150/1000], train loss:4001.4021, valid loss:2578.2901\n",
      "epoch [151/1000], train loss:4357.7604, valid loss:2948.6475\n",
      "epoch [152/1000], train loss:3812.3555, valid loss:2795.0925\n",
      "epoch [153/1000], train loss:4141.5529, valid loss:2953.3738\n",
      "epoch [154/1000], train loss:4113.5956, valid loss:2827.8985\n",
      "epoch [155/1000], train loss:3978.3352, valid loss:3210.9884\n",
      "epoch [156/1000], train loss:3617.4347, valid loss:3052.5333\n",
      "epoch [157/1000], train loss:4133.8053, valid loss:2932.8008\n",
      "epoch [158/1000], train loss:3595.5890, valid loss:3062.2887\n",
      "epoch [159/1000], train loss:3770.7442, valid loss:3015.2682\n",
      "epoch [160/1000], train loss:3586.9161, valid loss:3346.9662\n",
      "epoch [161/1000], train loss:3578.6384, valid loss:2802.3531\n",
      "epoch [162/1000], train loss:3870.8112, valid loss:3087.9684\n",
      "epoch [163/1000], train loss:3809.5867, valid loss:3466.9437\n",
      "epoch [164/1000], train loss:3637.9428, valid loss:3145.1417\n",
      "epoch [165/1000], train loss:3647.1488, valid loss:3463.3694\n",
      "epoch [166/1000], train loss:3736.0025, valid loss:3507.9789\n",
      "epoch [167/1000], train loss:3740.7449, valid loss:3022.2876\n",
      "epoch [168/1000], train loss:3874.8191, valid loss:3202.4730\n",
      "epoch [169/1000], train loss:3655.4551, valid loss:2997.1133\n",
      "epoch [170/1000], train loss:3839.8370, valid loss:2670.2098\n",
      "epoch [171/1000], train loss:3871.7992, valid loss:2516.1486\n",
      "epoch [172/1000], train loss:3549.9174, valid loss:2830.8734\n",
      "epoch [173/1000], train loss:3731.2198, valid loss:2812.8122\n",
      "epoch [174/1000], train loss:3550.1993, valid loss:2900.3604\n",
      "epoch [175/1000], train loss:4047.8968, valid loss:2918.0720\n",
      "epoch [176/1000], train loss:3799.6911, valid loss:2833.7055\n",
      "epoch [177/1000], train loss:3962.5142, valid loss:3173.9107\n",
      "epoch [178/1000], train loss:3869.0589, valid loss:2637.5323\n",
      "epoch [179/1000], train loss:3866.7982, valid loss:2608.6214\n",
      "epoch [180/1000], train loss:3819.8497, valid loss:2768.2666\n",
      "epoch [181/1000], train loss:3773.7028, valid loss:2701.5541\n",
      "epoch [182/1000], train loss:3900.8911, valid loss:3032.7623\n",
      "epoch [183/1000], train loss:4165.8171, valid loss:2500.0904\n",
      "epoch [184/1000], train loss:3797.9336, valid loss:3018.5854\n",
      "epoch [185/1000], train loss:4081.1265, valid loss:3169.2397\n",
      "epoch [186/1000], train loss:3631.9213, valid loss:2774.8789\n",
      "epoch [187/1000], train loss:3450.3786, valid loss:2560.0277\n",
      "epoch [188/1000], train loss:3760.5223, valid loss:2455.8608\n",
      "epoch [189/1000], train loss:3736.4621, valid loss:2831.1890\n",
      "epoch [190/1000], train loss:3928.3442, valid loss:2845.3834\n",
      "epoch [191/1000], train loss:3836.2344, valid loss:2950.2604\n",
      "epoch [192/1000], train loss:3420.9857, valid loss:2868.1573\n",
      "epoch [193/1000], train loss:3869.0522, valid loss:2651.0931\n",
      "epoch [194/1000], train loss:3721.5910, valid loss:3266.5243\n",
      "epoch [195/1000], train loss:3623.1362, valid loss:2858.9767\n",
      "epoch [196/1000], train loss:3777.7820, valid loss:2646.9444\n",
      "epoch [197/1000], train loss:3828.7865, valid loss:2461.3161\n",
      "epoch [198/1000], train loss:3673.7198, valid loss:2529.6270\n",
      "epoch [199/1000], train loss:4019.6275, valid loss:2659.6091\n",
      "epoch [200/1000], train loss:4106.4504, valid loss:2810.3155\n",
      "epoch [201/1000], train loss:3941.3012, valid loss:3428.9709\n",
      "epoch [202/1000], train loss:3814.6314, valid loss:3262.6366\n",
      "epoch [203/1000], train loss:3715.9806, valid loss:3321.7970\n",
      "epoch [204/1000], train loss:3862.4016, valid loss:3288.8334\n",
      "epoch [205/1000], train loss:3729.4751, valid loss:3068.5888\n",
      "epoch [206/1000], train loss:3779.2152, valid loss:3189.7614\n",
      "epoch [207/1000], train loss:4172.2721, valid loss:3465.1515\n",
      "epoch [208/1000], train loss:3795.9572, valid loss:3525.9260\n",
      "epoch [209/1000], train loss:3814.7086, valid loss:2965.0482\n",
      "epoch [210/1000], train loss:4100.7485, valid loss:2762.7003\n",
      "epoch [211/1000], train loss:3679.0556, valid loss:2640.5285\n",
      "epoch [212/1000], train loss:3628.3531, valid loss:2545.3924\n",
      "epoch [213/1000], train loss:3615.4632, valid loss:2868.0151\n",
      "epoch [214/1000], train loss:3633.4820, valid loss:2934.2448\n",
      "epoch [215/1000], train loss:3507.9250, valid loss:2764.1413\n",
      "epoch [216/1000], train loss:3675.0349, valid loss:2978.7238\n",
      "epoch [217/1000], train loss:3987.6656, valid loss:2979.5563\n",
      "epoch [218/1000], train loss:3673.1350, valid loss:2919.8708\n",
      "epoch [219/1000], train loss:3866.6544, valid loss:2906.9096\n",
      "epoch [220/1000], train loss:3999.6416, valid loss:3097.5227\n",
      "epoch [221/1000], train loss:3595.1414, valid loss:2879.9805\n",
      "epoch [222/1000], train loss:3688.4540, valid loss:2842.1313\n",
      "epoch [223/1000], train loss:3798.4617, valid loss:2917.8718\n",
      "epoch [224/1000], train loss:3452.3398, valid loss:2646.5836\n",
      "epoch [225/1000], train loss:3578.2445, valid loss:2876.6943\n",
      "epoch [226/1000], train loss:3819.0300, valid loss:3079.5892\n",
      "epoch [227/1000], train loss:3717.8495, valid loss:2751.6303\n",
      "epoch [228/1000], train loss:3953.8977, valid loss:2578.1968\n",
      "epoch [229/1000], train loss:3845.5791, valid loss:2968.6087\n",
      "epoch [230/1000], train loss:3605.5985, valid loss:3210.7445\n",
      "epoch [231/1000], train loss:3705.0111, valid loss:2714.0137\n",
      "epoch [232/1000], train loss:3946.4112, valid loss:2893.0313\n",
      "epoch [233/1000], train loss:3731.9865, valid loss:2796.0949\n",
      "epoch [234/1000], train loss:3421.0574, valid loss:2864.4345\n",
      "epoch [235/1000], train loss:4007.2707, valid loss:2914.9554\n",
      "epoch [236/1000], train loss:3818.5605, valid loss:2858.3459\n",
      "epoch [237/1000], train loss:3689.6172, valid loss:2805.3721\n",
      "epoch [238/1000], train loss:3690.3258, valid loss:2833.5535\n",
      "epoch [239/1000], train loss:3420.8784, valid loss:3029.7209\n",
      "epoch [240/1000], train loss:3685.6192, valid loss:3094.0924\n",
      "epoch [241/1000], train loss:3793.2060, valid loss:3209.7894\n",
      "epoch [242/1000], train loss:3366.5649, valid loss:3226.9364\n",
      "epoch [243/1000], train loss:3456.2641, valid loss:2903.8260\n",
      "epoch [244/1000], train loss:3675.8907, valid loss:3040.4608\n",
      "epoch [245/1000], train loss:3722.5833, valid loss:2749.4228\n",
      "epoch [246/1000], train loss:3585.4905, valid loss:2880.0301\n",
      "epoch [247/1000], train loss:3495.0287, valid loss:2807.1168\n",
      "epoch [248/1000], train loss:3209.1198, valid loss:2895.5951\n",
      "epoch [249/1000], train loss:3497.3544, valid loss:3228.1053\n",
      "epoch [250/1000], train loss:3654.7736, valid loss:2868.0950\n",
      "epoch [251/1000], train loss:3657.6956, valid loss:2775.6302\n",
      "epoch [252/1000], train loss:3322.6880, valid loss:2705.2460\n",
      "epoch [253/1000], train loss:3743.4408, valid loss:2786.6499\n",
      "epoch [254/1000], train loss:3737.3338, valid loss:3176.5180\n",
      "epoch [255/1000], train loss:3589.8215, valid loss:2627.4805\n",
      "epoch [256/1000], train loss:3618.9632, valid loss:2555.6026\n",
      "epoch [257/1000], train loss:3966.2036, valid loss:2602.2382\n",
      "epoch [258/1000], train loss:3675.2488, valid loss:2837.7191\n",
      "epoch [259/1000], train loss:3712.9607, valid loss:2600.4004\n",
      "epoch [260/1000], train loss:3430.3691, valid loss:2731.2691\n",
      "epoch [261/1000], train loss:3512.2395, valid loss:2838.9128\n",
      "epoch [262/1000], train loss:3809.3610, valid loss:3240.0150\n",
      "epoch [263/1000], train loss:3592.3980, valid loss:3070.6206\n",
      "epoch [264/1000], train loss:3941.8011, valid loss:3432.5037\n",
      "epoch [265/1000], train loss:3432.3155, valid loss:3073.4467\n",
      "epoch [266/1000], train loss:4002.5256, valid loss:3129.2110\n",
      "epoch [267/1000], train loss:3253.8774, valid loss:3568.4781\n",
      "epoch [268/1000], train loss:3481.9903, valid loss:3475.7504\n",
      "epoch [269/1000], train loss:3680.2351, valid loss:3274.8272\n",
      "epoch [270/1000], train loss:3434.3261, valid loss:3426.0493\n",
      "epoch [271/1000], train loss:3662.0492, valid loss:2967.0192\n",
      "epoch [272/1000], train loss:3387.4814, valid loss:2887.4525\n",
      "epoch [273/1000], train loss:3452.1900, valid loss:2859.4520\n",
      "epoch [274/1000], train loss:3333.9006, valid loss:2881.6527\n",
      "epoch [275/1000], train loss:3725.9556, valid loss:3290.6544\n",
      "epoch [276/1000], train loss:3499.5624, valid loss:3057.5387\n",
      "epoch [277/1000], train loss:3302.7383, valid loss:2627.2390\n",
      "epoch [278/1000], train loss:3652.8270, valid loss:2750.1348\n",
      "epoch [279/1000], train loss:3668.9008, valid loss:2946.3226\n",
      "epoch [280/1000], train loss:3882.2538, valid loss:3159.5923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [281/1000], train loss:3732.5633, valid loss:2992.0113\n",
      "epoch [282/1000], train loss:3594.6030, valid loss:3023.5697\n",
      "epoch [283/1000], train loss:3751.9292, valid loss:3612.7614\n",
      "epoch [284/1000], train loss:3695.9475, valid loss:2903.5553\n",
      "epoch [285/1000], train loss:3462.7111, valid loss:3453.3934\n",
      "epoch [286/1000], train loss:3779.0894, valid loss:3152.0489\n",
      "epoch [287/1000], train loss:3425.7250, valid loss:3353.0390\n",
      "epoch [288/1000], train loss:3663.9695, valid loss:3386.7121\n",
      "epoch [289/1000], train loss:3593.4643, valid loss:3369.3056\n",
      "epoch [290/1000], train loss:3876.6789, valid loss:3002.8013\n",
      "epoch [291/1000], train loss:3716.6565, valid loss:3042.5896\n",
      "epoch [292/1000], train loss:3310.8693, valid loss:3038.8810\n",
      "epoch [293/1000], train loss:3685.3666, valid loss:3331.2993\n",
      "epoch [294/1000], train loss:3417.8898, valid loss:3169.1395\n",
      "epoch [295/1000], train loss:3665.8093, valid loss:2866.2385\n",
      "epoch [296/1000], train loss:3409.5688, valid loss:3034.9033\n",
      "epoch [297/1000], train loss:3639.6408, valid loss:2922.1155\n",
      "epoch [298/1000], train loss:3792.0795, valid loss:3402.4476\n",
      "epoch [299/1000], train loss:3480.3379, valid loss:2902.1035\n",
      "epoch [300/1000], train loss:3323.7405, valid loss:2921.9858\n",
      "epoch [301/1000], train loss:3372.8336, valid loss:2826.0352\n",
      "epoch [302/1000], train loss:3435.4375, valid loss:2855.3704\n",
      "epoch [303/1000], train loss:3575.8435, valid loss:2729.6499\n",
      "epoch [304/1000], train loss:3475.0136, valid loss:2812.7644\n",
      "epoch [305/1000], train loss:3975.2214, valid loss:2966.7165\n",
      "epoch [306/1000], train loss:3632.6134, valid loss:2874.2845\n",
      "epoch [307/1000], train loss:3408.3146, valid loss:2865.8808\n",
      "epoch [308/1000], train loss:3687.8337, valid loss:2899.9122\n",
      "epoch [309/1000], train loss:3329.4668, valid loss:2897.5833\n",
      "epoch [310/1000], train loss:3204.1778, valid loss:2840.7593\n",
      "epoch [311/1000], train loss:3433.9955, valid loss:2936.5806\n",
      "epoch [312/1000], train loss:3382.8940, valid loss:2870.0649\n",
      "epoch [313/1000], train loss:3521.0156, valid loss:2994.9921\n",
      "epoch [314/1000], train loss:3280.6748, valid loss:3080.9604\n",
      "epoch [315/1000], train loss:3456.5831, valid loss:2999.3223\n",
      "epoch [316/1000], train loss:3840.4783, valid loss:3002.5477\n",
      "epoch [317/1000], train loss:3633.4455, valid loss:2808.2647\n",
      "epoch [318/1000], train loss:3749.0900, valid loss:2930.0083\n",
      "epoch [319/1000], train loss:3428.4367, valid loss:2832.5912\n",
      "epoch [320/1000], train loss:3607.4275, valid loss:2818.7088\n",
      "epoch [321/1000], train loss:3421.1657, valid loss:2821.3507\n",
      "epoch [322/1000], train loss:3766.7965, valid loss:3173.6084\n",
      "epoch [323/1000], train loss:3328.7819, valid loss:2880.9160\n",
      "epoch [324/1000], train loss:3319.7901, valid loss:3054.1801\n",
      "epoch [325/1000], train loss:3511.9001, valid loss:2957.6364\n",
      "epoch [326/1000], train loss:3461.6687, valid loss:3212.5269\n",
      "epoch [327/1000], train loss:3522.9625, valid loss:2835.7645\n",
      "epoch [328/1000], train loss:3153.2544, valid loss:2698.2766\n",
      "epoch [329/1000], train loss:3051.1915, valid loss:2710.7640\n",
      "epoch [330/1000], train loss:3498.2843, valid loss:2706.6503\n",
      "epoch [331/1000], train loss:3480.9047, valid loss:3140.9680\n",
      "epoch [332/1000], train loss:3419.6396, valid loss:2833.6037\n",
      "epoch [333/1000], train loss:3546.9596, valid loss:2784.9360\n",
      "epoch [334/1000], train loss:3341.3284, valid loss:2799.4022\n",
      "epoch [335/1000], train loss:3241.5528, valid loss:2770.0024\n",
      "epoch [336/1000], train loss:3195.8504, valid loss:3043.7667\n",
      "epoch [337/1000], train loss:3414.6736, valid loss:2830.0298\n",
      "epoch [338/1000], train loss:3341.7075, valid loss:2850.0833\n",
      "epoch [339/1000], train loss:3007.8581, valid loss:3058.7075\n",
      "epoch [340/1000], train loss:3504.5923, valid loss:2753.9226\n",
      "epoch [341/1000], train loss:3354.0162, valid loss:2733.9461\n",
      "epoch [342/1000], train loss:3447.7176, valid loss:3036.3275\n",
      "epoch [343/1000], train loss:3473.5499, valid loss:3064.3127\n",
      "epoch [344/1000], train loss:3141.5588, valid loss:2683.8986\n",
      "epoch [345/1000], train loss:2854.8647, valid loss:2713.0382\n",
      "epoch [346/1000], train loss:3436.9007, valid loss:2814.5938\n",
      "epoch [347/1000], train loss:3364.9629, valid loss:2846.4658\n",
      "epoch [348/1000], train loss:3344.5047, valid loss:2982.7355\n",
      "epoch [349/1000], train loss:3533.1833, valid loss:3079.6360\n",
      "epoch [350/1000], train loss:3356.1466, valid loss:2850.3325\n",
      "epoch [351/1000], train loss:3172.2072, valid loss:2784.9998\n",
      "epoch [352/1000], train loss:3118.0756, valid loss:2834.5573\n",
      "epoch [353/1000], train loss:3408.0484, valid loss:3054.0124\n",
      "epoch [354/1000], train loss:3154.9019, valid loss:2845.9798\n",
      "epoch [355/1000], train loss:3355.5825, valid loss:3083.2719\n",
      "epoch [356/1000], train loss:3143.0250, valid loss:3044.4489\n",
      "epoch [357/1000], train loss:2935.1664, valid loss:3048.2661\n",
      "epoch [358/1000], train loss:3136.8796, valid loss:3050.6787\n",
      "epoch [359/1000], train loss:3204.2604, valid loss:3020.9487\n",
      "epoch [360/1000], train loss:3207.5696, valid loss:2877.2145\n",
      "epoch [361/1000], train loss:3418.2909, valid loss:2995.6082\n",
      "epoch [362/1000], train loss:3104.3782, valid loss:3158.5969\n",
      "epoch [363/1000], train loss:3570.1897, valid loss:3410.4058\n",
      "epoch [364/1000], train loss:3358.3261, valid loss:2998.7699\n",
      "epoch [365/1000], train loss:3368.3539, valid loss:2815.1000\n",
      "epoch [366/1000], train loss:3518.8479, valid loss:3214.9258\n",
      "epoch [367/1000], train loss:3237.9133, valid loss:3423.0283\n",
      "epoch [368/1000], train loss:3291.3914, valid loss:3343.8908\n",
      "epoch [369/1000], train loss:3360.1253, valid loss:3094.3968\n",
      "epoch [370/1000], train loss:3275.6969, valid loss:3334.2685\n",
      "epoch [371/1000], train loss:3502.5499, valid loss:3061.9386\n",
      "epoch [372/1000], train loss:3406.9186, valid loss:3559.9391\n",
      "epoch [373/1000], train loss:3063.7865, valid loss:3441.2855\n",
      "epoch [374/1000], train loss:3376.4260, valid loss:3283.8602\n",
      "epoch [375/1000], train loss:3413.2477, valid loss:3306.3856\n",
      "epoch [376/1000], train loss:3130.4281, valid loss:3215.7568\n",
      "epoch [377/1000], train loss:3277.5866, valid loss:3137.7187\n",
      "epoch [378/1000], train loss:3911.2316, valid loss:3363.3324\n",
      "epoch [379/1000], train loss:3354.4642, valid loss:3187.4779\n",
      "epoch [380/1000], train loss:3108.0794, valid loss:3235.5106\n",
      "epoch [381/1000], train loss:3395.9441, valid loss:3262.6223\n",
      "epoch [382/1000], train loss:3445.7183, valid loss:3343.5957\n",
      "epoch [383/1000], train loss:3234.7174, valid loss:3446.5762\n",
      "epoch [384/1000], train loss:3281.1522, valid loss:3263.6099\n",
      "epoch [385/1000], train loss:3363.4119, valid loss:3082.7852\n",
      "epoch [386/1000], train loss:2980.6734, valid loss:2624.6154\n",
      "epoch [387/1000], train loss:3476.9616, valid loss:3093.8869\n",
      "epoch [388/1000], train loss:3649.1384, valid loss:3246.9524\n",
      "epoch [389/1000], train loss:3118.5344, valid loss:2847.2083\n",
      "epoch [390/1000], train loss:3734.0121, valid loss:2813.5792\n",
      "epoch [391/1000], train loss:3267.8346, valid loss:3049.9523\n",
      "epoch [392/1000], train loss:3704.1993, valid loss:2911.0422\n",
      "epoch [393/1000], train loss:3681.6473, valid loss:3150.7240\n",
      "epoch [394/1000], train loss:3267.8673, valid loss:2885.6232\n",
      "epoch [395/1000], train loss:3592.9475, valid loss:2886.2161\n",
      "epoch [396/1000], train loss:3177.9633, valid loss:2965.5119\n",
      "epoch [397/1000], train loss:2913.3037, valid loss:3069.3468\n",
      "epoch [398/1000], train loss:2896.7012, valid loss:2810.3173\n",
      "epoch [399/1000], train loss:3144.2020, valid loss:3531.0466\n",
      "epoch [400/1000], train loss:3389.6980, valid loss:3069.8482\n",
      "epoch [401/1000], train loss:3302.9743, valid loss:2935.0613\n",
      "epoch [402/1000], train loss:3359.9916, valid loss:2813.2011\n",
      "epoch [403/1000], train loss:3598.3040, valid loss:2932.0979\n",
      "epoch [404/1000], train loss:3067.3580, valid loss:2960.7926\n",
      "epoch [405/1000], train loss:3197.7537, valid loss:3000.0934\n",
      "epoch [406/1000], train loss:3135.6104, valid loss:2991.4749\n",
      "epoch [407/1000], train loss:3440.7365, valid loss:2949.2262\n",
      "epoch [408/1000], train loss:3267.9354, valid loss:3073.9016\n",
      "epoch [409/1000], train loss:3194.4878, valid loss:3187.8156\n",
      "epoch [410/1000], train loss:3392.0903, valid loss:2923.1467\n",
      "epoch [411/1000], train loss:3499.2124, valid loss:2782.4987\n",
      "epoch [412/1000], train loss:3182.8213, valid loss:2929.8892\n",
      "epoch [413/1000], train loss:3598.6594, valid loss:3106.3586\n",
      "epoch [414/1000], train loss:3661.0690, valid loss:3082.0110\n",
      "epoch [415/1000], train loss:3812.6329, valid loss:3062.6917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [416/1000], train loss:3596.1552, valid loss:3130.7697\n",
      "epoch [417/1000], train loss:3527.0364, valid loss:2961.2962\n",
      "epoch [418/1000], train loss:3735.0082, valid loss:3056.5693\n",
      "epoch [419/1000], train loss:3362.3382, valid loss:3005.2891\n",
      "epoch [420/1000], train loss:3282.9923, valid loss:3072.3264\n",
      "epoch [421/1000], train loss:3311.2715, valid loss:3024.2172\n",
      "epoch [422/1000], train loss:3353.8452, valid loss:3017.0532\n",
      "epoch [423/1000], train loss:3070.1951, valid loss:2933.1364\n",
      "epoch [424/1000], train loss:3550.7026, valid loss:2631.1056\n",
      "epoch [425/1000], train loss:3601.8046, valid loss:3187.5256\n",
      "epoch [426/1000], train loss:3765.6329, valid loss:3159.1256\n",
      "epoch [427/1000], train loss:3539.0227, valid loss:2890.8931\n",
      "epoch [428/1000], train loss:3222.1199, valid loss:3035.8464\n",
      "epoch [429/1000], train loss:3368.7550, valid loss:2978.7659\n",
      "epoch [430/1000], train loss:3288.8934, valid loss:3179.4082\n",
      "epoch [431/1000], train loss:3245.8406, valid loss:3085.0507\n",
      "epoch [432/1000], train loss:3291.7783, valid loss:3165.6487\n",
      "epoch [433/1000], train loss:3307.2303, valid loss:2926.1637\n",
      "epoch [434/1000], train loss:3806.5672, valid loss:2840.7431\n",
      "epoch [435/1000], train loss:3032.3519, valid loss:2922.1951\n",
      "epoch [436/1000], train loss:3261.0145, valid loss:3011.0450\n",
      "epoch [437/1000], train loss:3365.1094, valid loss:2798.9621\n",
      "epoch [438/1000], train loss:3504.5221, valid loss:3072.0427\n",
      "epoch [439/1000], train loss:3383.1453, valid loss:3224.1217\n",
      "epoch [440/1000], train loss:3200.3248, valid loss:3001.7613\n",
      "epoch [441/1000], train loss:3639.2594, valid loss:3171.8327\n",
      "epoch [442/1000], train loss:3417.2201, valid loss:2939.2315\n",
      "epoch [443/1000], train loss:3482.2780, valid loss:3078.7402\n",
      "epoch [444/1000], train loss:3461.6058, valid loss:3027.4981\n",
      "epoch [445/1000], train loss:2998.8492, valid loss:3179.0628\n",
      "epoch [446/1000], train loss:3343.8709, valid loss:2890.2919\n",
      "epoch [447/1000], train loss:3569.5114, valid loss:2766.7125\n",
      "epoch [448/1000], train loss:3206.8106, valid loss:3008.8623\n",
      "epoch [449/1000], train loss:3086.4593, valid loss:3424.2387\n",
      "epoch [450/1000], train loss:3353.6258, valid loss:3265.6117\n",
      "epoch [451/1000], train loss:3515.4874, valid loss:3592.8132\n",
      "epoch [452/1000], train loss:3390.8460, valid loss:3272.6843\n",
      "epoch [453/1000], train loss:3532.9071, valid loss:3046.6865\n",
      "epoch [454/1000], train loss:3263.7514, valid loss:3052.9164\n",
      "epoch [455/1000], train loss:3323.9567, valid loss:3259.9589\n",
      "epoch [456/1000], train loss:3136.6736, valid loss:3058.6736\n",
      "epoch [457/1000], train loss:3490.8862, valid loss:3356.5092\n",
      "epoch [458/1000], train loss:3643.0226, valid loss:3389.1907\n",
      "epoch [459/1000], train loss:3305.6685, valid loss:3293.7368\n",
      "epoch [460/1000], train loss:3462.0745, valid loss:2925.8012\n",
      "epoch [461/1000], train loss:3080.9744, valid loss:3331.5673\n",
      "epoch [462/1000], train loss:3509.8303, valid loss:3060.7111\n",
      "epoch [463/1000], train loss:3177.8616, valid loss:2879.6339\n",
      "epoch [464/1000], train loss:3116.9611, valid loss:3178.1589\n",
      "epoch [465/1000], train loss:3753.2057, valid loss:3092.5316\n",
      "epoch [466/1000], train loss:3167.4033, valid loss:2990.9239\n",
      "epoch [467/1000], train loss:3433.7820, valid loss:2939.7455\n",
      "epoch [468/1000], train loss:3365.7922, valid loss:2822.1859\n",
      "epoch [469/1000], train loss:3357.7995, valid loss:3257.2635\n",
      "epoch [470/1000], train loss:3245.1759, valid loss:2517.7508\n",
      "epoch [471/1000], train loss:3494.0759, valid loss:2764.3808\n",
      "epoch [472/1000], train loss:3201.4237, valid loss:2871.0992\n",
      "epoch [473/1000], train loss:3102.9132, valid loss:2865.1028\n",
      "epoch [474/1000], train loss:3348.7733, valid loss:2933.4795\n",
      "epoch [475/1000], train loss:3881.6817, valid loss:2591.4297\n",
      "epoch [476/1000], train loss:3356.2377, valid loss:2781.6866\n",
      "epoch [477/1000], train loss:3155.8399, valid loss:3224.6320\n",
      "epoch [478/1000], train loss:3150.0997, valid loss:2818.0182\n",
      "epoch [479/1000], train loss:3234.0922, valid loss:2629.2574\n",
      "epoch [480/1000], train loss:3173.0263, valid loss:3229.6134\n",
      "epoch [481/1000], train loss:3440.5916, valid loss:2807.2154\n",
      "epoch [482/1000], train loss:3209.4645, valid loss:2716.8082\n",
      "epoch [483/1000], train loss:3244.5123, valid loss:2958.0066\n",
      "epoch [484/1000], train loss:3722.7865, valid loss:2969.6412\n",
      "epoch [485/1000], train loss:3722.0849, valid loss:2875.3105\n",
      "epoch [486/1000], train loss:3396.5017, valid loss:3139.1443\n",
      "epoch [487/1000], train loss:3254.3703, valid loss:2979.2069\n",
      "epoch [488/1000], train loss:3146.0673, valid loss:3014.2452\n",
      "epoch [489/1000], train loss:3295.4128, valid loss:2732.2929\n",
      "epoch [490/1000], train loss:3318.9834, valid loss:2742.2806\n",
      "epoch [491/1000], train loss:3272.2545, valid loss:2930.3527\n",
      "epoch [492/1000], train loss:3172.5428, valid loss:2792.9014\n",
      "epoch [493/1000], train loss:2938.3479, valid loss:3016.1953\n",
      "epoch [494/1000], train loss:3167.2546, valid loss:2868.9010\n",
      "epoch [495/1000], train loss:3223.6286, valid loss:2984.8623\n",
      "epoch [496/1000], train loss:3157.5436, valid loss:2853.4891\n",
      "epoch [497/1000], train loss:3082.7416, valid loss:3107.3328\n",
      "epoch [498/1000], train loss:3182.5255, valid loss:2986.1669\n",
      "epoch [499/1000], train loss:3265.4888, valid loss:2809.7791\n",
      "epoch [500/1000], train loss:3124.6976, valid loss:2680.8333\n",
      "epoch [501/1000], train loss:3178.8579, valid loss:2540.9125\n",
      "epoch [502/1000], train loss:3258.0469, valid loss:2661.7984\n",
      "epoch [503/1000], train loss:3362.1784, valid loss:2520.7671\n",
      "epoch [504/1000], train loss:3516.5563, valid loss:2732.0139\n",
      "epoch [505/1000], train loss:3159.5620, valid loss:3079.8113\n",
      "epoch [506/1000], train loss:3008.9008, valid loss:3145.1712\n",
      "epoch [507/1000], train loss:3488.2251, valid loss:3070.0638\n",
      "epoch [508/1000], train loss:3258.5002, valid loss:3158.8203\n",
      "epoch [509/1000], train loss:3563.5451, valid loss:3012.3230\n",
      "epoch [510/1000], train loss:3118.9037, valid loss:2935.9703\n",
      "epoch [511/1000], train loss:3278.7151, valid loss:2901.1455\n",
      "epoch [512/1000], train loss:3229.0885, valid loss:2856.6223\n",
      "epoch [513/1000], train loss:3320.9953, valid loss:2983.6739\n",
      "epoch [514/1000], train loss:3253.8811, valid loss:2777.5517\n",
      "epoch [515/1000], train loss:3306.3938, valid loss:3128.2888\n",
      "epoch [516/1000], train loss:3118.3900, valid loss:2998.8543\n",
      "epoch [517/1000], train loss:3241.5159, valid loss:3321.3536\n",
      "epoch [518/1000], train loss:3719.3951, valid loss:2764.3103\n",
      "epoch [519/1000], train loss:3383.7974, valid loss:2983.1233\n",
      "epoch [520/1000], train loss:3257.4571, valid loss:2956.7807\n",
      "epoch [521/1000], train loss:3139.6672, valid loss:2806.5876\n",
      "epoch [522/1000], train loss:3098.0706, valid loss:3061.8573\n",
      "epoch [523/1000], train loss:3159.0868, valid loss:2979.9410\n",
      "epoch [524/1000], train loss:3070.4134, valid loss:2897.8228\n",
      "epoch [525/1000], train loss:3086.8852, valid loss:2777.0389\n",
      "epoch [526/1000], train loss:3383.7167, valid loss:2843.6527\n",
      "epoch [527/1000], train loss:3674.8445, valid loss:2907.3279\n",
      "epoch [528/1000], train loss:3332.6032, valid loss:2887.1792\n",
      "epoch [529/1000], train loss:3393.5719, valid loss:3051.7235\n",
      "epoch [530/1000], train loss:3247.3437, valid loss:3038.6072\n",
      "epoch [531/1000], train loss:3260.8955, valid loss:2819.4990\n",
      "epoch [532/1000], train loss:3083.2842, valid loss:2706.6915\n",
      "epoch [533/1000], train loss:3138.8026, valid loss:2790.6597\n",
      "epoch [534/1000], train loss:3425.8806, valid loss:3050.4800\n",
      "epoch [535/1000], train loss:3207.3076, valid loss:2926.6419\n",
      "epoch [536/1000], train loss:3313.7744, valid loss:2632.8043\n",
      "epoch [537/1000], train loss:3327.5011, valid loss:2721.1901\n",
      "epoch [538/1000], train loss:3184.9228, valid loss:2721.0828\n",
      "epoch [539/1000], train loss:3286.7738, valid loss:2869.0306\n",
      "epoch [540/1000], train loss:3110.0790, valid loss:2781.2578\n",
      "epoch [541/1000], train loss:3073.2723, valid loss:2623.3800\n",
      "epoch [542/1000], train loss:3010.4131, valid loss:2847.8416\n",
      "epoch [543/1000], train loss:2843.1262, valid loss:2683.3301\n",
      "epoch [544/1000], train loss:2948.7594, valid loss:2766.2983\n",
      "epoch [545/1000], train loss:3092.6858, valid loss:2981.5305\n",
      "epoch [546/1000], train loss:3349.8834, valid loss:2810.7052\n",
      "epoch [547/1000], train loss:2885.6619, valid loss:2665.7782\n",
      "epoch [548/1000], train loss:3068.7955, valid loss:2645.3038\n",
      "epoch [549/1000], train loss:3466.3641, valid loss:3018.8466\n",
      "epoch [550/1000], train loss:3470.2719, valid loss:2995.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [551/1000], train loss:3254.5062, valid loss:2892.6438\n",
      "epoch [552/1000], train loss:3263.7342, valid loss:3125.9411\n",
      "epoch [553/1000], train loss:3047.2492, valid loss:3000.9733\n",
      "epoch [554/1000], train loss:3232.6189, valid loss:2997.4566\n",
      "epoch [555/1000], train loss:3500.6068, valid loss:3159.4542\n",
      "epoch [556/1000], train loss:3355.9467, valid loss:2992.0733\n",
      "epoch [557/1000], train loss:3412.3831, valid loss:2986.4539\n",
      "epoch [558/1000], train loss:3459.4864, valid loss:2995.2339\n",
      "epoch [559/1000], train loss:3152.6406, valid loss:2937.6247\n",
      "epoch [560/1000], train loss:3438.6267, valid loss:3106.0891\n",
      "epoch [561/1000], train loss:2946.0030, valid loss:2919.8263\n",
      "epoch [562/1000], train loss:3200.6044, valid loss:2937.8232\n",
      "epoch [563/1000], train loss:3223.6991, valid loss:3493.5087\n",
      "epoch [564/1000], train loss:3408.8674, valid loss:2767.4077\n",
      "epoch [565/1000], train loss:2843.0217, valid loss:2776.0252\n",
      "epoch [566/1000], train loss:3254.0141, valid loss:2646.5759\n",
      "epoch [567/1000], train loss:3108.1743, valid loss:2933.5384\n",
      "epoch [568/1000], train loss:3240.2728, valid loss:3265.9379\n",
      "epoch [569/1000], train loss:3465.4089, valid loss:2885.5380\n",
      "epoch [570/1000], train loss:3521.9331, valid loss:2949.5064\n",
      "epoch [571/1000], train loss:3106.8256, valid loss:2970.3141\n",
      "epoch [572/1000], train loss:3163.5654, valid loss:2782.8282\n",
      "epoch [573/1000], train loss:3422.6631, valid loss:2962.0381\n",
      "epoch [574/1000], train loss:2908.3501, valid loss:2813.5771\n",
      "epoch [575/1000], train loss:3269.9979, valid loss:2904.1319\n",
      "epoch [576/1000], train loss:3367.7365, valid loss:2795.4876\n",
      "epoch [577/1000], train loss:3068.7725, valid loss:2892.8526\n",
      "epoch [578/1000], train loss:3084.2460, valid loss:3001.7475\n",
      "epoch [579/1000], train loss:3144.8314, valid loss:3031.9689\n",
      "epoch [580/1000], train loss:3408.0513, valid loss:2913.0213\n",
      "epoch [581/1000], train loss:3035.0585, valid loss:3015.1029\n",
      "epoch [582/1000], train loss:3371.0410, valid loss:2899.2483\n",
      "epoch [583/1000], train loss:3292.5313, valid loss:2957.6925\n",
      "epoch [584/1000], train loss:3230.5796, valid loss:2937.2686\n",
      "epoch [585/1000], train loss:3254.7022, valid loss:3022.4743\n",
      "epoch [586/1000], train loss:3414.2677, valid loss:2693.8966\n",
      "epoch [587/1000], train loss:3083.1218, valid loss:2540.7357\n",
      "epoch [588/1000], train loss:2890.8972, valid loss:2782.8500\n",
      "epoch [589/1000], train loss:2884.6771, valid loss:2981.3916\n",
      "epoch [590/1000], train loss:3078.9521, valid loss:3110.0069\n",
      "epoch [591/1000], train loss:3129.0550, valid loss:2867.9994\n",
      "epoch [592/1000], train loss:3155.1447, valid loss:3022.0206\n",
      "epoch [593/1000], train loss:2990.6917, valid loss:3037.8796\n",
      "epoch [594/1000], train loss:3269.8268, valid loss:3011.3572\n",
      "epoch [595/1000], train loss:3113.3391, valid loss:3061.9195\n",
      "epoch [596/1000], train loss:3000.1714, valid loss:2857.7143\n",
      "epoch [597/1000], train loss:3255.5767, valid loss:2825.5052\n",
      "epoch [598/1000], train loss:2867.6560, valid loss:2837.3708\n",
      "epoch [599/1000], train loss:3328.2549, valid loss:2926.5826\n",
      "epoch [600/1000], train loss:3535.5431, valid loss:2713.5580\n",
      "epoch [601/1000], train loss:3663.3878, valid loss:2788.4766\n",
      "epoch [602/1000], train loss:3551.1389, valid loss:2906.6274\n",
      "epoch [603/1000], train loss:3265.4290, valid loss:2885.1573\n",
      "epoch [604/1000], train loss:3367.4275, valid loss:2687.9579\n",
      "epoch [605/1000], train loss:3439.0312, valid loss:2718.5095\n",
      "epoch [606/1000], train loss:3709.7813, valid loss:2720.6978\n",
      "epoch [607/1000], train loss:3315.8032, valid loss:2649.2721\n",
      "epoch [608/1000], train loss:3355.0512, valid loss:2821.5129\n",
      "epoch [609/1000], train loss:3203.9108, valid loss:2670.4638\n",
      "epoch [610/1000], train loss:3411.0630, valid loss:2759.1926\n",
      "epoch [611/1000], train loss:3200.7935, valid loss:2844.0930\n",
      "epoch [612/1000], train loss:3476.1620, valid loss:2807.2042\n",
      "epoch [613/1000], train loss:3158.4565, valid loss:2822.5260\n",
      "epoch [614/1000], train loss:3314.3199, valid loss:2682.3604\n",
      "epoch [615/1000], train loss:3073.4814, valid loss:3001.8950\n",
      "epoch [616/1000], train loss:3165.0213, valid loss:2787.3618\n",
      "epoch [617/1000], train loss:3168.5028, valid loss:3198.3189\n",
      "epoch [618/1000], train loss:3352.0188, valid loss:2689.9894\n",
      "epoch [619/1000], train loss:3207.0318, valid loss:2765.6504\n",
      "epoch [620/1000], train loss:3567.5842, valid loss:2734.7862\n",
      "epoch [621/1000], train loss:3344.3455, valid loss:2685.5404\n",
      "epoch [622/1000], train loss:2996.1984, valid loss:2624.0630\n",
      "epoch [623/1000], train loss:3395.4614, valid loss:2822.8825\n",
      "epoch [624/1000], train loss:3287.7661, valid loss:2751.8645\n",
      "epoch [625/1000], train loss:3060.9541, valid loss:2652.9467\n",
      "epoch [626/1000], train loss:3133.8189, valid loss:3115.0402\n",
      "epoch [627/1000], train loss:2840.4839, valid loss:3139.2698\n",
      "epoch [628/1000], train loss:3420.9180, valid loss:2777.2691\n",
      "epoch [629/1000], train loss:3252.8129, valid loss:2522.2442\n",
      "epoch [630/1000], train loss:3323.2053, valid loss:3217.2289\n",
      "epoch [631/1000], train loss:3226.7738, valid loss:3370.5361\n",
      "epoch [632/1000], train loss:3268.8141, valid loss:2725.8600\n",
      "epoch [633/1000], train loss:3052.6655, valid loss:2912.2664\n",
      "epoch [634/1000], train loss:3102.4175, valid loss:2878.2695\n",
      "epoch [635/1000], train loss:2969.3754, valid loss:3081.6947\n",
      "epoch [636/1000], train loss:3167.1668, valid loss:3014.1208\n",
      "epoch [637/1000], train loss:3239.2659, valid loss:3084.1738\n",
      "epoch [638/1000], train loss:2987.3430, valid loss:3259.8183\n",
      "epoch [639/1000], train loss:3569.7221, valid loss:3330.8030\n",
      "epoch [640/1000], train loss:3518.7865, valid loss:2980.3499\n",
      "epoch [641/1000], train loss:3046.6856, valid loss:2809.4233\n",
      "epoch [642/1000], train loss:3568.3015, valid loss:3072.0567\n",
      "epoch [643/1000], train loss:3660.5633, valid loss:2991.1896\n",
      "epoch [644/1000], train loss:3107.4527, valid loss:3168.9974\n",
      "epoch [645/1000], train loss:3800.9307, valid loss:3434.7428\n",
      "epoch [646/1000], train loss:3470.0612, valid loss:3116.1994\n",
      "epoch [647/1000], train loss:3104.9451, valid loss:2700.0662\n",
      "epoch [648/1000], train loss:3216.1764, valid loss:2986.5886\n",
      "epoch [649/1000], train loss:3452.4460, valid loss:3080.5654\n",
      "epoch [650/1000], train loss:3562.0655, valid loss:3083.7272\n",
      "epoch [651/1000], train loss:3155.8152, valid loss:3210.8888\n",
      "epoch [652/1000], train loss:3126.4931, valid loss:3066.3889\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d94e6716ba6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# ===================backward====================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\penny\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\penny\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Tanh(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 30))\n",
    "\n",
    "\n",
    "for name, param in decoder.named_parameters(): #checking the parameters of model\n",
    "    print(name,param)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr= 1e-2)\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epochlosstrain = 0\n",
    "    epochlosstest = 0\n",
    "    decoder.train()\n",
    "    for j in range(len(train_dataset)):\n",
    "        sample = train_dataset[j]\n",
    "        X, encoded = sample['X'],sample['encoded']\n",
    "        encoded = encoded.reshape(-1)\n",
    "        # ===================forward=====================\n",
    "        output = decoder(encoded)\n",
    "        loss = criterion(output, X)\n",
    "        epochlosstrain +=loss.item()\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        for j in range(len(test_dataset)):\n",
    "            sample = mi_dataset[j]\n",
    "            X, encoded = sample['X'],sample['encoded']\n",
    "            encoded = encoded.reshape(-1)\n",
    "            # ===================forward=====================\n",
    "            output = decoder(encoded)\n",
    "            loss = criterion(output, X)\n",
    "            epochlosstest +=loss.item()\n",
    "\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], train loss:{:.4f}, valid loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, epochlosstrain/len(train_dataset), epochlosstest/len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b = torch.unsqueeze(torch.ones(4),0)\n",
    "c = torch.unsqueeze(torch.ones(4)*2,0)\n",
    "d = torch.cat((b,c),0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = torch.zeros((6,4))\n",
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('modelBC_w3b_1model_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset\n",
    "csv_file = 'breast-cancer-wisconsin-data\\data.csv'\n",
    "prep = BC_binary_prep()\n",
    "\n",
    "full_dataset = GenericDataset(csv_file, transform=None, preprocessing = prep)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "full_dataset.get_nfeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([1]) tensor([1])\n",
      "predandlab tensor([0]) tensor([0])\n",
      "acc tensor([0.9386])\n"
     ]
    }
   ],
   "source": [
    "score = torch.zeros(1)\n",
    "valid_loss_store = torch.zeros(1)\n",
    "                \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for j in range(len(test_dataset)):\n",
    "        #print('evalmode', j)\n",
    "        sample = test_dataset[j]\n",
    "        X, label = sample['X'], sample['label']\n",
    "        output = model(X)\n",
    "        output = torch.unsqueeze(output,0)\n",
    "        label = torch.unsqueeze(label,0)\n",
    "        #output = torch.log(output)#postprocessing(output)\n",
    "        #valid_loss_store += loss\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print('predandlab', predicted, label)\n",
    "        score += predicted.eq(label).float()\n",
    "    score = score/len(test_dataset)\n",
    "    print('acc', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[ 0.22766684-0.10493104j -0.1133743 +0.44643881j  0.41466601-0.05405745j\n",
      "   0.05592543+0.00461174j -0.08803281-0.23648231j  0.45173194-0.37517381j\n",
      "   0.26586285+0.12893508j  0.002538  +0.22621312j]\n",
      " [ 0.22766684-0.10493104j -0.1133743 +0.44643881j  0.41466601-0.05405745j\n",
      "   0.05592543+0.00461174j -0.08803281-0.23648231j  0.45173194-0.37517381j\n",
      "   0.26586285+0.12893508j  0.002538  +0.22621312j]\n",
      " [ 0.22766684-0.10493104j -0.1133743 +0.44643881j  0.41466601-0.05405745j\n",
      "   0.05592543+0.00461174j -0.08803281-0.23648231j  0.45173194-0.37517381j\n",
      "   0.26586285+0.12893508j  0.002538  +0.22621312j]]\n",
      "2 [[ 0.22766684 -0.10493104 -0.1133743   0.44643881  0.41466601 -0.05405745\n",
      "   0.05592543  0.00461174 -0.08803281 -0.23648231  0.45173194 -0.37517381\n",
      "   0.26586285  0.12893508  0.002538    0.22621312]\n",
      " [ 0.22766684 -0.10493104 -0.1133743   0.44643881  0.41466601 -0.05405745\n",
      "   0.05592543  0.00461174 -0.08803281 -0.23648231  0.45173194 -0.37517381\n",
      "   0.26586285  0.12893508  0.002538    0.22621312]\n",
      " [ 0.22766684 -0.10493104 -0.1133743   0.44643881  0.41466601 -0.05405745\n",
      "   0.05592543  0.00461174 -0.08803281 -0.23648231  0.45173194 -0.37517381\n",
      "   0.26586285  0.12893508  0.002538    0.22621312]]\n",
      "3 [[[ 0.22766684 -0.10493104]\n",
      "  [-0.1133743   0.44643881]\n",
      "  [ 0.41466601 -0.05405745]\n",
      "  [ 0.05592543  0.00461174]\n",
      "  [-0.08803281 -0.23648231]\n",
      "  [ 0.45173194 -0.37517381]\n",
      "  [ 0.26586285  0.12893508]\n",
      "  [ 0.002538    0.22621312]]\n",
      "\n",
      " [[ 0.22766684 -0.10493104]\n",
      "  [-0.1133743   0.44643881]\n",
      "  [ 0.41466601 -0.05405745]\n",
      "  [ 0.05592543  0.00461174]\n",
      "  [-0.08803281 -0.23648231]\n",
      "  [ 0.45173194 -0.37517381]\n",
      "  [ 0.26586285  0.12893508]\n",
      "  [ 0.002538    0.22621312]]\n",
      "\n",
      " [[ 0.22766684 -0.10493104]\n",
      "  [-0.1133743   0.44643881]\n",
      "  [ 0.41466601 -0.05405745]\n",
      "  [ 0.05592543  0.00461174]\n",
      "  [-0.08803281 -0.23648231]\n",
      "  [ 0.45173194 -0.37517381]\n",
      "  [ 0.26586285  0.12893508]\n",
      "  [ 0.002538    0.22621312]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.evalmode_()\n",
    "dataset = []\n",
    "with torch.no_grad():\n",
    "    for j in range(10,13):\n",
    "        sample = test_dataset[11]\n",
    "        X, label = sample['X'], sample['label']\n",
    "        output = model(X)\n",
    "        dataset += [model.device._state]\n",
    "        \n",
    "dataset = np.array(dataset)\n",
    "print('1',dataset)\n",
    "dataset2 = dataset.view(np.float64)\n",
    "print('2',dataset2)\n",
    "dataset3 = dataset2.reshape(dataset.shape + (2,))\n",
    "print('3',dataset3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separability evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_prep(object): #apply a pca \n",
    "    \n",
    "    def __init__(self, n_components):\n",
    "        \n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(self.n_components)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        x = data[:,0:-1]\n",
    "        labels = np.expand_dims(data[:,-1],1)\n",
    "        \n",
    "        x = self.pca.fit_transform(x)\n",
    "        print(x.shape, labels.shape)\n",
    "        data = np.concatenate((x,labels), axis=1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[2.1560e+01, 2.2390e+01, 1.4200e+02, 1.4790e+03, 1.1100e-01, 1.1590e-01,\n",
      "         2.4390e-01, 1.3890e-01, 1.7260e-01, 5.6230e-02, 1.1760e+00, 1.2560e+00,\n",
      "         7.6730e+00, 1.5870e+02, 1.0300e-02, 2.8910e-02, 5.1980e-02, 2.4540e-02,\n",
      "         1.1140e-02, 4.2390e-03, 2.5450e+01, 2.6400e+01, 1.6610e+02, 2.0270e+03,\n",
      "         1.4100e-01, 2.1130e-01, 4.1070e-01, 2.2160e-01, 2.0600e-01, 7.1150e-02]])\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'breast-cancer-wisconsin-data\\data.csv'\n",
    "prep = BC_binary_prep()\n",
    "model = torch.load('modelBC_w9b_2model_id')\n",
    "mi_dataset = MutualInformationDataset(csv_file, encoder = model)\n",
    "ordataset = mi_dataset.BC_dataset.data\n",
    "endataset = mi_dataset.data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 2) (357, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barthelemy\\.conda\\envs\\penny\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x197b79467b8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "csv_file = 'breast-cancer-wisconsin-data\\data.csv'\n",
    "datar = pd.read_csv(csv_file)\n",
    "\n",
    "datar= datar.sample(frac=1)\n",
    "datar= datar.sample(frac=1)\n",
    "prep = BC_binary_prep()\n",
    "prepca = PCA_prep(2)\n",
    "\n",
    "datar = prep(datar)\n",
    "datar = np.array(datar)\n",
    "#datar = datar.iloc[:,-3:]\n",
    "# print('before')\n",
    "# print(datar.shape,datar[:5,:])\n",
    "# print(datar[0,0])\n",
    "\n",
    "\n",
    "X = datar[:,0:-1]\n",
    "y = datar[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "#plt.cla()\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "l0 = X[y==0]\n",
    "l1 = X[y==1]\n",
    "\n",
    "\n",
    "print(l0.shape, l1.shape)\n",
    "ax.scatter(l0[:,0],l0[:,1],s=2, label = 'malignant')\n",
    "ax.scatter(l1[:,0],l1[:,1],s=2, label = 'benign')\n",
    "ax.set_title('PCA of the original dataset')\n",
    "ax.set_xlabel('1st component')\n",
    "ax.set_ylabel('2nd component')\n",
    "ax.legend(fontsize=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels (569,)\n",
      "out [[ 0.76937179 -0.08993734]\n",
      " [-0.34943342  0.28484811]\n",
      " [-0.26919539  0.27864241]\n",
      " ...\n",
      " [ 0.22457601 -0.25474219]\n",
      " [-0.36880245  0.10248742]\n",
      " [-0.30068432  0.32685932]]\n",
      "[ True False False False  True False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      "  True  True False  True  True False  True False False  True  True False\n",
      " False False False False False False  True  True False False False False\n",
      " False False False  True  True  True  True  True  True False  True False\n",
      "  True  True False False False False  True  True False False  True False\n",
      " False  True False  True False  True False False False False False  True\n",
      " False  True False False  True False False False False  True False  True\n",
      " False False False  True  True  True False  True False  True  True False\n",
      " False  True False  True  True False False  True False  True  True  True\n",
      " False  True False False False  True  True  True False False  True False\n",
      "  True False  True False False False False False False False False False\n",
      " False False False  True  True  True  True False  True  True False False\n",
      "  True False  True  True  True False False False False  True False False\n",
      "  True False  True False False False False False False False  True False\n",
      "  True False  True False False False  True False False  True False False\n",
      " False False False  True False False False  True False False False False\n",
      " False False False False False False  True  True False  True  True False\n",
      " False False  True False  True False  True False False False  True False\n",
      " False False False  True False  True  True  True False  True  True  True\n",
      " False False  True  True  True  True False  True False False False  True\n",
      "  True False  True  True  True False  True False False False  True  True\n",
      " False  True False  True False False False False False False False  True\n",
      " False  True False False False False  True False False  True False False\n",
      " False False False  True False False  True False False False  True False\n",
      "  True  True False False  True False False False False False  True  True\n",
      " False False False False  True False  True  True False  True  True  True\n",
      " False False  True False  True  True False  True  True  True  True False\n",
      " False  True False False False  True False False False  True False False\n",
      " False  True False False  True False  True False  True False  True False\n",
      " False False False  True False  True False  True False  True False  True\n",
      " False  True  True False False False False False False False False False\n",
      "  True False False False False False False  True False  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False  True False  True  True False False False False  True False\n",
      " False  True False  True False  True False  True False False  True  True\n",
      " False  True False False  True False False  True  True False  True  True\n",
      " False  True False False False False False  True False False False False\n",
      " False  True  True False False  True False  True False  True False False\n",
      " False  True  True  True False False  True False False  True  True False\n",
      "  True False  True False False False  True False  True  True False  True\n",
      "  True False  True  True  True False False  True False  True  True False\n",
      " False  True  True  True  True False False False False False False False\n",
      " False False False False  True False False False False False  True False\n",
      " False False False False  True  True False  True False  True False False\n",
      " False  True False False  True  True False False  True  True  True False\n",
      "  True False  True False False  True False False False  True False  True\n",
      " False  True  True False False]\n",
      "lo [[ 7.69371791e-01 -8.99373382e-02]\n",
      " [ 2.78603200e-01 -1.88850014e-01]\n",
      " [ 4.77936802e-01 -4.83403176e-02]\n",
      " [ 3.99129946e-01 -7.30391361e-02]\n",
      " [ 7.06940782e-01  2.41571847e-01]\n",
      " [ 6.41099072e-01 -1.38608740e-01]\n",
      " [ 5.68029195e-01 -4.86296244e-03]\n",
      " [ 1.11058355e-02  3.35651968e-01]\n",
      " [ 6.79289654e-01 -1.80491964e-01]\n",
      " [ 8.35672924e-01  3.93146973e-02]\n",
      " [ 5.27759023e-01 -7.18192998e-04]\n",
      " [ 6.92067720e-01 -1.28556059e-01]\n",
      " [ 6.80202473e-01 -5.59671326e-02]\n",
      " [ 1.88010837e-01  3.56579298e-01]\n",
      " [ 2.63958508e-01  9.15341210e-02]\n",
      " [ 1.04900972e-01 -2.78285487e-01]\n",
      " [-2.20056388e-01 -1.10689861e-01]\n",
      " [ 1.27580375e-01  1.30687262e-01]\n",
      " [ 6.06841510e-01  2.11990359e-03]\n",
      " [ 2.80307102e-01  1.57966551e-01]\n",
      " [ 8.30516733e-01 -1.15010780e-01]\n",
      " [ 1.63979100e-01 -2.82889590e-01]\n",
      " [ 2.77406566e-01  2.08105702e-01]\n",
      " [ 5.05443047e-01  2.18868340e-01]\n",
      " [ 3.50098138e-01 -1.14871692e-01]\n",
      " [ 9.05847017e-02 -5.32441921e-02]\n",
      " [ 2.63982459e-01  8.17047094e-02]\n",
      " [ 5.70006996e-01 -1.06364196e-01]\n",
      " [ 4.37637452e-02 -3.99696033e-02]\n",
      " [ 2.36691749e-01 -1.48599811e-01]\n",
      " [ 6.28131220e-01  3.41274247e-02]\n",
      " [ 1.98301950e-01 -1.34111911e-01]\n",
      " [ 4.92915610e-01  2.58855742e-01]\n",
      " [ 4.65237680e-01 -1.68080209e-01]\n",
      " [ 1.47501760e-01 -2.60806005e-01]\n",
      " [-1.83334184e-02 -1.16024940e-02]\n",
      " [ 4.48023247e-01  7.90643475e-02]\n",
      " [ 2.39204280e-01 -1.04092763e-01]\n",
      " [ 2.77818498e-01 -1.32953039e-01]\n",
      " [ 8.95588953e-01  5.74067412e-02]\n",
      " [-3.94363907e-02  4.39786528e-02]\n",
      " [ 4.30040022e-01 -2.35133233e-02]\n",
      " [ 9.41291036e-01 -5.01268645e-02]\n",
      " [ 6.91055827e-01  7.32405051e-02]\n",
      " [ 7.35228862e-01  1.94972324e-02]\n",
      " [-1.15719163e-03  3.66596945e-01]\n",
      " [ 4.28811088e-01  2.61397743e-01]\n",
      " [ 2.62695209e-01 -2.33594064e-02]\n",
      " [ 8.78283038e-01 -7.99174421e-02]\n",
      " [ 6.17312253e-01 -6.88734769e-02]\n",
      " [ 4.16909430e-01 -1.18683759e-01]\n",
      " [-2.56297908e-02 -2.25707259e-01]\n",
      " [ 5.53749028e-01 -4.24667314e-02]\n",
      " [ 7.54973318e-01 -1.27704377e-01]\n",
      " [ 6.90210043e-01  1.33601939e-01]\n",
      " [ 4.09889397e-01 -5.85167526e-02]\n",
      " [ 3.72144564e-01 -9.91703640e-02]\n",
      " [ 3.99662079e-01 -5.71020972e-03]\n",
      " [ 5.84006502e-01 -8.37725900e-03]\n",
      " [ 3.74474328e-01 -2.38369954e-01]\n",
      " [ 6.23734361e-01  2.26288192e-01]\n",
      " [ 6.37289253e-01 -2.48046367e-02]\n",
      " [ 3.96633026e-01 -6.31122273e-02]\n",
      " [ 2.45017585e-01  1.20790820e-01]\n",
      " [ 6.64719316e-01 -9.05509294e-02]\n",
      " [ 4.48819757e-01 -2.51836324e-01]\n",
      " [ 3.89224623e-01  8.54396643e-02]\n",
      " [ 2.71073503e-01  1.44498339e-01]\n",
      " [ 6.89163117e-02 -8.33000516e-03]\n",
      " [ 5.65547568e-01 -2.09727382e-01]\n",
      " [ 9.41013389e-01 -8.37477594e-02]\n",
      " [ 6.47768443e-01  2.25042932e-02]\n",
      " [-5.84900278e-02  4.10796941e-01]\n",
      " [ 3.33019794e-01  1.03391872e-01]\n",
      " [ 8.11094668e-01 -6.96409505e-02]\n",
      " [ 6.03819994e-01 -5.89211969e-02]\n",
      " [ 5.02385587e-01  7.52084514e-02]\n",
      " [ 4.22842022e-01 -1.85530984e-01]\n",
      " [ 6.69720308e-01 -8.73558259e-02]\n",
      " [ 7.35617748e-01 -8.70686223e-03]\n",
      " [ 2.19319597e-01  1.79548256e-01]\n",
      " [ 4.86379651e-01  9.68777000e-02]\n",
      " [ 8.48843389e-01 -1.02360941e-01]\n",
      " [ 5.75743162e-01  3.72906230e-02]\n",
      " [ 2.98017585e-01 -5.50124576e-02]\n",
      " [ 2.41504802e-01  2.41684176e-01]\n",
      " [ 5.66520568e-01  1.18356664e-01]\n",
      " [ 5.49482052e-01  1.19472872e-02]\n",
      " [ 3.95417650e-01 -1.93226781e-01]\n",
      " [-1.36087353e-01  1.55766247e-01]\n",
      " [ 6.87859799e-02  4.93184659e-01]\n",
      " [ 9.52281847e-01  1.75034699e-02]\n",
      " [ 5.83833832e-01 -1.21116216e-01]\n",
      " [ 6.09022104e-01  8.99398185e-02]\n",
      " [ 5.42678970e-01 -2.19966989e-01]\n",
      " [ 4.25807611e-01  4.49107078e-02]\n",
      " [ 8.96838036e-01  2.05832347e-03]\n",
      " [-1.32888600e-01 -2.03417492e-01]\n",
      " [ 8.28962527e-01  1.17637330e-01]\n",
      " [ 8.88164447e-01  2.93218876e-02]\n",
      " [ 4.87145602e-01  5.34079037e-02]\n",
      " [ 2.64936369e-01 -1.04641201e-01]\n",
      " [ 4.46996258e-01 -1.76365030e-01]\n",
      " [ 6.99633999e-01  1.17686032e-01]\n",
      " [ 7.88750267e-01 -1.08165368e-01]\n",
      " [ 3.91498724e-01 -1.44864342e-01]\n",
      " [ 6.75882109e-01  2.47939515e-02]\n",
      " [ 6.58259725e-02 -7.10482581e-02]\n",
      " [ 2.17612210e-01 -1.86874461e-01]\n",
      " [ 2.48224722e-01 -4.43932642e-03]\n",
      " [ 3.28293156e-02  7.25062556e-02]\n",
      " [ 4.35201356e-01 -2.09709228e-04]\n",
      " [ 7.60437601e-01 -1.18951530e-01]\n",
      " [ 7.81229484e-01  1.71739865e-01]\n",
      " [ 3.74013257e-01  8.78201761e-03]\n",
      " [ 8.62591976e-02  6.24389558e-01]\n",
      " [-2.29099433e-01  1.53124305e-01]\n",
      " [ 6.46161829e-01 -1.10943774e-01]\n",
      " [ 1.36678902e-01 -1.05512700e-01]\n",
      " [ 4.11528890e-01 -1.62179002e-01]\n",
      " [ 5.71723444e-01  1.21056797e-01]\n",
      " [ 8.28391580e-01  9.01251108e-02]\n",
      " [ 2.66965136e-01  2.50021537e-01]\n",
      " [ 5.89013939e-01 -1.30556745e-01]\n",
      " [ 2.76946849e-01  4.88069403e-02]\n",
      " [ 3.96735559e-01  9.21632180e-02]\n",
      " [ 2.32163357e-01  1.19502474e-01]\n",
      " [-3.51364358e-02  1.40765196e-01]\n",
      " [-8.21494684e-02 -2.70464671e-01]\n",
      " [ 2.24988557e-01 -1.03692871e-01]\n",
      " [ 3.54714609e-01  2.26357867e-01]\n",
      " [ 8.07707804e-01 -1.12348909e-01]\n",
      " [ 3.78864758e-01  3.93702148e-02]\n",
      " [ 7.11768819e-01 -1.39762944e-01]\n",
      " [ 8.09711449e-01 -7.63652543e-02]\n",
      " [ 2.02030844e-01  1.85598540e-01]\n",
      " [ 2.22192842e-01  3.36573054e-02]\n",
      " [ 2.33852073e-01 -1.47103823e-01]\n",
      " [ 1.82691136e-01  2.89744999e-01]\n",
      " [ 9.93339716e-01 -6.87634296e-02]\n",
      " [ 7.58677889e-01  1.62302040e-02]\n",
      " [ 1.91235323e-01  2.33866678e-01]\n",
      " [-6.44558654e-03 -2.06692314e-01]\n",
      " [ 6.06594981e-01 -1.98279278e-01]\n",
      " [ 6.27844092e-01 -1.15061906e-01]\n",
      " [ 9.23718027e-01 -2.75674072e-02]\n",
      " [ 2.56781268e-02 -6.78782650e-02]\n",
      " [ 5.21073903e-01 -1.32884219e-01]\n",
      " [-1.20395967e-02 -2.47395735e-01]\n",
      " [ 1.73875077e-01  1.87695461e-01]\n",
      " [ 2.57345230e-01  4.04460532e-01]\n",
      " [ 3.10556368e-01  2.76942317e-01]\n",
      " [ 9.00056271e-01 -1.28261738e-01]\n",
      " [ 6.45949162e-01  2.75332253e-02]\n",
      " [ 7.41217506e-01 -4.62488019e-02]\n",
      " [-7.10391621e-02 -1.47196230e-01]\n",
      " [ 7.65211971e-01  1.08526243e-01]\n",
      " [ 2.23144980e-01 -6.41571362e-02]\n",
      " [ 1.06593609e-01 -7.28826109e-02]\n",
      " [ 6.34186961e-01  2.61258539e-02]\n",
      " [ 8.59079433e-01 -1.01529326e-01]\n",
      " [ 6.76305278e-01 -2.35012705e-02]\n",
      " [ 6.72630764e-01  2.48109413e-01]\n",
      " [ 2.61009138e-01 -1.73833830e-01]\n",
      " [ 6.16283601e-01  1.93934050e-01]\n",
      " [-1.90514540e-01 -4.83607287e-02]\n",
      " [ 6.15190438e-01 -6.37091328e-02]\n",
      " [ 5.99882320e-02  1.49874918e-01]\n",
      " [ 9.17980803e-01  4.00191861e-03]\n",
      " [ 7.23670546e-01  9.76260954e-03]\n",
      " [ 8.04367379e-01  4.55332261e-02]\n",
      " [ 8.37469525e-01 -1.50050166e-01]\n",
      " [ 8.52346890e-01 -9.60418833e-03]\n",
      " [ 4.27126702e-01  1.86754410e-02]\n",
      " [ 5.09379478e-01  2.83659970e-01]\n",
      " [ 6.19873599e-01 -1.35030933e-01]\n",
      " [ 2.93680222e-01 -6.76343378e-03]\n",
      " [ 4.07875189e-01 -1.73745924e-01]\n",
      " [-3.10439600e-01 -1.75310826e-01]\n",
      " [ 6.04908227e-01  5.26702062e-02]\n",
      " [ 3.73387856e-01  1.42713130e-01]\n",
      " [ 5.87894482e-01 -8.39075156e-02]\n",
      " [-6.05444931e-02 -1.54869185e-01]\n",
      " [ 8.50875034e-01 -9.21435228e-02]\n",
      " [ 8.30647524e-01 -1.50138638e-01]\n",
      " [ 9.39970036e-03  4.47060681e-01]\n",
      " [ 5.07857411e-01  2.55268906e-01]\n",
      " [ 3.07322967e-01 -2.15128166e-01]\n",
      " [ 8.67811776e-01 -6.07529544e-02]\n",
      " [ 4.02422535e-01  9.61606897e-02]\n",
      " [ 4.60627160e-01  1.42532645e-01]\n",
      " [ 4.75307905e-01 -1.75935506e-01]\n",
      " [ 3.67127851e-01  8.01306805e-02]\n",
      " [ 1.51484238e-01 -7.05403463e-02]\n",
      " [ 8.38971212e-01 -1.08642925e-01]\n",
      " [ 4.25953596e-01  2.97712502e-02]\n",
      " [ 4.19546829e-01  1.16826495e-01]\n",
      " [ 3.77347870e-01  1.22161403e-01]\n",
      " [-7.61106704e-02  1.67874750e-01]\n",
      " [ 4.18766195e-01  5.89270259e-02]\n",
      " [ 4.06357131e-01 -2.76744373e-01]\n",
      " [-2.44403453e-01  1.49087476e-02]\n",
      " [ 3.79797118e-01  6.57547217e-02]\n",
      " [ 1.85219065e-01  3.49247618e-01]\n",
      " [ 5.30204473e-01 -1.86682655e-01]\n",
      " [ 7.99191549e-01  2.08201951e-02]\n",
      " [ 5.16751181e-01 -2.10157343e-01]\n",
      " [ 1.77116166e-01 -4.31729483e-02]\n",
      " [ 6.73367232e-01 -2.24899150e-01]\n",
      " [ 5.16983126e-01  5.71890538e-02]\n",
      " [ 2.87813877e-01  1.83582193e-01]\n",
      " [ 2.24576013e-01 -2.54742192e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x197bf02bb70>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOy9e3hcZbX4/1mTpGmT9J6kQtNQlEILiFJKKQhHEBAQEI+0CCjXUxBUEDh6hKNyPUL1/BA5qAcq0gJqi1zkIh7xq4ig9ELaCkLLnV7SYptLaZumTZrM+/tjz0727OzrzN4ze5L38zx5JjOzL2vvmVnrfdda71qilEKj0Wg0GjdSxRZAo9FoNMlGGwqNRqPReKINhUaj0Wg80YZCo9FoNJ5oQ6HRaDQaT7Sh0Gg0Go0n2lBoSgoR+YSIvCUiHSLyuQDbTxYRJSLlhZAvbkTkWBFpLsS+IvKciMzN5VyawYU2FBpfRGStiOzKKOfNIrJARGos758kIs+LyA4RaRGRv4jIZ23HODajsP8jT3FuBn6slKpRSj3uIusJeZ5DE5JC3Xf9+RYHbSg0QTldKVUDTAcOB74DICKzgYeBB4AGYAJwPXC6bf8LgPbMYz7sA7yW5zE0Gk0ItKHQhEIptRH4P+BgERHgh8AtSql7lVLblFJppdRflFKXmPuISBUwG/gqMEVEZnidQ0QuEZG3RaRdRJ4Ukb0zr78DfBh4KjO7qbTt9yDQaHnfOnv5ooisF5FWEfm2ZZ+UiFwrIu+ISJuI/FpExnnIdpqI/F1EPhCRF0XkEMt7a0XkGyLyiohsE5GHRGS45f0zMvtuz5zv5Mzre2eusz1z3dZ7N0JEForIVhFZjWGkrfLsLSKPZmZy74nIlUH3dbi2E0Xk9YzsPwbE8t5HROTZzD1qFZFfisgYr/suIg+LyD8zx3teRA6yHO8zIrI6MwvdKCLf8LvHPp+vJk6UUvpP/3n+AWuBEzL/T8IY0d8CTAUUsK/P/ucB7wNlwFPA/3hs+ymgFWPmUgncBTzvJIufrJnnkzMy/gwYAXwM6AKmZd6/CliKMRuqBO4BFrkcezqwBTgicy0XZM5XaTn3cmBvYBywBrgs895MYBtwIsYAbSIwNfPeX4CfAsOBjwMtwPGZ9+YBL2SONwl4FWjOvJcCVmDM4IZhGNF3gZP89nW4tlpgO4ZBrwCuBnqAuZn398vIXgnUAc8DP/L6XICLgZGZfX4E/N3y3vvAMZn/xwLTQ9xj189f/8WkA4otgP5L/l/mx9kBfACsyyi1EcAnMkp4uM/+fzSVCnBORhFWuGz7c+AHluc1wB5gskWWXAxFg+W15cDZmf/XmEo583yvzPnKHY79vxizJ+trbwCftJz7S5b3fgDcnfn/HuAOh2NOAnqBkZbXbgMWZv5/FzjZ8t6l9BuKI4D1tuNdByzw29dBjvOBpZbnAjSTMRQO238OWOV23x22H5P5HEZnnq8HvgyMyuEea0NR4D/tetIE5XNKqTFKqX2UUl9RSu0C2jLv7eW2k4hMAo4Dfpl56QmMkfOpLrvsjWGMAFBKdWTOMzFP+f9p+b8TwwCBEfP4TcbN8QGG4ejFiLXY2Qf4d3PbzPaTMjL7nWcS8I7DMfcG2pVSOyyvraP/evcGNtjes8qzt02e/7TI7rWvkxx92ypDK/c9F5F6EVmccRNtB36BMQtxRETKRGRexsW2HUPBY9nnTOAzwLpM8sORlmvyu8eaAqMNhSYf3sBQJmd6bHMexvfsKRH5J8YodzjGCNaJTRjKAgARqQbGAxsDyhS2HPIG4JSMETT/hisjFuO07fds21YppRYFPM9HHF7fBIwTkZGW1xrpv973MRSl9T3rMd+zyTNSKfWZAPvaydo2E3+y7nsbxr09RCk1CvgSlhgGA+/7ucAZwAnAaIyZHeY+SqmXlFJnAPXA48CvLdfkdY91uesioA2FJmcyo85rgO+KyEUiMioTHD5aROZnNjsfuAnD927+nQmcKiLjHQ77K+AiEfl4Jlh9K7BMKbU2oFibMXz1Qbkb+J6I7AMgInUicobLtj8DLhORI8SgWkROtSl5N36OcV3HZ+7RRBGZqpTaALwI3CYiwzOB23+jfwb2a+A6ERkrIg3AFZZjLge2i8i3MoHrMhE5WEQOD7CvnaeBg0Tk82KsObkS+JDl/ZFk3I8iMhH4pm1/+30fiRELagOqMD5HAERkmIh8UURGK6X2YMRGejNv+93jsJ+vJgqK7fvSf8n/w9//fDJG0LQDI/7wHIZraRawG6hz2Oc14Gsux7sMw03TDvyW7PiCnyxnYPi/PwC+QX+MotyyzXP0B2lTGMbuDWBH5ry3+lzrS5njv4+RGjzSSTbgRuAXluf/CrySOc/b9AedGzLX2Z45/2WWfaowUo8/AFZjKOhmy/t7A4swXF5bMQLzJwTZ1+Xa3sQIuv8YI8hu3qeDMALnHcDfgX+3yWG/7zUYbsYdGC6v8zOfw34YgfffZ+TdnrmfRwe8x1nnKfZvY6j8SebmazQajUbjiHY9aTQajcYTbSg0Go1G44k2FBqNRqPxRBsKjUaj0XgyKEovW6mtrVWTJ08uthgajUZTUqxYsaJVKVXn9N6gMxSTJ0+mqamp2GJoNBpNSSEiriv3tetJo9FoNJ5oQ6HRaDQaT7Sh0Gg0Go0n2lBoNBqNxhNtKDQajUbjiTYUGo1Go/Fk0KXHajRDjW3bttHa2kp3d3exRdEkkGHDhlFbW8vo0aNzPoY2FBpNhnRa0bazm9qaYRh9e5LP7t272bx5Mw0NDYwYMaJk5NYUBqUUu3btorm5mcrKSoYPH57TcbTrSaPBMBLn/GwpR972J86ev5R0ujTK77e0tFBXV0dVVZU2EpoBiAhVVVXU1tbS0tKS83G0odBogLad3axYt5WetGLFuq207SwNN87u3bupqanx31AzpBk5ciS7d+/OeX9tKDQaoLZmGIftM5bylHDYPmOprRlWbJEC0dPTQ3m59iBrvCkvL6enpyf3/SOUJTQicjJwJ1AG3KuUmuewzVkYLSUV8LJS6tyCCqkZEogIiy6ZVXIxCqCkZNUUh3y/I0UzFCJSBvwEOBFoBl4SkSeVUqst20wBrgM+oZTaKiL1xZFWMxRIpYS6kZXFFkOjSRzFdD3NBN5WSr2rlOoGFmM0TrdyCfATpdRWAKXUlgLLqCkV0mno2AK6B7xGEznFNBQTgQ2W582Z16zsD+wvIn8TkaUZV9UARORSEWkSkaZ8IvuaBONlCNJpuP80+OE0WHiq8Vyj8UBEuPHGG/ue33jjjSXnwnvuuee48cYbSRfg+15MQ+H0qdi1QDkwBTgWOAe4V0TGDNhJqflKqRlKqRl1dY59NzSljJ8h6GyFDcsg3WM8drYWR05NyTJ37lyWLFlSbDFC8dxzz3HTTTcNekPRDEyyPG8ANjls84RSao9S6j3gDQzDoRlK+BmC6jqYdASkyo3Haj1Y0ISjoaGBWbNmFVuMxFJMQ/ESMEVE9hWRYcDZwJO2bR4HjgMQkVoMV9S7BZVSU3z8DIEIXPBbuGYNXPi08VxTsphuoNdff52TTjqJ6upqGhsbWbBgAQAPPvggU6dOpaamhuOOO4533nmnb9/FixfzqU99irq6Ompqajj00EO5//77A5/TSktLC+eccw6jRo1i7NixXHTRRTz55JOICM8991zfdsceeyxHH300f/zjH5k+fTpVVVUcfPDBPP7441nHe/vttznvvPPYd999GTFiBB/+8Ie5/PLL2bp1a9Z2F154IQ0NDaxatYpjjjmGqqoqpkyZwt13350l70033QRARUUFIhKr66xoWU9KqR4R+RrwDEZ67H1KqddE5GagSSn1ZOa9T4vIaqAX+KZSqq1YMmuKhGkIOlsNI+H0g0iloEYnxQ0m5syZwyWXXMI3vvENfvrTn3LxxRfz1ltv8dxzzzFv3jz27NnD17/+dc4991yWLVsGwLvvvsvs2bO59tprSaVSPP/888ydO5ddu3Zx2WWXhTr/5z//ef7xj39w2223sd9++/Hoo49yxRVXOG77zjvv8PWvf53rrruO2tpabr/9dmbPns3rr7/OfvvtB8CmTZtoaGjgRz/6EWPHjuXdd9/l1ltv5TOf+cwAt9f27ds599xzueqqq7j++utZsGABl19+OQcccADHHXccc+fOpbm5mZ///Of89a9/paysLIc7HAKl1KD6O+yww5RGM1RYvXp1LMft7U2rLdt3q3Q6HcvxvbjhhhsUoO6///6+19rb21VZWZkaN26c2rZtW9/rd955pwLU2rVrBxynt7dX7dmzR82dO1cdcsghWe8B6oYbbhhwTpNnnnlGAeqhhx7K2u/0009XgPrzn//c99onP/lJVV5ert58882+1zZv3qxSqZT63ve+53qde/bsUS+88IIC1MqVK/tev+CCCxSgnn322b7Xdu/ercaPH68uueSSATLv2bPH9RxW/L4rGAN0R72qV2ZrNJosklL36pRTTun7f+zYsdTX1zNr1ixGjRrV9/rUqVMB2LDBSKB86623OOecc5g4cSIVFRVUVFRw77338sYbb4Q699KlSykrK+Nf//Vfs16fPXu24/ZTpkxhypT+8Gl9fT319fWsX7++77Xu7m5uvfVWpk6dyogRI6ioqOCYY44BGCBfVVUVxx13XN/zyspKpkyZknW8QqLX/ms0miyc6l4VYyHi2LFjs54PGzbM8TUwal51dHRw4oknUlVVxbx58/jIRz7CsGHD+N///V/uu+++UOd+//33GTt2LBUVFVmvT5gwwXH7cePGDXitsrIyq77Sddddx1133cX111/PUUcdxciRI2lububzn//8gDpM9ut0Ol4h0YZCo9FkYda9WrFua0nVvVqyZAnr1q3jhRde4Oijj+57PZcaR3vttRdbt25lz549WcZi8+bNOcu3ePFizj//fL7zne/0vdbR0ZHz8QqJNhQajSaLUq171dnZCZCl2Ldu3coTTzwR+lizZs2it7eX3/zmN5x11ll9rz/88MN5yWefoZiZXLlQWWnM8nbt2sXIkSNzPk4QtKHQaDQDKMW6V0cddRSjRo3iq1/9KjfddBM7d+7kv/7rv6itrWXbtm2hjvXpT3+ao48+mksvvZTW1lb2228/HnnkEV5++WUAUqnw4d2TTz6Z+++/n49+9KPst99+PPbYY7z44ouhj2Ny4IEHAnD77bdzyimnUFZWxowZM3I+nhc6mK0Z/Og6UEOCuro6fvOb39Db28vs2bO57rrrmDt3Ll/60pdyOt5jjz3GySefzLe+9S3OOussdu/ezS233AKQU1vRu+66i89+9rN8+9vf5gtf+AI7duxg0aJFOckGcNppp/GVr3yFn/70pxx55JEcfvjhOR/LD1GD7MczY8YM1dTUVGwxNEnBLP+xYZmxWO+C3xprLgYJa9asYdq0acUWY8jw1a9+lYULF9Le3t7n+ikV/L4rIrJCKeU4JdGuJ83gxqn8h16YpwnAwoUL2bZtGwcddBDd3d38/ve/5+677+ab3/xmyRmJfNGGQjO4Mct/mDMKXQdKE5Dq6mp+9KMf8c4779DV1cW+++7Lrbfeyje/+c1ii1ZwtKHQDB7S6YFlPoKU/9BoHJgzZw5z5swpthiJYPA4azVDG69S5GYdKG0kNJqc0IaiVMknkyeXfZOeOaR7Umg0saENRSmST0e3XPYthQ5yuieFRhMbOkZRiuSTyZPLvqWQOaRjERpNbOgZRSmSz+g5l31LZbSeQywinVa07OhisK0n0miiRM8oSpF8Rs+57DtIR+tmOW2z+N2iS2aRSg2Oa9NookTPKEqVfDJ5ctm3GJlDMQfQ2zp2s3bde/Sk033ltDUazUC0odAkk7gD6Ok0tY+eyd+GfY2Hht3CjMbRJVNOe7Bj9q/OpTx4rqxduxYRYeHChQU7ZymhXU+aZBJ3AL2zFdmwjHJ6mVn+Nou+uF/JlNPWRM9ee+3FkiVL+MhHPlJsURKJnlFokkncAXTL8WXSEUjSsrg0BaWyspJZs2ZRV5fQRI0iow2FJpmYAfRr1sCFT0cfG4n7+Jq8WbNmDccddxxVVVXstddeXH/99aQtLsjW1lYuv/xyJk6cSGVlJVOnTmX+/PlZx1i4cCEiwtKlS/niF7/IqFGj2Hvvvbnyyiuz2oq6uZ7uvPNOJk+ezPDhw5k5cyYvvvgikydP5sILLwx9jlJGGwrNQJKyCjvuALou7ZFoPve5z3HCCSfw+OOPc+6553LLLbdw8803A7B9+3Y+8YlP8PTTT3PjjTfy9NNPc/rpp3P55Zdz1113DTjWeeedx0c+8hEee+wxLr/8cn7yk59w2223eZ7/3nvv5aqrruKEE07giSee4MILL+Tcc8/lgw8+cNw+l3OUDEqpQfV32GGHqUFPb69SOzYrlU5Hf9zt7yt13ylK3TTOeOztLdz5NaFZvXp1PAcu4md8ww03KEDddtttWa/PnTtX1dTUqK1bt6qbb75ZVVZWqjfffHPANuPHj1d79uxRSim1YMECBajrr78+a7tTTz1VTZkype/5e++9pwC1YMECpZRSvb29qqGhQZ1yyilZ+z366KMKUBdccEHfa0HPUWz8vitAk3LRq3pGUWqEyQYKMzPoO+6BsO5F95pJpVDOQ5MfCfmMrb2qAc4++2w6Ojp49dVX+f3vf88RRxzBvvvuS09PT9/fSSedRFtbG6tXr87a99RTT816/tGPfpT169e7nru5uZnm5uYB1WPPOOMMysudc4DCnqOU0FlPpUbQbKCwnd3M46pe43mqzDmInPByHum0om1nN7U1w3QWU64k5DOeMGGC4/ONGzeyZcsW3n77bSoqKhz3bWtry3o+bty4rOeVlZV0dXW5nvv9998HoL4++7rLysqora113CfsOUoJbShKjaCNeML+2K3HbZgJcxY6++8T3AhIr7SOiIR8xps3b+bDH/5w1nOAiRMnMn78eOrr67nzzjsd9z3ggAPyOvdee+0FwJYtW7Je7+3tpbV16FUm1oai1AhaTsOu+JUy/ty2D3rcBJfzaNvZzYp1W+lJq76V1nUjh1bLykhIyGf861//mmuvvbbv+eLFi6mpqeHggw/m5JNP5q677qKxsXHAqD8KGhoaaGho4OGHH+aiiy7qe/3xxx8v6ELApKANRSliZuu4YXZ6O/8p2NkCj1wEdxzo74LyO27Y7QpMbc0wDttnbN+MQq+0zoMEfMY/+9nPSKfTHH744TzzzDPce++93HjjjYwZM4arr76ahx56iGOOOYarr76aAw44gJ07d/L666/zwgsv8MQTT+R17lQqxQ033MAll1zC3LlzmTNnDu+++y7z5s1j9OjRpLzcuIMQbSgGG/bYxOz7oHl50f3NfYF1kdhSUkWERZfM0jGKQcITTzzBFVdcwS233MLo0aP5zne+w3e/+10ARo8ezYsvvsjNN9/M97//fTZu3MiYMWM44IADOPPMMyM5/9y5c+no6OCOO+7gF7/4BQcffDC//OUvOf300xk9enQk5ygVRBU7Vz5iZsyYoZqamootRvHo2GJkq6R7jFXNV682ZhSm4SjG4rJ02sieWb8EUNB4lCHHEBuVxcGaNWuYNm1ascUYMrz00kvMnDmTBx54gPPOO6/Y4oTC77siIiuUUjOc3tMzisGGPRBZUx/M32y6q+LwSXe2QvMyIDMoKfbMJoHxFU3yeO+99/jJT37CMcccw6hRo1izZg233nor++67b2SzllJBG4rBhlMg0nT3uBE2lTYs1XUwaZaxPgMVOJMm8lTXuK9TM6gYMWIEr776Kg888ABbt25l7NixnHDCCcybN4+qqqpii1dQimooRORk4E6gDLhXKTXPZbvZwMPA4UqpIexXCkjYQKQ1lXb9Umh5HeqnRTfiNo1XiBhFLKmuCVkf4IVeB5IcPvShD/H73/++2GIkgqINp0SkDPgJcApwIHCOiBzosN1I4EpgWWElHEKY7iopg2HVcM8x0a/ITaVg1Idg5IRABsgp1TVvEt7S1TSOR972J86ev5R0OgHxQ6Wgd0/x635pikox590zgbeVUu8qpbqBxcAZDtvdAvwAGBxlGJOIOeK/7K+wp9O9fEcBMVNdy1MSXaprwivG5mocY0tIUQra3obNrxmP2liULPl+R4ppKCYCGyzPmzOv9SEihwKTlFK/9TqQiFwqIk0i0tTS0hK9pEkirsquqZThbir0iNvlesxU1yXXHc/iS2dF54ZJcMXYXIxjRUUFu3btikegdA907wSU8ZgeegvNBgu7du1yLXcShGLGKJx+qX3aQkRSwB3AhX4HUkrNB+aDkR4bkXzJI+5gbKFX5PpcTyolQ2pldS7rQOrr69m4cSMTJ05kxIgR0cY1UuWGK7J7p/GY0rkvpYZSil27drFx48YBtbPCUMxPvhmYZHneAGyyPB8JHAw8l/nyfwh4UkQ+O2QD2oUIxhZyRW4JBJcLTVjjOGrUKAA2bdrEnj17ohdIKVDlkOoxkhw0JUdFRQUTJkzo+67kQjENxUvAFBHZF9gInA2ca76plNoG9JVpFJHngG8MWSMBiSnWFhmD7XqKxKhRo/JSAhqNH0UzFEqpHhH5GvAMRnrsfUqp10TkZowGGk8WS7ai47YoLCHF2iJjsF2PRjNIKarTUSn1O+B3tteud9n22ELIVHT84hAJKNYWKRFdj15/oNHEh16WWiiCZis5+e1zOc4QIpHrDzSaQYQ2FIUgTGtJr0VhTseJ03CEPXaRjFgsi/MiIJ1WtOzoim+dg0ZTIHS+WyEIk93j5be3H6djCzx6cTzpsmFTcYtYRymJfSh0tz3NYEIbikIQNrvHzW9vP45IuPTSMJVTw6auFjHVNYl9KFo6umha206vQnfb05Q82lAUgqiye+zHgeAGKOyIP6xxK3Kqa5IW56XTiisWraI343Ga3jgmEbMcjSZXtKEoFFFlK9mPE9QAhR3xhzVuCUp1zcqAUspZphj7UrTt7Gbluq0AlKWEH587PRGzHI0mV7ShKHWCGqBcRvxhjVsCUnetsYEZjaNZNOx7SLNtFhVzPMUeM0nKTEejyRVtKIYC5uj5/KdgV5v/KNpvtJ3gLnHWDKj31q+D4Q6zqJjjKUmMmWg0+eA7jMqU2PB9TZNQzH7VP5wKD5wOVbX+RsIrldf+fm+Pe0psEdJlrRVYJzdOdk41LkBfCjNmoo2EZjAQZEbxKDDd9tojwGHRi6OJnI4tsH4JoIxWpB1bjAZCbviNtu3vLzgZNq0a6MIpUrrsgNG8coibJCieotGUAq6GQkSmAgcBo0Xk85a3RgHD4xZM40NQ948I/dXblb9S9ItlWN/f+1DYuBJU70CjUsR02awMKLd+4QmIp2g0pYLXjOIA4DRgDHC65fUdwCVxCjVoiMuXH2a0XlMPjUf1b+unHP1G29b3q2qz5bAaFV0ZVqMZNIhfeQEROVIptaRA8uTNjBkzVFNTAiqRR+l6sRucji1GjCDdY/jZr1kT3UK7fGUr1Hk1Gk2kiMgKpdQMp/eCxCjeFpH/BCZbt1dKXRyNeIOUqFwvTgYnqpXe1nP4KXS3bbyOrd07Gs2gIIiheAJ4Afgj0BuvOIOIIMo8iILu2AIblkLaEgeoqoUz7+v3v+czWg8y8yliHSeNRlN8ghiKKqXUt2KXZLDh5+sPqqAfucgwEgg0zIQR4wful4+hCDLz0S1LQ6P7Y2gGE0GGhb8Vkc/ELslgxHS9OCkKv74T5jbNy43/JQVzFhoL5qz7tbye3zqFIGsKgq470L0yAN0fQ5dXH3wEmVF8HfhPEekGugEBlFJKN+nNBy/XlOmSqqrN3sYcxZuvVVTB3UdD46zs8hRBA8jmthc8BZ0eK7aDrDvQ7qk+nPpjxFHGI4mzFl1efXDiayiUUiMLIciQw0352hXu+U/CrvbsbS74rTGTuPvo7DUM9nRVL2XtpNi9lI1fYFq7p/ooRH+MpCrkQhlJTWEJUsJDRORLIvLdzPNJIjIzftEGCV7uGCfXlF3h7mofuE0qBfXTjJmE1R0UxJ3ldh6vbYNQgLIYpYK5OnzJdcez+NJZsYz2k9rVz1pCJSlNpDT5E8T19FMgDXwKuAXoAH4CHB6jXIODXNwxQVNfnWYkYdJmo14Qp8tiZBF3f4wkdvUDXRBxsBJkwd1KpdR0EVmllDo089rLSqmPFUTCkCRmwR2EXxhnks9CtVxiFOa2eoFcSRFXjCKX4yYxXqIJh9eCuyDRxj0iUkamYJCI1GHMMDR+5OqO8cqWinJf67Z+VWM1iSOOCrW5ZGzZ9+npSeusp0FGENfT/wC/AepF5HvAbOA7sUo1WMjFHVOsUX2Sg9FDcKZTrBF6LsFo6z5Na9uZM38J/2jeVpQgu57ZxIPvjEIp9UvgP4DbgPeBzymlHo5bsEFDmBF+MUf1SQ1GD8GZTjHXYeQSjLbu87FJY3ileVtRguxDff1KnATtcPcWsN3cXkQalVLrY5NqMBJkVFzMUX2hg9FBZwlJnulEhH0UXMwU01yC0dZ9xldXcM7PlhUlyO533/RsI3d8DYWIXAHcAGzGqPVkNjg4JF7RBhFBs58KVZo7lwJ/UZ8/aDZYiZcrd1ROlvufVgxYD1HsjKZcMras+xQr68nrviV13UmpEHRl9gFKqba4hRm0WEfF65fCzhYYOWHgdoUY1VuVdMNMmL3AkCXMufKNGYSZJZRw2q2jckJlGcm2Mx91HAWXcopp3KnBbnjNhvRCwPwIkvW0AdgWtyCDDutCu+o6QykDKLPQn4uvPWxMw6+2Um8PbF7df74so/Ui/OjAcL7/KGIGYeMh+WSBFRHHRXE2I1kr2x1jAlFkNA22mktBrsftvumFgPkRZEbxLvCciDwNdJkvKqV+GJtUpY6Ta2X2AkMppx3ahkZ1Drv7prcHfrAvdG2HylHwH+/1K+n1Sw2jZZfHb7YQRcyghGcJgcjcw9rqWgdXSLYrTWrqWXRJfeSzh2K5WuJc25HP9eiFgPkRxFCsz/wNy/xp/HBSpiMnwKRZ0fnagyjs1jcNIwHGY+ubMOFAQ0nvbDFmNlZ5ghifqGIGg7WpkeUeyqQjWDT3Kdo6e7KVk81IpoTI3duBevsAACAASURBVCDFcLXEaZyiuJ5iucQGA0GKAt4EICIjjaeqI3apSh0nZRr1KDqIwq6baswkzBlF3VTj9VTKMFx2eXa2+BsfEaNQYeubxvH0yCwbmwFP7WqjbqTtHhbASBYjIB6ncSp2gH+oEyTr6WDgQWBc5nkrcL5S6rV8Ty4iJwN3AmXAvUqpebb3rwHmAj1AC3CxUmpdvueNHTejYFcQ+QSFgxieVMpwN7W+CeP395cnaFe+Bz6ry4m7EXGWVq6unGK4WuJU5tp1VFyC1Hp6Efi2UurPmefHArcqpY7K68RGWZA3gROBZuAl4Byl1GrLNscBy5RSnSJyOXCsUuoLXsdNVK0nL9JpIxhsKpQLn45P4YZJR/UzXvb6VVe/ZjRVGoyxhlyJaCV5KaZ06rUKpUu+tZ6qTSMBoJR6DqiOQK6ZwNtKqXeVUt3AYuAM6wZKqT8rpTozT5cCDRGcNxns3GJkHale43HnFuP1fLrEue3rFM9w29Yvw8iasdQwEx65eEitmg5ERFlaSS0l7kUc9adg8GVwlRpBDMW7IvJdEZmc+fsO8F4E556IkXpr0px5zY1/A/7P6Q0RuVREmkSkqaWlJQLRCoFk/iz/B0k9dVPwXvva01Grxuee4mq6vK5ZY7RmzbenhW6f6opO6TTQpTmKT5Csp4uBm4DHMDTa88BFEZzbacjh+A0QkS8BM4BPOr2vlJoPzAfD9RSBbPFTUw+NR0LzMiMbqqbeP5js5kJKp42Od+uXZne8M/e1xzOCBK29MEfMSuXnjx+E7VPdXC99r1eXI15tZy1ov7yBXixXfIJkPW0FrhSR0UBaKbUjonM3A5MszxuATfaNROQE4NvAJ5VSXfb3SxYRIy4RpvGQkwvJ2v50WDV073Te1xq4jirgahqgji3xr9AuAdxiCubrK9e18UTNPKb1rGHP3odTcfHTSKrM85imKyedVrR2dA1Jg6EznopPkKynw4H7gJGZ59swso9W5Hnul4ApIrIvsBE4GzjXdu5DgXuAk5VSW/I8X/KwZx35ZTI5KXjr7GBPJ1z2V6NNqpcyiTpV99GLc5sVlHgdJztuI1/z9THp7Uzpeg2RNKkNy/jy3c9w92Wn+AaoSzGoHSV6ZlV8griefg58RSn1AoCIHA0sIM+igEqpHhH5GvAMRnrsfUqp10TkZqBJKfUk8N9ADfBw5suxXin12XzOm3i8cuyDtD/1MxJBzhOGfGYFURusIvetcBv59r+ueGPYgRzQvZoV6f15tlmF7vcwVF0vxVwspzO5ghmKHaaRAFBK/VVEInE/KaV+B/zO9tr1lv9PiOI8RSVu5VXschj5zgpsBivnH2UC4h1uI9+sMtxVJ3HZPX/g2WbFYfuMC9XvQbteCs9Qn82ZBDEUy0XkHmARRrD5Cxi1n6YDKKVWxihfaRO18sr3eHEYLbuhUspwh+Vwjrx+lAmJd7iNfK2v333ZKTn3exjKo9pioGdzBkG0zMeB/TF6UtwITAOOAm4H/r/YJBsMOCmvqI8XtJprnJ3irFlQtnOEyX+3/ihXrmujfUuzccwgKbRJ7dDnQNi1Btr1UTx0irJBkKyn4wohyKDE6pbZ+1AjQymq4zkFs71G0m4jbpdZRk7KyXaOdEcL5yx6N/AMwfxRmtlB4+ev6S/P3rzcexYV0gVXKspXuz6Ki57NGQTJehoDnA9Mtm6vlLoyPrEGCWYBvQUnw8aVxmg7H/dTkGB21Xhj9G1Xlk5GxsWVlbNysp2jjdGhpu3mj7J9SzPj569B0j3GOhOF8/oQOwED9KWkfBPj+ihyokAx0VVng8UofodRPuMfgK7REJZd7bBpVTBFFwSvlNqq8XD/6c4xDCcj4zIbyVk52c5RC6GDsKmUUDuhIduoKdU3o0gPH0f7Pzcwvn4ikqPBTYzy9SGdViilmN44hpXrP8jb9RFFooBqOILW2Y9SO3L4kB1dD0WCGIrhSqlrYpeklAgzuirEWgHTeHRs8XZDBawWm1eWjeUcgkv/ZL/75xQg72wlPXwcr//gWPbveo01lQcx9Vt/IVXmvWDNiVLIIrLOeqY3juVv136K+jxqKEWVKNC7fimnzfsNk/fZN9EzMU20BDEUD4rIJcBvye5w1x6bVEkmbOZRodJX05ludRVVRv+JiioYMd57HxfZovTLDpi2B71/VqMmAjX1tP9zA/t3vUa5pNm/6zXaWzZR+6FJA/f1IdfrK2RcIyuwv34rKZG8zpnXLCozoFAblrGiZz82p0fRluCZmJVSiUUlnSBz926MhW9LgBWZvxKo4x0Tna1GTaV0j/EYJJMp7p7PpvK946D+jnbdO2FXW86yxVUFNJ9MsPH1E3mz8iB6VIo3Kw9ifL1XDUlvcsk8KmRhuqizbfI6njmguHo1P9z7DspTqcTOxKzoYoLREWRGcQ2wn1Iqz9zOQULVeKOmUtd247EqM2ovZrDPVL6q13ieKjMKDSYxRTQPV5ykUkz91l9ob9nEtDxiFLkQd1zDPvKNOttGRPjlvx3B2y0d7D+hJvzxUilk5AQWXRpPf+84Rv2lEosqBYIYiteATt+thgqdbUZNJTAeO9uyC/MVY1WwVfk2zDTKf8c5g8mHPF1xqbKynNxN+RJHXMNUkOOqKjj33mUD4gdRZtuk04ov/nzgOdxkclPaUWcA9fSkmTN/Ca80b2NGxBlo1s9seuMYlDKSA+JyQQ1mN1cQQ9EL/F1E/kx2jGJopsfms5YhLvKNgxR6NlSAntFRE/UI3xpc/mjDaF7Z8AG9ithGvkFG14VOG06nFWfNX8Kq9R8A0BTxtZufWUtHF1csWsVR856N7bpKKeU6F4IMex8Hvge8SH+MIt/KsaWLtXHPhU9nr2UIsyrYabVxPk18co2DhFnZ7SVbsRoQRX0fPYgybmNV3K80b+Njk8bEuvo3SIyi0B312nZ28/KGD/qeH9IwOvJrT6WElAgrQ15X2I56pdiNMAxBVmbfLyLDMMp4ALyhlNoTr1gJJ2x5cDtOmT/g776KY+QfpEaSX6ZSsQry5XofE4DdlfWruUfQ3rknr9mKl+sjyIyo0GnDtTXDmDF5HE1r2/nYpDE8ctmRsbhswl5XLrODUki5zocgK7OPBe4H1mKkxk8SkQuUUs/HK1qJEcad4pb5k0t3u3ypGm+UF9m40n025GdMilWQL5f7mBCcFHc+Lpcgys0pvmA3LoVMGy5UeYyw58klCD7YS30E0TS3A59WSn1SKfUvwEnAHfGKNchxclX5ua9ySSsN4i66/3Rj5fjE6XDBU84zFT/Z4irI5yd/LvcxQXi5sgrh+ujpSXPm3S8yy5I+Wui04djSsPM4T66pxIW6lmIQJJhdoZR6w3yilHpTRCpilKl0MF1BVeON7KegLiE3V1XY7nZ+MrmV8zCxGp9Nq4xrcBp9+7nW4lhUGGQGlct9LAEK4fqIKpBc6LThQlAKCzILTRBD0SQiPwcezDz/IkM5mG1iKrL1S431FHs6w7mEnFxVXu4rpWD2fYC4B62tynXvQw3l7+WCCbOmwZQtnXbuNxF1JlNQd1bY+1gCtO3spmltO70Kmta2x+L6aNnRxd8jCCTH6ZsvZiZR2DTgwZ71FMRQXA58FbgSI0bxPPDTOIUqCayL3MzV0Ln4xIMEqJ1G19ZtzWMo1a9cN6403EmbVrkbgSiC8HEFigdZP+0wjKuqoKqynB27e6iqLGdcVbAJvJtys49002nFFYtWYnqJDp00hkc9Asn5BslzpZQWzJWSrLkQxFCUA3cqpX4IICJlwOC5A7mQThtKuWGmocisM4owCi2o4nUaXVfVOruYGmZaejc85e8SyzcIH9fIPUJ3Vqm5BNo799DZbayy7+zupb1zT85Kx2mk27azm5UZl1OZwD3nHUbKxeCHDZJHea+jmK0U6rMf8llPwJ+AE4COzPMRwB8wutwNPazKvWEmXLPaUGRhYhQmQRWvU88JU4YJB8PmV/uPcdVrhvI3ZYlSkQcZ5UeZwhuBC6kUXQK1NcOYEZHScRrp2pWalxEKM1KO+l7nO1sp5Gc/2LOegpYZN40ESqkOEamKUaZkY1XuzctBUkZtpbAKzZyVBHGv2EfX1pXg7/8dhtVAz27jGCMnxBfA9RvlF2s9hQel6BKIUunYjcK4qgpaO7oDr9sIM1KO417nUzKk0J/9YG5wFMRQ7BSR6UqplQAichiwK16xEozbqDrMSNo+K7nqNX8Fbx1dV9cZwerml4zn3Z1w+d+gflo8RsJ6bV6j/GKtp/CgVF0CUSkdq9FxqillNRJObpowRqvQtZX8KIXPvlTcouKXpy0ihwOLgU2Zl/YCvqCUSmTm04wZM1RTU8xV0O1GIexIumOLUTIj3WPk+1+zxnk1tJfhSffCzz9tBK0bZ8FFv4vPSDitfnaSTSmjDIi5rVnipJA43LdS+THGTcuOLo687U/0pBXlKWHJdcdnxRZyddNY769S9NVWWpmnyyeKzy3Jn33S3KIiskIpNcPpvSAlPF4SkanAARhZT6/rEh6p8CuTrQrMz9cfyPAIlA2DlBgKUSlnV1C+8QL7te3cAo9cHLzdaiFxuW+l7BIoVHA4VzeNo7JzqK0U9v5HpUST/NmXkls0iOuJjGF4NWZZkoufws1F8Xsp1I4tsGGpMWtwMzydrUaMxG2bqOIF9mtDwrVbjRBfpZlA11c+FDI4nO02GhvYbRQkWJ6LyyfpSjQKA14KrjGTQIZiSJPPCmETNwXmpMTSaXjkIsMAIEYMwynI7WecolKa9muDoqxvCKQ0g9StKiEKqSz7SnLv6OKKRSsDl+R2UnZRBOOTrES9vothDEgpZUppQ+FHPiuETcIsHjNnCmBkVM1Z6DyL8TNOUS5Ys19bEdxLvkozaN2qhBBEoUStLP2MrdksaeX6DwIbJzdll8vK5iAd/pIQc3D7LuYyA0yya8yKq6EQkeleO5pZUIOeKBRuGN+9/XxuxsfPHRZXvKBILV99lWbQulUJIKhCiXrEGWSGUlszjOmNY/oyl4IYp3yVndv9sB83KcFft+9i2DUnxTZ4YfCaUdyeeRwOzABexghmHwIsA46OV7SEEJXCDeq7D3K+IO6wsOm69iwup32LuE7CV2mWUMmPMAolyhFnkBmKkQSZSZAQccyRiJqg98O6XdPadrbs2E1ZKjXg+xC3Enb7LgadASbF4IXB1VAopY4DEJHFwKVKqX9knh8MfKMw4iUEv4J4YQiiwP2Mip87LIxCt297/pPwwGed9y1ysNhTaVoN7IjxhfmccsRVocQ8WwsyQ2nb2c2K9VvpLWAQOaiCNWc7y9dupVfBiXc8z86uHqPp0ZePpKwslZMSDmtY3LYPOgNMeqDeiSDDwammkQBQSr0KfDw+kRKKU8tQe7+EQP0fTvNvO+pH2N4VHVvc5bJsqzYso23tK6gNS3HsexFFr4c4W6amUkYNrAdOz+8eR/U5uWAqlCXXHc/iSzOL3mI+p4lfz4RxVRVUDSsDoGpYWeCChPngeD9ctrvrnOmUZRT/jt09pBWsWv8Bc+5Z0qfAw/TlcOqn4dULxK//RpCeFLn0uwjbnyRqggSz14jIvcAvAAV8CVgTq1RJxG89gddI3O0YXiNyr9Gln3tqxHioqDKq2lZUwcMXwsaXnOXKKH+1YRlryqay4/4vc3jKyLgSe8ZVvm64fF1XQUbcUcx6CjBzGjA7KsA5g4yc2zv30NnVY4jU1ZNXQcIwcgR1sdWPqmTGPmNpWreV4RUpdnYZxRNf3vBBqNRcUwalVJZhaeno4spFq1xnJFHMBsLGnpLgqgryK70IeA34OnAVsDrzWt6IyMki8oaIvC0i1zq8XykiD2XeXyYik6M4b07YR9P29QStb/p3oAs6IvcaXZojcrPgnzkatY7Sd7VB907j/+6OzHoLi1zW7TPKv+3Sv3PRzq8wXd42vhRuGVemWywX10guXfqC3BMrppEE43HE+PByFqNLXsznDNqJzuxjXZ4SZkweF3laar4d8Uwlu/S643n5uycyvXEMZUKfrEFmJ1YZvrZoFdMbx/SN7gU8ZyS5dr+z4zbzcJo55NK9MGqCrMzejdH6NNL2p5ly5T8BTgSagZdE5Eml1GrLZv8GbFVK7SciZwPfB74QpRyB8VtPUDfVP5gadETuNrp0K6dhf626zijrsX6pkSoq5f0zCmvlWcuofvyEBiY37svKTftzmLxF2cTp0SvIfALOQUfcWUZyp/E87Mi8GCvMYz5n0JGwvTZUa0f+QWHrDCLsiNxv9vHIZUeFnp1YZVi5bit/+9anSKWkT+l7zUiizkSzlz9xmjkkYU2Jr6EQkU8ANwL7WLdXSn04z3PPBN5WSr2bOc9i4AyMGYvJGZlzAzwC/FhERBXLUee3niDIDz1I9pObQrUry5bXDcXvpEDPfxIWnGykijbMhKtfg5oJ2ZVnLduLCIsuPZK2Hc9S9vAZyMaVhkGJIrPJ2p71zPuyZ0NBCWpkTCOZb/ZTEbrkpRHa1GhqMdILo8RN2bgp4vHVwyJxd9jdJr+ae8SAarYtO7oclW7YXhi53ov6Udkjez9DEFUmmv36/ufsQx2NaBIW5gWJUfwcuBqj/WlvhOeeCGywPG8GjnDbRinVIyLbgPFAls9CRC4FLgVobGyMUEQf7MokKuXiZnSsyrKiCu4+2tKsyKYYd7X3t0I1y6GLeCrcVEqoK9tp7Kc8yoeEwatlbJgvfFBDHHJknpR89iBKMR9ZnZSN1zmjysyxH6e9c49rNdtf/tsRbN3VX/o8ruwg+71QClo7+o1VlIbAN8PMcn0i7rOZYi/MC2Iotiml/i+Gczt90+0zhSDboJSaD8wHo3ps/qI5kGvqYq77ORkdUwm2vG4YCVOZ732ocVeU6o87uBmEQq7ohuhaxsKAe+L6QwxosJMQJDTxU4pRyGpXNl7njMrd4Vbio25kJS07urLWRcyZv4R/NG/ru744XS7mvYjrOxDkuE4NpIo9c3AjiKH4s4j8N/AY0GW+GMHK7GZgkuV5A/2lzO3bNItIOTAaaM/zvOHJNVsnjgVqqZTRd8J0r+x9aP8MoHl5vwJ2Mwh+i+ui9pWbhsc+o6iuy2vdQKAfuM/xk5TP7qcU45DV65xRuTuCFiI8pGE0LzdvG7B+I27FGdd3IMhxne6NCIlcUxHEUJjuIGudcgV8Ks9zvwRMEZF9gY3A2cC5tm2eBC4AlgCzgWeLEp/INXUxl/16e4wMqrqp7kbFqsyrarONkXUGYB9ZB11cF6V/PkvW8f0tY5XKy4i27exm5bo2xqS3s2Kdcq79ZO+NYTt+EoKEJn5B5Dhk9VLiUbrk3Nwm1vOPr67gnJ8tG3B9bvt6yRdG9ri+A0GPW2yXUlB8GxfFenKRzwA/AsqA+5RS3xORm4EmpdSTIjIceBA4FGMmcbYZ/HYjlsZFuTbkCbKfddSb7oUf7Gu4aCpHwX+8B2UBbHnQkbm9YdKXX4B7jsGzgVJcBGne5IFK97Jm3ifZv+s13qw8iGnX/gVJlfXfi3Qv/HBq/w7//gaM/NCA4yQlRmGVJ4rKpHHJECdBr8/vHsW9Mjvq6ymUPH7k3Lgo07BoIrDM2jdbRE5WSv0+X8GUUr8Dfmd77XrL/7uBOfmeJ29ydceY+5nrHuzYR/in/KDfj9+13ZhZTDjQ/zxBZwD2+EOQlN64yDMWIp1tTOtZg0jaeOxsy55d7fVxjBCXyjw6f2ZJG9F5uSwKJWuxXHJBr89Lvlxkj+u+5nLcJMXNrLjO9UXkSuAJ4ArgVRE5w/L2rXELlijyrcHz6MVwx4EDF4rZXVNVtcZMAozHuqnOxwsir1OZDNNwXbOm3xVjfa4U7Pgn7NgcT4kNL1nC3tfqOiSzQE1MQ2OvINswA1JlsM9RUFNf9DIIQYhqQVepy+CFl3xJl92PJCyuc8LV9SQi/wCOVEp1ZFZEPwI8qJS6U0RWKaUOLZyYwYnc9ZRvQNruYrnqNWN/cwRtd0317oENy6HxSCgrK5y8pk9//YuAGOd38OsnCrsBt7v6LniqLyaSdlnMFI9Y+bkOkuAOi1uGOO9REu5friilOHt+//fUq/ZV1OTqeioz3U1KqbUicizwiIjsQ/TrgZJLvvWZrC6WhplG97rm5c4tUZWCBz+XX5ZUvoF3AJSxLsNj3wE/xmL0qbC73JxchJn32zq6CuJOiSONtRgEkSEfH3yc9yhXl08SjIvfGo9i4aWF/ikifVViM0bjNKAW+GjcgiWGsPWZbp8KPz8RejNrE60uljkLB9ZdMiue7mxxXjUdl7xu+xlCw6RZRp0kBxfWgHo9vb0FqXwaCJdaVEFdEvm6p+J2HSTFfZZPzaakuVfyrT8VNaahM0t6JEEurxnF+UCP9QWlVA9wvojcE6tUSUKpYGUnOluNtQKqF5pfggUnwcV/yE43VWpgANfqKmqYmVllvdxdycfV2U7EcDXt3AJIf7luh9nNgNW2LZuoLVSfihxnLkHWBUQx0o0z5TbOQGfYEXU+Ae+wFV5zGU2H2TdJ62mSKpdX46Jmj/f+Fo84CcPJ3+/2pauuMwrwNb9kPN+0aqDCdFLi1llE83KjJpOknBVh0PhDrusgUqn+FNKOLa4uLPsPfXz9xMJkT+UZLwpTLC7uEtK5KMGoFYcpg72URhADlI9BDGu0pzeO4a5zpg+oyeR1XWEMaiHW0+TyeSdpnU+QBXdDlzD+fqXgrAfh1+cZRsJNYdqVuFOaaGdbcHmqauOJDXikr2b90KvLkc7WrMBxbDGKHOIvxVh85WeQcp0Z5C2fZTZmDe5/tGE0r2z4gF5FYAOU78rtMEZ7+dqtHPX9ZzmkYXRfJzsvwhrUXK8linUfXoSRK+4YizYUXgTN9be7j656DUZOyFaYbi4T+8rl+53dPY7yjHAuGd53PnvfijD4uLBSKaGuuiL4jCsKQq698PuB2n9cuQQSCzkzyEs522ZjbWc+2ifDK83bOGTSmL46S0ENUJxBd9MoNq1tp1dBb1r1dbJ75LKjIp8hhL2WMMo/n5lg0KSCuDP6tKHwIqi/3zrSbV5uKGtrJtCI8a7+fqB/lmF39+zc0u+GUso4lnXk7lIyvD/VdQmgoPGogamuhejdHTUh4y9eP1C3H1eYYnHFmBnkrJxtn1WtbGd641iWr22nN60oF/jbtz4V2L0TN6ZRbO3o4ssPrmDVhg+A/k52rvcgnUY6W1k09wjaOvfENsJu29ndZ8Sa1rZ7yhS3C6kQsYwEJ8knhCAd3Zwyjawd2RacZAS6/bKZrMdpmGm0Wv3hNFjwGUPx/3CaMeOoqs2uEGvPcOpsNdJbzUK79nMWqne3G/n0zQ7RYc8r08kv8yZIZk5bx27WrnuPnnQ6VPZOkC5skWP7rKSmnrvOPZSyzKlXbdhGKiVFNxLWrK5USqgfNZxHLjtyQCc7l537vtepB06jrroitusZV1VBVaUxzq6qLPfsLW79vH819whaO7oDZ60FyXIrxCJDPaOIAr8g9aZVRqDbK3ZhP05vL9x5kFGzqHlZpoy4rUeE2wi7us5Ib133IqAGnjOqmUAuGVZxVNR1FS9Y5VKnH5fvKDCdpvbRM/nbsKWsSE/hjr1/WJiZQa44fFb1IyuZMXlcIoKl4D5DKytLOXayG0BnK2rDMiTdYzzGOMNt79xDZ7eRAt/Z3evbWzyXZlBBZ6yFaGykDUVUeAWpG2YaKbZBRsPmuoqFpxpGAoGGzPoGp7RZr74VZoyiOrNOw1TmUfaccKpQ62U4CuyuClK51OnH5fvj62xFNiyjnF5mlr/Noi/uV/TRuC+2zyoJndOs5FvnqqdyPK+XTeWA3tW8VT6NqSNq83KZeMWfamuGMcPHnWTfP6yLKMz2cQ88tKGIC6uyfuQiuPPg4AHfzlbDKIARo5izsL+WUZisolTKPUAeR39mt57e1vNE3RgpD/x+XJ7vW65DJh1R8LapYXFTeklYBW6Sjy8/nVac9bOlrNpxLePZwdY9o1nqM8r3O57XaN7PyDrtH/b6dHrsUMFcbGdfje2lVNJpw3ffMNPYfuJ0QymFWRthVdhmYyP7+ePoCW2fLXRsMQoiFsJIBSWqUiO5LmzsE6NfcStF7HWVkliR1E4+M5y2nd28vOEDFClaGc2hDWPyUqxBRvNeRrZlRxdN67bSm1Y0rdtKa0cX9aOGh7q+JM34dDDbTj6BVifCBHxNBX9HprS4qeTvPy1cwDkrC2sFlA83Xq+oMjKwzHM5XWc+12+/VhHnkiQhAtKRElEQvy/AmGPqsbVkxBfuWcrZ85cMKNMQZamOpJXMsGMPYNeNDJ95VVszjBmTx1EmML1xDI9edmReitUpQBz0M+npSXPZL5rozXyWvWnF1361knQ6/PXlej+iRs8orHgFWnMdiYoYneTMrnVe+2YpeJcAdhCs7p29D4WNma613TthV9vArnjmdTpcfxrxH9FY7411lA3OJUuKNZuIID7iOjoPcV1Zinv9VlAqa7Fb2KCnH0lyYdjJZ7Zjd6dFOfp2WlNjlxMGzgTTacWc+UtYtWFb1vFWrvdJ60042lBYcVMk+WTqpNPO7UadqBrfr9gnzTJG9V51n9zIWsTn0CrVbf2F7frTHS2cs+hd7x+x072xKl97ddwCZTw5EkF8xNEl4bTw0OO6rIp7+j5jQSlWrv+gT4m3duSfF5+LEi1GBdWwAV6/siNRKmLr8Vpt1YdbOrq4ctGqAYbjzc07eKW530hUV5axe086cQY6LNpQWHFTJB1bYMNSIwsp7Eg06Cg2nTaCzmYq7QVPAZL76Nsag7Cu/N7ZYhgPp+u0zUTa1Cj/H7Hf9VnlcDNQhSLPuAK4jM5DXpfTaNWqoPOdAbiN0uMoK5IvWUazcQxKKZRSvvWfcik7EhQng2n/TASyDceOLq5cvIqmte1UVZbT2d3LIQ2jefjSWWzd1VP0GEO+aENhxUmRpNNG1lJfFEnMiwAAG8hJREFUqurMcCPRoKNYe3e2zjZD2eSiSK1uEHNFtz376fwnYVd7tsI03WQLToaNK6l97ExmNH6bpvUepR28rs/ujklCxlOeQXzH0XkO12VV3CJkKbl83Si5rNQtVqVS81pbOrq4YtEqjpr3rKuhssr4SvM2PjZpDK/4lB0JO0vq6UkzZ/4SXmnexgyLHPbPBMg2HGIYjl4FnV09PH3lMRzwoZGICHUj3RuQJaUPhh/aUNixKxKnVNWwMQqnUay1vIcZN4hCidrrToEhvz37aVe7s8Lc1W5sp3qRDcv41VX70SZj3L/IXtfn5I4pZsZTRAwYnUcwU3E7RzqtQjeuyWVGEkccI6gSTKWElAgrM0agaW17X5aQl4y/mnsE7R5lOsLOktJpxVnzl7BqvVEupMlnLYeX4TCNhN/9KYVsNNCGwh/7aNHNbWRV+nZlYW1OZPfVV1QZQebGWQNH+bkEft0C4htXuq8Ot57Hdr2pkfXU+Z3baZTu5pKKIy3X6ToKbYQ8rqvQneBymZFEHQzOpdT39MYxLF9rjMq/tmgViy37mPfQbhyiLBtvptiaHNIw2tNgehmOuHt6FBptKPzwGy1aR85WpW/PmLKOrs+8r1+Jdm03trGP8nMNoHsFxJ1KgdvXXFz8TDSjYz93TNRKvYClQcKJlfuoMe6qo1Hs40Yupb7vOmc6R33/WXrTipWWfZzuYZDKvk6zJN/V1pPH0bS2nY9NGsMjIVNsw96/JGej2dGGIgheo2DryNlU+uuXGrOHkRMGbrNhmaEYTSVaUQXdHT71mGzHcyNIQNxqiDpbDUPSNwN5Ce7LdObLd9Tv5ZLaucUoeOii1HMagRe6km1A/BSmn+KKs1tenL5xT9ldBgn1oyody2LY76EZOA5bA8kpxTXMauuoSdKCOj+0ocgX68i5osowFioTADcVoJP7yizv8fCFxohfKePP/LJU1xkxhvVLjED6wxcOLBVuxy0gbnV7mS4taxxjr0NhY6Yz38aV0TVEcqoDdf9pmZaxaUANUOo5j8CTECh3wEthptOKs+cvZcV6473FBVJchfCNu8ruMfNz22dAxpEQeLbileIadrW1H+aCPDM5IcjnlaQSKl5oQ5Ev1pGzteKrX5VXEeMHsvGlTJ/t5dmjYBGYswB+eKDz+06jMidl6fTDtPfPuPIV+OlMY2YzrBqGj812R130f7Bra/5uIvO8yqi6SapsgFK3jh6b1rbz5uYdgQKDcQSUo8BL2bfs6GL52nYAlr/XTsuOLiaMzg7gxqFICuUbd5TdZ+bntI9fxlHQmVbcM7Sz5y/t+zxnTh7L4kuPTGxwOizaUESBOXJWyogLOI1qndxXfqPgmglGvMP+vtuozElZOuX4289bVg57dhnH7t4JbW9lu6O+Pxl6dnv7/oPEHOwVdecsHFACw9rZrKqynFPv+mtWmqIrxQxk++Bewdb7eSByuO6wvvtIyXHml2/gGOJ19bTt7DZW2WdIenA6LNpQOJFPuQ6/wLd9VuG1vdv7XqOyID257ceFbINUN9WYSTRn3FHdHcajm+/fzXAFvV7LduaP+c3NOzj1rr/SG2TUm9BAth91IyuZOblfYYdWKjlet5Pv/tz5L/Le+nVMbpzMojhHwhHN/HKdacXl6jGN7/L3jBlF0oPTYdGGwo7dfz9ngTGyD/qFdpo5uAVwIbd2pGFGZeYP0+xN4XZc+4/34meMwHbzCqisgT2d7udyMlxu9aTc4haW7VKpFAd8aKRvvX/P8ycgkO2HiLD40iNzH+Hmcd1Zvvsdu7h60zVMr3iTlZv2p63jOepGjXDcL5KZR5wp0kVCRFh8yazQMYpSQRsKO9Yf3/oX4fZpxmjbL5DshlsA160EdxDMFdQ+hQb7ftTV5Yjfuew/3lSZkf1kruq2p9VacTJcQctauCi7UG6ChAayg+A0wg2sjCO67nFqG2NTb1FOmsPkLcpkO9BvKJzqK01vHMNd50xPTI/tyMjDhZlKyYAY02BBGwo75o9v/ZKMYk8bBmPnFhj5ofDHcwrgNsw0FO/6pcbr9nRaP3p7jDIb5uI5B1dP2pIK+KkGuKfVaBEZ6lxW4+E1AnRyJ7gpsSBlPTLbpKrrgrkJEhrIzoVQGUkRXHc6rTh30btck57CYam3KGs0+mk7yWOtr7R87VaO+v6zweJHRSCnmU+JujALgb4Ldswf35f/CphfMLH8HxJrj4bGo+Cq14zX5/+LkWEEhrF4+EIC9UdIpw0j0fxS9ijc1muhrWN3X2bLs82KPXvNyJzLrF2VWy8GV+w9Jsz7eM0aYzZmTcu19oMwZ0dffsHY3ly1HrZnRLF6XOSAV1+D0L0j8rxuIwj7AWd3f4dPdP+YLZ9/jJaO7j7ZnOorlWVO1RtQxih7awTB2u/D2uPDF6fZrQbQhsKZVAomHAiNRxozgH2Oyt2nalWYF/3OOJ7Z8c4MEkP/rMWPztb+/hJgBJ2r6wZ8yWtlu6XxyjgqvrDQOLd17ULc2JWY0w/RLMN+zzGGgejYMqh/rH5KzN4wZ1xVRaxK1jxfWaqMfRr35YrFq7Jks8ozY5+xPPzlI1ly3fHM3HdcVlOfXK83DnJu1BSmydgQoyiuJxEZBzwETAbWAmcppbbatvk48L/AKKAX+J5S6qECCmmMhKN2Z9ibCjU3YRRkCjhrqa4zYibrlxqrry/+g6MLR2rqWXRJff/0G9xTdwtFkFiGddX6IPyx+q1hsMZm3HouRIW9fpJSiqPmPTtANnusqH7UcBYHjB8Vo55RzuslBpELM2qKFaO4FviTUmqeiFybef4t2zadwPlKqbdEZG9ghYg8o5T6wH6w2IgiO8PJ72ltKrTwVKN436RZ/r20nbrI2V09ltdTkl2+OvYfgV8g0JRx5xb6jKLbqvWgKcYlRhAlZga4W3b4ryTOFadYiIjzQjangHvQNNMoemsUdL3EIMzIigIplN8w66QibwDHKqXeF5G9gOeUUgf47PMyMFsp9ZbXdjNmzFBNTU0RSpsnHVsMf3u6x5jSXrNmYHqon+IrZJAtV0XsIWPWj92pyx0EO6fLOUqlpr9JUHmVypT4yCjZxZfOiuz6WnZ0ceRtf6InrShPCUuuO76vAF8cJUMKWT1XkxsiskIpNcPpvWLNKCYopd4HyBgLTxMuIjOBYcA7Lu9fClwK0NjYGLGoHoRdjezkSgkyginUOoF8DJKLjAN+7Od8mJTTtQS5HodzpKvqSk6ZBB2Nx7mS2G2kH9WCNKtx8DqmlxEppTLcg53YDIWI/BFwyif9dsjj7AU8CFyglHJMgVFKzQfmgzGjCClqbgRVqlH4PXPNl3czZG6v52OQXGQc8GNnNHW5xiDsJUCUoi1AoTdPEu7KclOy+Y784zRCQWcCftuVUhnuwU5shkIpdYLbeyKyWUT2srieHNN9RGQU8DTwHaXU0phEzQ27Um15HeqnOSubsH5PcyU34l5UMMgx3MpqmAsAJ06Hi56BskyrxnwWcLnIOPDHXgGz78u+trDn6NhipPjecSC1k47wb9ca9h4lnKhcMnGVs3CbCdiNW5jAfqm4FQcrxXI9PQlcAMzLPD5h30BEhgG/AR5QSj1cWPEc8FooVlEFdx89sGFRLsdWyghwr38RECNF11wVHsbYuM0OOlv7F/o1vwT3Hg+X/MlInXUKNofBKmPmmqS6rv/HXl2OWPt2X/Db8KP4TBkQ1bzcWEC4IUC7VjdKtPRH0l0ybkUH7cYtTGA/DKUWsyoFijV8mgecKCJvASdmniMiM0Tk3sw2ZwH/AlwoIn/P/H28KNK6LRS74LfGQrHunYbiNWcWYRIE7Mc21xEAoIyMqFzWErjlhFfXGTMJk/dXGTWdrAvbHrkY7jgw3II3j2tKoYzaN51tkayRSI+oZU35NHpUijXl0yCzgju0UijRvHn7Wou8XDLptPGdizCpxZwJLLnu+L4AvJNxc9ouX4qxbmMoUJQZhVKqDTje4fUmYG7m/18AvyiwaM549X+un9ZfeTWXmUVWbamlRmmPSUf0zygmzQqmwIJWahUx3E33Hm8YCehvVmTOOPIdZbsdI6LaRG2de/hcx38wOb2Jd/c0sKRzT24j6hLNm4/MJROj680+E4g7eG6S9NlWqaJrPQXBS8GZyqbldcNIqF53BevVbGj9UqOkx/x/MQK1V68x3EFB/PhutZ/c3FVlZYa76b6TDCPROCt7xhFEmXsFgUdk+nab8pjHiEgx11aX83jND9i/6zXerDyI2upTcjoOULJ583m7ZJQyvrMFcr0VKt6gA+DxoA1FEPwUnH1m4aRg3UZvSsGZ9xkzifn/0t91rqw82I/WWvsJgv/grdVhfRbuOZ7TbSSaTsMDpxsGaOJ0OP+pgeXN7a1ZQyKdbUzrWYNI2ng0W75qXLHGCGY0jmbRsO8hGzKDE68S8hFSiLafOgAeD9pQBMVv5OmnYIP0bGiYaRgJtx+t0yjerfZTPtfkd61e7ilrtdxNq2BX28AFhvm6O6rrkL402SNo6a2hdsdmo+qpVgyOWF0y761fB8Mzn1H3Trjsr+4ZeyVIqfShLiWSnwtYKvjl41dl3DGkjMcR4wZO/WcvMFZuX/CUMeK2BhitAeIFn4Ed/zTeN2s/SRk0HN5f+ymozG6BTK/3vILAfgHiKCp0Zoxy+qrVnNP1n7x7+3H03j4NtcAh+B5DsDYKCl1R1RoAn9w42VLReJavkSi0rJrkUZQSHnFSkBIedqOQTmfXbLKPkq2j6PLhRn/qYdXQ1ZHdPe7CpyHda7iSzNiBeSxrKRAAUv0NlSDcwjq7TE7uI79Rv9+x3d4z03/NY5slyHOgZUcXp932KH+t+CoVkkalyhFriZSErpMoVmmKATGKALEiXUZj6OBVwqP4v5pSw1Q+t0+Fe0+Abe/Djs1Go6N0L6x70VDqVqyj6O4OY8rftR1IG1P/L79gKEyl+uMNZkMjc8RtjtTF/MgsDZWcehI4pfS6yWQf2QcZ9dvPaR25e/VIcOpTkSO1NcOY3DiZlWp/eigbOIOJub9AriPtnMtg54npkhGRwH0siiWrJlloQxEW64K1jU1wx1R46IsYpcIxHpXKdndY3TGVoww3kflonfp3thp+fZOJ0wdmDAVtqOSnJM3MpFzcR3b8jJKdiJoMiQiLLj2SD3/jOcr+fQ1yvs1lF+M6iXzy9SNdBxEzpSSrJj50MDss5oI1M8sI4P2/w8QZhpJvmGn0wjaD0qa7wwx0jxhvBHjNR6dUWbNXhVO8obrWWK3tV5rcK83VLzMpbBprRCucc1lRm0oJdaNGQLrS2c0U0zqJfPL1Sykzp5Rk1cSHNhRhMResLTipv+mQqZh2tRmj2TsOdF6cZ+8/bVemXgra6m9vmAlXrTb6Xrv9cL2OlZWZlFlsZ++hHWZ9QQQL6Xx94X7JAl6LInNMnfUyXPnm6ycpM8fPQCdJVk1x0IYiF8oyaxA6thhKy3Sj1NQbhiIfpemm2KyKsHm5sZ3f6M7tWNV1hrEx4yoPX9hfTyoXIlhI5zlCDxKUjmjVt4mf4bKPtJWC1o6ukht162C1JgjaUORKKgWjHKqox1UWIkpFKAJzFsAPD8wUB1ye36rcfEt1p9PU8gGHNY5hxfoPBo7Qg7i2orjvlusI4loyR9qlrGx1yQtNELShiIOoy0KYCuz8pwbGNZy2c4p/2KmZ4L2S3Om4YdNsg17b/achG5axuOEIWq99lNqRw7NH5UGNZD733XYdtRc8Fdi1VMrKVpe80ARBG4qk46SIndZKVI0Hs4R3RZWRdutWnNDc54KnjNIh+bRhDRvIthsdy/7SvIy61A6QEdn7hJkt5Dq7sV2HdLY5B3Edjl/KylYHqzVB0IaimDgpNQ9FOkARW5W4WYQv3ZNZo4Gz4vYzPHb8DEEYl5jTwsQoZwv5zG4c5EiJLYjrcvxSV7Y6WK3xQxuKYuGkdGDga16K1KrEzVTXTav6ZxRBS2h4KWA/RR5mtN+xxQigo/oXJo76UG7d+6Ju5RrkOjyOr5WtZjCjDUWxcFsQ56SI3BSYXYmbriSvGEXYoHgQBRo0NiBC1sJE81hhYgtes4Z8A/5+ckScWaXRlAraUBQLN6Xj9JqbAnNS4m5rNLz28SOq4HxNPTQe1X99YWIZJl6zhrgbEZVooyONJl90UcA4CBpQDRKjGGwEuT6vWUOERQU1Gk0/XkUB9YwiKqypqQ+cHiyg6jRSz3X0bhblsy4ATCJBrq+YswaNRjMAbSiiwDoCnvBReP9lIB17e8ms8y88tT9Q3HhUfiuti41fLKBE25dqNKWKNhRRYB0Bv78KhtUYPScKFfDsbDVSTs1AcaEMVFzoWYNGkyhKdMiZMKrrMt3rMuzZZbSXLJT/vLrOWJdglhwfDBk5EZUi12g0+aNnFFEgAhc/A/ed1N+ZrpA9iM0ReCnEKDQaTcmhDUVUpDIVZYvlLnErUqjRaDR5og1FlOggq0ajGYToGIVGo9FoPNGGQqPRaDSeaEOh0Wg0Gk+0odBoNBqNJ9pQaDQajcYTbSg0Go1G44k2FBqNRqPxZNCVGReRFmBdiF1qgdaYxMmHpMoFWrZcSKpckFzZkioXDE7Z9lFKOdb+GXSGIiwi0uRWg72YJFUu0LLlQlLlguTKllS5YOjJpl1PGo1Go/FEGwqNRqPReKINBcwvtgAuJFUu0LLlQlLlguTKllS5YIjJNuRjFBqNRqPxRs8oNBqNRuOJNhQajUaj8WTIGQoRGSci/09E3so8jnXZrlFE/iAia0RktYhMToJcmW1HichGEflxnDKFkU1EPi4iS0TkNRF5RUS+EKM8J4vIGyLytohc6/B+pYg8lHl/WdyfXUjZrsl8n14RkT+JyD5Jkc2y3WwRUSJSkPTPIHKJyFmZ+/aaiPyqEHIFkS2jJ/4sIqsyn+lnCiTXfSKyRURedXlfROR/MnK/IiLT8zqhUmpI/QE/AK7N/H8t8H2X7Z4DTsz8XwNUJUGuzPt3Ar8CfpyUewbsD0zJ/L838D4wJgZZyoB3gA8Dw4CXgQNt23wFuDvz/9nAQwW6T0FkO878LgGXJ0m2zHYjgeeBpcCMJMgFTAFWAWMzz+uTcs8wAseXZ/4/EFhbINn+BZgOvOry/meA/wMEmAUsy+d8Q25GAZwB3J/5/37gc/YNRORAoFwp9f8AlFIdSqnOYsuVke0wYALwh5jlseIrm1LqTaXUW5n/NwFbAMdVnnkyE3hbKfWuUqobWJyRz03eR4DjRQrSm9ZXNqXUny3fpaVAQwHkCiRbhlswBga7EyTXJcBPlFJbAZRSWxIkmwJGZf4fDWwqhGBKqeeBdo9NzgAeUAZLgTEisleu5xuKhmKCUup9gMyjU+/S/YEPROSxzJTyv0WkrNhyiUgKuB34ZsyyhJbNiojMxBiBvRODLBOBDZbnzZnXHLdRSvUA24DxMciSi2xW/g1j1FcIfGUTkUOBSUqp3xZIpkBy8f+3d3YhVlVRHP/9w/xICy0hhYyp6FvQSCqjSSsNKxAlA80hB+ZFxCJDgrBIood8KHvpITIaMLEaynEqCfNjwkzzc3RGoQ8UbChEIi17sDFXD3vfOox3zj2Tc88d76wfHO65+66z9/+ee+5ZZ+99zlrh/3iTpO2Sdkqa0Y+0LQfqJHUCG4Cn85FWkt4ei6lUZc5sSZuAMUU+WpaxikFALXAHcAz4EKgH3q2wrkXABjP7qa8vkPtAW6GescBqYIGZnesLbd2bKFLW/R7vLDblIHO7kuqAScCUsipKNFmk7F9t8SJkJeE4z5Ms+2wQYfhpKqEHtk3SeDM72Q+0zQMazex1SZOB1VFbOY793tCn/4GqdBRmNq2nzyQdlzTWzH6JJ7Vi3dhOYL+ZHYnbNBPG+S7IUfSBrslAraRFhHmTwZJOm1mPE5M5akPSFcDnwIuxu1sOOoFxiffXcH53v2DTKWkQYUggrZuepzYkTSM44ClmdiYHXVm0XQ6MB1rjRcgYoEXSTDPbU0FdBZudZtYFHJX0HcFx7C6jrqzaGoAZAGa2Q9JQQlC+vIbHeiLTsZiVgTj01AIsiOsLgPVFbHYDoyQVxtgfBA5XWpeZzTeza82sBlhKGIO8YCfRF9okDQbWRU1NZdSyG7hR0nWxzblRX0965wBbLM7wlZmS2uLwztvAzBzH2ktqM7NTZjbazGri8bUzaiynkyipK9JMuAkASaMJQ1FHyqwrq7ZjwENR263AUOBEDtpK0QI8Fe9+ugc4VRg+/l/kMUPfnxbCWPVm4If4emUsnwSsSthNBw4C7UAjMLg/6ErY15PfXU8ltQF1QBfQllgmlknPo8D3hDmQZbHsFcKJDcKftQn4EdgFXJ/j8VVK2ybgeGIftfQXbd1sW8nhrqeM+0zAG4SLtXZgbn/ZZ4Q7nbYT7ohqAx7OSddawp2FXYTeQwOwEFiY2GdvRd3tF/pbeggPx3EcJ5WBOPTkOI7j9AJ3FI7jOE4q7igcx3GcVNxROI7jOKm4o3Acx3FScUfhVC2lImx2s50q6d48dFUaSTWSnqy0DufiwR2FU800Ep+azcBUYEA4CqAGcEfhZMYdhVO1WA8RNiU9k8gJ8UHMV7EQWCKpTVJtN/sRkt6T1B63eTyWz4tlHZJWJOxPS1ohaa+kTZLuktQq6YikmdGmXtJ6SV/EfAcvJ7Z/LtbZIenZWFajkBvlHYWcDBslDYuf3RDr2Stpm6RbYnljzEnwTWx7TmziNUIomDZJS/pshzvVS15POPriSyUWwtVzR7eyn4EhcX1kfF0OLO2hjhXAm4n3owg5N44RQqkPArYAs+LnBjwS19cRQsJfCkwA2mJ5PeHJ2quAYUAH4Un3OwlP0g4nxPM6RAhOWQOcJT7tDnwE1MX1zfyXC+RuQsgSCD2qJsIF4W2EkNkQek+fVfq38eXiWaoyKKDjlOAgsCYGe2zOYD+NEOcHADP7TdL9QKuZnQCQtIaQTKYZ+Av4Ipq3A2fMrEtSO+GEX+BLM/s1bv8JcB/Byawzsz8T5bWE2D1HzawtbrsXqJE0gjBk1pSIKDwk0UazhUimhyVdneG7Os55uKNwBiKPEU7qM4GXJN1ewl5kC2VeoMvMCvbngDMAZnYuRrMt0L1OK1FvMtLs34SeyCXASTObmGGbPJI3OVWIz1E4A4qYd2GcmW0FngdGEoZ4/iCE2i7GRmBxoo5RwLfAFEmjFZJazQO+6qWc6Qr5yIcRsgZuJ6QhnSXpMknDgdnAtp4qMLPfCaG3n4jaJGlCiXbTvqvjnIc7CqdqkbQW2AHcLKlTUgMhD/L7cRhoP7DSQgKcT4HZxSazgVcJYec7JB0AHrAQsvkFYCshcug+MysWsj6NrwlJntqAj81sj5ntI8wt7CI4o1Vmtr9EPfOBhqjtEMVTnCY5CJyVdMAns50sePRYx6kAkuoJoZ8Xl7J1nErjPQrHcRwnFe9ROI7jOKl4j8JxHMdJxR2F4ziOk4o7CsdxHCcVdxSO4zhOKu4oHMdxnFT+AZYLbOzMXJjQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array(endataset)\n",
    "#print(X)\n",
    "X = X.reshape((X.shape[0],1024))\n",
    "#print(X)\n",
    "y = np.array(mi_dataset.Ys)\n",
    "print('labels',y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "#plt.cla()\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "print('out',X)\n",
    "bina = y==0\n",
    "print(bina)\n",
    "l0 = X[bina]\n",
    "print('lo', l0)\n",
    "l1 = X[y==1]\n",
    "\n",
    "ax.scatter(l0[:,0],l0[:,1], s=5, label = 'malignant')\n",
    "ax.scatter(l1[:,0],l1[:,1], s=5, label = 'benign' )\n",
    "\n",
    "ax.set_title('PCA of the encoded dataset')\n",
    "ax.set_xlabel('1st component')\n",
    "ax.set_ylabel('2nd component')\n",
    "ax.legend(fontsize=16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "c = [1]*10\n",
    "for i in range (100):\n",
    "    b+=[[i]*10]\n",
    "    \n",
    "b = np.zeros((100,10))\n",
    "for i in range(100):\n",
    "    for j in range(10):\n",
    "        b[i,j]= 10*i +j\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>370.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>190.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>300.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>120.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>510.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>790.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>500.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>360.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>830.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>260.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>590.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>940.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>930.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>600.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>700.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>690.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>340.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>720.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>660.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>290.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>570.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>870.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>640.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>400.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>550.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>650.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>380.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>470.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>530.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>910.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>990.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>900.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>760.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>280.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>800.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>480.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>540.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>880.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>160.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>230.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>250.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>420.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>750.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>170.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>440.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>630.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>850.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>859.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9\n",
       "37  370.0  371.0  372.0  373.0  374.0  375.0  376.0  377.0  378.0  379.0\n",
       "19  190.0  191.0  192.0  193.0  194.0  195.0  196.0  197.0  198.0  199.0\n",
       "8    80.0   81.0   82.0   83.0   84.0   85.0   86.0   87.0   88.0   89.0\n",
       "30  300.0  301.0  302.0  303.0  304.0  305.0  306.0  307.0  308.0  309.0\n",
       "12  120.0  121.0  122.0  123.0  124.0  125.0  126.0  127.0  128.0  129.0\n",
       "51  510.0  511.0  512.0  513.0  514.0  515.0  516.0  517.0  518.0  519.0\n",
       "79  790.0  791.0  792.0  793.0  794.0  795.0  796.0  797.0  798.0  799.0\n",
       "50  500.0  501.0  502.0  503.0  504.0  505.0  506.0  507.0  508.0  509.0\n",
       "36  360.0  361.0  362.0  363.0  364.0  365.0  366.0  367.0  368.0  369.0\n",
       "4    40.0   41.0   42.0   43.0   44.0   45.0   46.0   47.0   48.0   49.0\n",
       "83  830.0  831.0  832.0  833.0  834.0  835.0  836.0  837.0  838.0  839.0\n",
       "26  260.0  261.0  262.0  263.0  264.0  265.0  266.0  267.0  268.0  269.0\n",
       "0     0.0    1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0\n",
       "59  590.0  591.0  592.0  593.0  594.0  595.0  596.0  597.0  598.0  599.0\n",
       "2    20.0   21.0   22.0   23.0   24.0   25.0   26.0   27.0   28.0   29.0\n",
       "94  940.0  941.0  942.0  943.0  944.0  945.0  946.0  947.0  948.0  949.0\n",
       "93  930.0  931.0  932.0  933.0  934.0  935.0  936.0  937.0  938.0  939.0\n",
       "60  600.0  601.0  602.0  603.0  604.0  605.0  606.0  607.0  608.0  609.0\n",
       "18  180.0  181.0  182.0  183.0  184.0  185.0  186.0  187.0  188.0  189.0\n",
       "70  700.0  701.0  702.0  703.0  704.0  705.0  706.0  707.0  708.0  709.0\n",
       "69  690.0  691.0  692.0  693.0  694.0  695.0  696.0  697.0  698.0  699.0\n",
       "34  340.0  341.0  342.0  343.0  344.0  345.0  346.0  347.0  348.0  349.0\n",
       "13  130.0  131.0  132.0  133.0  134.0  135.0  136.0  137.0  138.0  139.0\n",
       "72  720.0  721.0  722.0  723.0  724.0  725.0  726.0  727.0  728.0  729.0\n",
       "66  660.0  661.0  662.0  663.0  664.0  665.0  666.0  667.0  668.0  669.0\n",
       "29  290.0  291.0  292.0  293.0  294.0  295.0  296.0  297.0  298.0  299.0\n",
       "57  570.0  571.0  572.0  573.0  574.0  575.0  576.0  577.0  578.0  579.0\n",
       "87  870.0  871.0  872.0  873.0  874.0  875.0  876.0  877.0  878.0  879.0\n",
       "1    10.0   11.0   12.0   13.0   14.0   15.0   16.0   17.0   18.0   19.0\n",
       "64  640.0  641.0  642.0  643.0  644.0  645.0  646.0  647.0  648.0  649.0\n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
       "40  400.0  401.0  402.0  403.0  404.0  405.0  406.0  407.0  408.0  409.0\n",
       "55  550.0  551.0  552.0  553.0  554.0  555.0  556.0  557.0  558.0  559.0\n",
       "65  650.0  651.0  652.0  653.0  654.0  655.0  656.0  657.0  658.0  659.0\n",
       "6    60.0   61.0   62.0   63.0   64.0   65.0   66.0   67.0   68.0   69.0\n",
       "38  380.0  381.0  382.0  383.0  384.0  385.0  386.0  387.0  388.0  389.0\n",
       "47  470.0  471.0  472.0  473.0  474.0  475.0  476.0  477.0  478.0  479.0\n",
       "53  530.0  531.0  532.0  533.0  534.0  535.0  536.0  537.0  538.0  539.0\n",
       "91  910.0  911.0  912.0  913.0  914.0  915.0  916.0  917.0  918.0  919.0\n",
       "99  990.0  991.0  992.0  993.0  994.0  995.0  996.0  997.0  998.0  999.0\n",
       "90  900.0  901.0  902.0  903.0  904.0  905.0  906.0  907.0  908.0  909.0\n",
       "76  760.0  761.0  762.0  763.0  764.0  765.0  766.0  767.0  768.0  769.0\n",
       "28  280.0  281.0  282.0  283.0  284.0  285.0  286.0  287.0  288.0  289.0\n",
       "80  800.0  801.0  802.0  803.0  804.0  805.0  806.0  807.0  808.0  809.0\n",
       "48  480.0  481.0  482.0  483.0  484.0  485.0  486.0  487.0  488.0  489.0\n",
       "7    70.0   71.0   72.0   73.0   74.0   75.0   76.0   77.0   78.0   79.0\n",
       "54  540.0  541.0  542.0  543.0  544.0  545.0  546.0  547.0  548.0  549.0\n",
       "88  880.0  881.0  882.0  883.0  884.0  885.0  886.0  887.0  888.0  889.0\n",
       "16  160.0  161.0  162.0  163.0  164.0  165.0  166.0  167.0  168.0  169.0\n",
       "23  230.0  231.0  232.0  233.0  234.0  235.0  236.0  237.0  238.0  239.0\n",
       "25  250.0  251.0  252.0  253.0  254.0  255.0  256.0  257.0  258.0  259.0\n",
       "42  420.0  421.0  422.0  423.0  424.0  425.0  426.0  427.0  428.0  429.0\n",
       "75  750.0  751.0  752.0  753.0  754.0  755.0  756.0  757.0  758.0  759.0\n",
       "17  170.0  171.0  172.0  173.0  174.0  175.0  176.0  177.0  178.0  179.0\n",
       "3    30.0   31.0   32.0   33.0   34.0   35.0   36.0   37.0   38.0   39.0\n",
       "44  440.0  441.0  442.0  443.0  444.0  445.0  446.0  447.0  448.0  449.0\n",
       "5    50.0   51.0   52.0   53.0   54.0   55.0   56.0   57.0   58.0   59.0\n",
       "20  200.0  201.0  202.0  203.0  204.0  205.0  206.0  207.0  208.0  209.0\n",
       "63  630.0  631.0  632.0  633.0  634.0  635.0  636.0  637.0  638.0  639.0\n",
       "14  140.0  141.0  142.0  143.0  144.0  145.0  146.0  147.0  148.0  149.0\n",
       "85  850.0  851.0  852.0  853.0  854.0  855.0  856.0  857.0  858.0  859.0\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.DataFrame(b)\n",
    "b= b.sample(frac=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[370., 371., 372., 373., 374., 375., 376., 377., 378., 379.],\n",
       "       [190., 191., 192., 193., 194., 195., 196., 197., 198., 199.],\n",
       "       [ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.],\n",
       "       [300., 301., 302., 303., 304., 305., 306., 307., 308., 309.],\n",
       "       [120., 121., 122., 123., 124., 125., 126., 127., 128., 129.],\n",
       "       [510., 511., 512., 513., 514., 515., 516., 517., 518., 519.],\n",
       "       [790., 791., 792., 793., 794., 795., 796., 797., 798., 799.],\n",
       "       [500., 501., 502., 503., 504., 505., 506., 507., 508., 509.],\n",
       "       [360., 361., 362., 363., 364., 365., 366., 367., 368., 369.],\n",
       "       [ 40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,  49.],\n",
       "       [830., 831., 832., 833., 834., 835., 836., 837., 838., 839.],\n",
       "       [260., 261., 262., 263., 264., 265., 266., 267., 268., 269.],\n",
       "       [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n",
       "       [590., 591., 592., 593., 594., 595., 596., 597., 598., 599.],\n",
       "       [ 20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.],\n",
       "       [940., 941., 942., 943., 944., 945., 946., 947., 948., 949.],\n",
       "       [930., 931., 932., 933., 934., 935., 936., 937., 938., 939.],\n",
       "       [600., 601., 602., 603., 604., 605., 606., 607., 608., 609.],\n",
       "       [180., 181., 182., 183., 184., 185., 186., 187., 188., 189.],\n",
       "       [700., 701., 702., 703., 704., 705., 706., 707., 708., 709.],\n",
       "       [690., 691., 692., 693., 694., 695., 696., 697., 698., 699.],\n",
       "       [340., 341., 342., 343., 344., 345., 346., 347., 348., 349.],\n",
       "       [130., 131., 132., 133., 134., 135., 136., 137., 138., 139.],\n",
       "       [720., 721., 722., 723., 724., 725., 726., 727., 728., 729.],\n",
       "       [660., 661., 662., 663., 664., 665., 666., 667., 668., 669.],\n",
       "       [290., 291., 292., 293., 294., 295., 296., 297., 298., 299.],\n",
       "       [570., 571., 572., 573., 574., 575., 576., 577., 578., 579.],\n",
       "       [870., 871., 872., 873., 874., 875., 876., 877., 878., 879.],\n",
       "       [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.],\n",
       "       [640., 641., 642., 643., 644., 645., 646., 647., 648., 649.],\n",
       "       [770., 771., 772., 773., 774., 775., 776., 777., 778., 779.],\n",
       "       [920., 921., 922., 923., 924., 925., 926., 927., 928., 929.],\n",
       "       [960., 961., 962., 963., 964., 965., 966., 967., 968., 969.],\n",
       "       [740., 741., 742., 743., 744., 745., 746., 747., 748., 749.],\n",
       "       [980., 981., 982., 983., 984., 985., 986., 987., 988., 989.],\n",
       "       [840., 841., 842., 843., 844., 845., 846., 847., 848., 849.],\n",
       "       [810., 811., 812., 813., 814., 815., 816., 817., 818., 819.],\n",
       "       [270., 271., 272., 273., 274., 275., 276., 277., 278., 279.],\n",
       "       [430., 431., 432., 433., 434., 435., 436., 437., 438., 439.],\n",
       "       [490., 491., 492., 493., 494., 495., 496., 497., 498., 499.],\n",
       "       [860., 861., 862., 863., 864., 865., 866., 867., 868., 869.],\n",
       "       [950., 951., 952., 953., 954., 955., 956., 957., 958., 959.],\n",
       "       [580., 581., 582., 583., 584., 585., 586., 587., 588., 589.],\n",
       "       [460., 461., 462., 463., 464., 465., 466., 467., 468., 469.],\n",
       "       [410., 411., 412., 413., 414., 415., 416., 417., 418., 419.],\n",
       "       [670., 671., 672., 673., 674., 675., 676., 677., 678., 679.],\n",
       "       [970., 971., 972., 973., 974., 975., 976., 977., 978., 979.],\n",
       "       [560., 561., 562., 563., 564., 565., 566., 567., 568., 569.],\n",
       "       [240., 241., 242., 243., 244., 245., 246., 247., 248., 249.],\n",
       "       [710., 711., 712., 713., 714., 715., 716., 717., 718., 719.],\n",
       "       [390., 391., 392., 393., 394., 395., 396., 397., 398., 399.],\n",
       "       [680., 681., 682., 683., 684., 685., 686., 687., 688., 689.],\n",
       "       [150., 151., 152., 153., 154., 155., 156., 157., 158., 159.],\n",
       "       [450., 451., 452., 453., 454., 455., 456., 457., 458., 459.],\n",
       "       [310., 311., 312., 313., 314., 315., 316., 317., 318., 319.],\n",
       "       [610., 611., 612., 613., 614., 615., 616., 617., 618., 619.],\n",
       "       [330., 331., 332., 333., 334., 335., 336., 337., 338., 339.],\n",
       "       [ 90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.],\n",
       "       [620., 621., 622., 623., 624., 625., 626., 627., 628., 629.],\n",
       "       [780., 781., 782., 783., 784., 785., 786., 787., 788., 789.],\n",
       "       [220., 221., 222., 223., 224., 225., 226., 227., 228., 229.],\n",
       "       [110., 111., 112., 113., 114., 115., 116., 117., 118., 119.],\n",
       "       [100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n",
       "       [730., 731., 732., 733., 734., 735., 736., 737., 738., 739.],\n",
       "       [820., 821., 822., 823., 824., 825., 826., 827., 828., 829.],\n",
       "       [320., 321., 322., 323., 324., 325., 326., 327., 328., 329.],\n",
       "       [520., 521., 522., 523., 524., 525., 526., 527., 528., 529.],\n",
       "       [210., 211., 212., 213., 214., 215., 216., 217., 218., 219.],\n",
       "       [350., 351., 352., 353., 354., 355., 356., 357., 358., 359.],\n",
       "       [890., 891., 892., 893., 894., 895., 896., 897., 898., 899.],\n",
       "       [400., 401., 402., 403., 404., 405., 406., 407., 408., 409.],\n",
       "       [550., 551., 552., 553., 554., 555., 556., 557., 558., 559.],\n",
       "       [650., 651., 652., 653., 654., 655., 656., 657., 658., 659.],\n",
       "       [ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.],\n",
       "       [380., 381., 382., 383., 384., 385., 386., 387., 388., 389.],\n",
       "       [470., 471., 472., 473., 474., 475., 476., 477., 478., 479.],\n",
       "       [530., 531., 532., 533., 534., 535., 536., 537., 538., 539.],\n",
       "       [910., 911., 912., 913., 914., 915., 916., 917., 918., 919.],\n",
       "       [990., 991., 992., 993., 994., 995., 996., 997., 998., 999.],\n",
       "       [900., 901., 902., 903., 904., 905., 906., 907., 908., 909.],\n",
       "       [760., 761., 762., 763., 764., 765., 766., 767., 768., 769.],\n",
       "       [280., 281., 282., 283., 284., 285., 286., 287., 288., 289.],\n",
       "       [800., 801., 802., 803., 804., 805., 806., 807., 808., 809.],\n",
       "       [480., 481., 482., 483., 484., 485., 486., 487., 488., 489.],\n",
       "       [ 70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.],\n",
       "       [540., 541., 542., 543., 544., 545., 546., 547., 548., 549.],\n",
       "       [880., 881., 882., 883., 884., 885., 886., 887., 888., 889.],\n",
       "       [160., 161., 162., 163., 164., 165., 166., 167., 168., 169.],\n",
       "       [230., 231., 232., 233., 234., 235., 236., 237., 238., 239.],\n",
       "       [250., 251., 252., 253., 254., 255., 256., 257., 258., 259.],\n",
       "       [420., 421., 422., 423., 424., 425., 426., 427., 428., 429.],\n",
       "       [750., 751., 752., 753., 754., 755., 756., 757., 758., 759.],\n",
       "       [170., 171., 172., 173., 174., 175., 176., 177., 178., 179.],\n",
       "       [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.],\n",
       "       [440., 441., 442., 443., 444., 445., 446., 447., 448., 449.],\n",
       "       [ 50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.],\n",
       "       [200., 201., 202., 203., 204., 205., 206., 207., 208., 209.],\n",
       "       [630., 631., 632., 633., 634., 635., 636., 637., 638., 639.],\n",
       "       [140., 141., 142., 143., 144., 145., 146., 147., 148., 149.],\n",
       "       [850., 851., 852., 853., 854., 855., 856., 857., 858., 859.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "\n",
    "y = iris.target\n",
    "print(y)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "#plt.cla()\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "l0 = X[y==0]\n",
    "l1 = X[y==2]\n",
    "\n",
    "ax.scatter(l0[:,0],l0[:,1])\n",
    "ax.scatter(l1[:,0],l1[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]:\n",
    "#     ax.plot(X[y == label, 0].mean(),\n",
    "#               X[y == label, 1].mean() + 1.5,\n",
    "#               X[y == label, 2].mean(), name,\n",
    "#               horizontalalignment='center',\n",
    "#               bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "# # Reorder the labels to have colors matching the cluster results\n",
    "# y = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "# ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap=plt.cm.nipy_spectral,\n",
    "#            edgecolor='k')\n",
    "\n",
    "# ax.w_xaxis.set_ticklabels([])\n",
    "# ax.w_yaxis.set_ticklabels([])\n",
    "# ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
